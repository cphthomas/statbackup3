---
output: 
  html_document: 
    css: style.css
    df_print: kable
---



```{r start,echo=FALSE,warning=FALSE,include=FALSE}
#pacman autoload evt. manglende pakker
if (!require("pacman")) install.packages("pacman")
pacman::p_load(timeDate, DT,plotly,rio,exams,e1071,WriteXLS,readxl,maps,knitr,kableExtra,ggplot2,openxlsx,quantmod,highcharter,forecast,ape,rdrop2) #load various packages
```

# Indledning 
					
<!-- BEGIN PROTECT-->
<!-- <meta name="robots" content="noindex, nofollow"> -->
<!-- <META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE"> -->
<!-- <style> -->
<!-- .Sentry_blanket { -->
<!-- background-color:#FFFFFF; -->
<!-- position:absolute; -->
<!-- z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/ -->
<!-- top:0px; -->
<!-- left:0px; -->
<!-- width:105%; -->
<!-- height:10000px; -->
<!-- padding:20px; -->
<!-- } -->
<!-- </style> -->
<!-- <script language="JavaScript" type="text/JavaScript"> -->
<!-- /* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/ -->
<!-- PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */ -->
<!-- pageLevel = 0; /* Access Level required to view this page   */ -->
<!-- SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */ -->
<!-- /* END Editable Settings: ////////////////////////////////////////////////////////////*/ -->
<!-- Sentry_ID = 22367; -->
<!-- </script> -->
<!-- <script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script> -->
<!-- <noscript> -->
<!-- <meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp"> -->
<!-- </noscript> -->
<!-- <div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div> -->
<!-- <div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div> -->
<!-- <script language="JavaScript" type="text/JavaScript"> -->
<!-- if(window.onload){ -->
<!--   window.onload = SentryProtect; -->
<!-- } -->
<!-- else if(document.body.onload){ -->
<!--   document.body.onload = SentryProtect; -->
<!-- } -->
<!-- else{ -->
<!--   SentryProtect(); /* call it here  */ -->
<!-- } -->
<!-- </script> -->
<!-- END PROTECT -->




  

Dette er undervisningsmaterialer og opgaver til faget statistik, for erhvervsakademierne. 


<div class="Keats">
<img src="img/wine.png" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
Orley Ashenfelter en Princeton økonom udviklede i 1980'erne en statistik model til forudsigelse af vinpriser baseret på nedbør, solskinstimer og andre klimadata. Hele den etablerede vinverden var i oprør, ved en præsentation i Christie's vinafdeling, blev han buhet ud. Robert Parker den verdenskendte vinkender udtalte "Det svarer til en filmanmelder der ikke ser filmen, men udelukkende baserer sin anmeldelse på instruktøren og skuespilleren". Orley udtalte, lang tid før det var muligt for vinseksperterne, at 1989 Bordeux ville blive århundredets vin, uanset den kun havde ligget 3 måneder på fade. Flere analyser har siden vist Orleys model er langt mere præcis eksperterne. Meget få vinkendere har anerkendt kvaliteten af Orleys model, men deres forecasts ligger nu langt tættere på modellens forudsigelser.

</div> 
Bogen er opbygget med en del praktiske eksempler.

Der er i nogle afsnit knapper med spørgsmål og svar, man kan klikke på disse og se om man kan nå frem til de rigtige løsninger.

Bogen er bygget op så kapitlerne beskriver fanerne i Freestat programmet. Man kan se og hente excelfiler direkte ved at klikke på links.

I alle brancher i den finansielle sektor spiller statistik en rolle. 

Bankerne sammensætter investeringsporteføljer, der minimerer risikoen (variansen), ved aktiver der har lav eller negativ samvariation (kovarians). Cykliske aktier som FL Smidth har fx. lav samvariation med en ikke cyklisk aktie som Novo.

Forsikringsselskaberne beregner præmier for forsikringstageren, baseret på statistike sandsynligheder for at en hændelse indtræffer. Modellerne kan være meget specifikke, en indboforsikring kan fx. være baseret på ikke bare postnummer, boligform, men også etage.

Finansielle virksomheder underlagt finanstilsynet, bruger modeller til beregning af risiko baseret på statistisk analyse.

Mægleren beregner udbudspriser, udfra en multipel lineær regressionsmodel, der indeholder variable som størrelse, energimærke, tagtype etc.



<a><img src="img/Freestatimg.png"alt="Freestat download"  target="_blank" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;" /></a>

## Freestat basisversion
Man kan få beregnet deskriptorerne i et utal af programmer heriblandt Freestat basis et gratis program, der kan hentes ved at [klikke her.](https://www.dropbox.com/s/th8q95lf864npie/FREESTATfin.xlsx?dl=1) Freestat basis, kan gennemføre de mest almindelige statistiske analyser. 

## Freestat fuld version
Har du købt adgang til premium abbonnementet, er der en del ekstra analyser, derfor bør du hente Freestat premium versionen. Seneste version af programmet kan [hentes her.](https://www.dropbox.com/s/a2jztexbxfzcli0/FREESTAT.xlsx?dl=1)

Du kan finde flere resourcer bagerst i bogen under materialer ved at [klikke her.](https://s.tepedu.dk/materialer.html)


Der findes opgaver quizzes og yderligere resourcer på [www.edutest.dk](http://www.edutest.dk)  

Min gode ven Benjamin Tejlbjerg har lavet en super hjemmeside med gymnasie matematik og statistik [http://www.mathhx.dk](http://www.mathhx.dk/?q=node/117). Siden er gratis og god til at genopfriske basisbegreber indenfor statistik, vi kommer ikke i dybden med disse begreber her.


<a href="http://bit.ly/mindmapfreestat"><img src="img/Hypotesemindmap.png"alt="Hypoteser mindmap download"  target="_blank" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;" /></a>
 
Denne online bog rettes og opdateres løbende med nye videoer opgaver og quizzes, der tages forbehold for tryk og tastefejl, men alle fejl eller uklarheder I måtte finde rettes med fluks. Forslag til forbedringer modtages med kyshånd.




***Noterne er kun til personligt brug. Alle rettigheder forbeholdes. Fotografisk eller anden gengivelse af eller kopiering eller anden udnyttelse, er uden forfatterens skriftlige samtykke forbudt ifølge dansk lov om ophavsret.***
<br>
<br>

# Datasæt  og data


<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->






<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228229052' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

### Uni- bi- og multivariate datasæt
  Datasæt er sæt af en eller flere variable:  

* Univariate datasæt fx tider ved marathonløb  
* Bivariate datasæt fx tider ved marathonløb og køn
* Multivariate datasæt fx tider ved marathonløb, køn, alder, medlem af sports klub
  
  
### Kvalitative variable  
  
  Kvalitative variable er data vi ikke kan måle eller tælle. De antager værdier i form af navne eller labels:
  
* Kæledyr: kat, hund, marsvin
* Køn: mand, kvinde
* Favorit app: Angry Birds, Messenger, Audible, Tinder
  
### Kvantitative variable
  
  Kvantitative variable er målbare numeriske variable, vi deler disse op i *kontinuerte* og *diskrete* variable
  
#### Diskrete variable
  
Diskrete variable er fx.
  
* Antal biler der passerer en bro observeret over flere dage.
* Dagsproduktionen af chokoladefrøer på Toms.
<img src="img/frog.png" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
* Antal personer der har iphones
* Antallet af indbyggere i en by
  
#### Kontinuerte variable
  
Kontinuerte variable er fx. 
  
* Antal ml. indhold i shampoo flasker
* Aktiekurser for Intel
* Vægten på værnepligtige
* Højden på studerende
  
  
### Skalatyper
  Vi kan ydermere inddele variable efter skalatype hvor lavere betyder mindst restriktiv.
  
  1. Nominalskala, bruges til at måle kvalitative data (er der kun 2 mulige udfald kaldes variablen specielt binær eller dikotom), fx.
      + Køn Mand Kvinde   
      + Styresystem: IOS Android Windows Symbian Andet
      + Race: Europæisk, Afrikansk, Asiatisk Andet
      
  2. Ordinalskala inddeler data efter en rangordning
      + Karakterer på 7 trins skalaen -3 00 02...
      + Moodys credit ratings Aaa Aa A Baa Ba B Caa Ca C
      + Tilfredshed meget utilfreds, noget utilfreds, nogenlunde tilfreds, meget tilfreds
      
  3. Intervalskala man kan sammenligne afstande og forskelle, men der er intet meningsfuldt nulpunkt. Nul for en intervalskala variabel betyder således ikke fravær af den målte størrelse. Nul grader celsius betyder altså ikke fravær af temperatur (det absolutte nulpunkt 0 Kelvin, hvor alle molekyler og atomer er i grundtilstanden). En IQ på 0 betyder ikke fravær af intelligens.
      + Temperatur målt i Celsius
      <img src="img/thermometer.png" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
      + Temperatur målt i Fahrenheit
      + PH
      + IQ
      
  4. Ratioskala
      + Beløb i lommen
      + Højde på studerende
      + Hastighed af biler ved vejkryds
      + Indhold i Coca Cola flasker
      <img src="img/Coca-Cola.png" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
      
<div class="Keats">
"Statistics are used much like a drunk uses a lamppost: for support, not illumination."   
- Vin Scully
</div>

  Interval- og ratioskalaer omtales som numeriske eller kontinuerte skalaer, disse er knyttet til kvantitative variable.  
  Nominal- og ordinalskalaer omtales ofte som kategorisk eller faktor, disse er knyttet til kvalitative variable.
  
  En stikprøve af skalatype ratio kan fx. reduceres til ordinal, eller nominal. Temperatur målt i celsius kan fx. omskrives til en ordinal variabel: koldt normalt varmt, eller en nominal variabel: ekstrem temperatur eller normal temperatur.
  
  Kategoriske skalaer kan yderligere reduceres til en dikotom skala, ved at sammenlægge kategorierne, til man kun har 2 kategorier.
  
  Det er vanskeligere at ændre en nominal- ordinal- eller ratioskala til en intervalskala. At ændre variablen nominalskala variablen køn til ordinal giver fx. ikke mening.
  























# Deskriptiv statistik






<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->













```{r OMX-data2, include=FALSE}

list.of.packages <- c("knitr","ggplot2","exams","openxlsx")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

companies <- c("TRYG.CO","DANSKE.CO","FLS.CO","GEN.CO","GN.CO","ISS.CO")
test <- getSymbols(companies,from = "2018-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE)
DKkurs <- as.data.frame(cbind(TRYG.CO[,6]  , DANSKE.CO[,6] ,FLS.CO[,6]   , GEN.CO[,6] ,GN.CO[,6],ISS.CO[,6] ))
DKdf <- round(100*((DKkurs[2:nrow(DKkurs),]-DKkurs[1:nrow(DKkurs)-1,])/DKkurs[1:nrow(DKkurs)-1,]),4)
names(DKdf) <- c("TRYG","DDB","FLS","GENMAB","TDC","ISS")
DKdf[is.na(DKdf)] <- 0 #Replace NA with 0
# DKdf <- as.matrix(DKdf)
write.xlsx(DKdf, file = "DK aktiekurser.xlsx", sheetName = "Kurser",colNames = TRUE,rowNames = TRUE,firstActiveRow = 2,  firstActiveCol = 2)


barx <- round(mean(DKdf[,1]),4)
s2 <- round(var(DKdf[,1]),4)


```




Deskriptiv eller beskrivende statistik er metoder til vha. figurer, tabeller og deskriptorer (middelværdi, median etc.) at præsentere et datamateriale. Beskrivende statistik er simplere metoder end inferentiel eller matematisk teoretisk statistik, hvor konklusioner drages på baggrund af en egentlig statistisk analyse.

<br>
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228228677' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

<br>

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228226686' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>
<br>
Vi har nedenfor et multivariat datasæt bestående af daglige procentvise afkast for 6 OMX20 aktier: `r names(DKdf)`  

Herunder kan man i tabellen se det procentvise daglige afkast for de 6 OMX20 aktier:  

```{r tabelomx,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
# datatable(DKdf, rownames = TRUE,class = 'cell-border stripe')

```

### Tryg aktien

Data for <a href="DK aktiekurser.xlsx" download> DK aktiekurser hentes her</a>, vi ønsker at beskrive det procentvise daglige afkast for Tryg vha. forskellige deskriptorer.  

I figuren herunder kan vi se hvordan selve kursen på Trygaktien udvikler sig over året, altså ikke afkastet i procent:

```{r, echo=FALSE,warning=FALSE, fig.width=9, fig.height=5}
x <- getSymbols("TRYG.CO", auto.assign = FALSE,from = "2018-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE)
hchart(x)
```

<br>



Vi kan grafisk illustrere Tryg data i et histogram, nedenfor er et histogram, på x-aksen er afkastet i procent, på y-aksen er hyppighederne dvs. antallet af observationer i hver søjle:  

```{r OMX-hist1,echo=FALSE,warning=F, fig.width=9, fig.height=5, dev='svg'}
hc <- ggplot(data=DKdf, aes(DKdf$TRYG)) + 
  
  geom_histogram( binwidth=.75,
                 col="white", 
                 aes(fill=..count..)) +
                stat_bin(binwidth=.75, geom="text", aes(label=..count..), vjust=-1.5,size=2)+
  scale_fill_gradient("Antal", low = "lightgrey", high = "black") +
  scale_size_area() + 
  xlab("Dagligt afkast Tryg aktien") +
  ylab("Hyppighed") +
  ggtitle("Histogram")
plot(hc)
```

Her er samme data med færre søjler, nu har vi på y-aksen frekvensen af søjlerne i stedet for hyppigheden. Frekvensen er antallet af observationer i hver søjle divideret med det totale antal observationer.

```{r OMX-hist2,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
hc <- ggplot(data=DKdf, aes(DKdf$TRYG, ..density..)) + 
  geom_histogram( binwidth=1,
                 col="white", 
                 aes(fill=..density..)) +
    scale_fill_gradient("Frekvens", low = "lightgrey", high = "black") +
  scale_size_area() + 
  stat_bin(binwidth=1, geom="text", aes(label=round(..density..,2)), vjust=-1.5,size=2)+
  xlab("Dagligt afkast Tryg aktien") +
  ylab("Frekvens=Hyppighed/n") +
  ggtitle("Histogram")
plot(hc)
```



<!-- ```{r OMX-tabel,echo=FALSE} -->
<!-- library(DT) -->
<!-- datatable(DKdf[,1], options = list(pageLength = 5)) -->
<!-- ``` -->


<!-- ```{r OMX-histplotly,echo=FALSE,fig.width=9, fig.height=5, dev='svg'} -->
<!-- hc <- ggplot(data=DKdf, aes(DKdf$TRYG, ..density..)) +  -->
<!--   geom_histogram( binwidth=1, -->
<!--                  col="white",  -->
<!--                  aes(fill=..density..)) + -->
<!--     scale_fill_gradient("Frekvens", low = "lightgrey", high = "black") + -->
<!--   scale_size_area() +  -->
<!--   stat_bin(binwidth=1, geom="text", aes(label=round(..density..,2)), vjust=-1.5,size=2)+ -->
<!--   xlab("Dagligt afkast Tryg aktien") + -->
<!--   ylab("Frekvens=Hyppighed/n") + -->
<!--   ggtitle("Histogram") -->
<!-- ggplotly(hc) -->
<!-- ``` -->
    

<!-- ```{r OMX-grafer, echo=FALSE} -->
<!-- library(dygraphs) -->
<!-- dygraph(DKdf, main = paste0("Danske aktiekurser pr. ",Sys.Date())) %>% -->
<!--   dyOptions(colors = RColorBrewer::brewer.pal(6, "Set2")) -->
<!-- barx <- round(mean(DKdf[,1]),4) -->
<!-- s2 <- round(var(DKdf[,1]),4) -->
<!-- ``` -->




### Middelværdien
Middelværdien af en variabel bestemmes ved at bestemme gennemsnittet for variablen. Da afkastet for Tryg indeholder n=`r nrow(DKdf)` observationer bliver formlen:

$$ \bar{x}=\frac{\sum_1^n (x_i)}{n}=\frac{`r DKdf[1,1]`+`r DKdf[2,1]`+`r DKdf[3,1]`...+`r DKdf[nrow(DKdf),1]`}{`r nrow(DKdf)`}=`r round(mean(DKdf[,1]),4)`$$

### Variansen
Variansen (stikprøvevariansen) er et udtryk for variationen omkring middelværdien i data:  

$$ S^2=\frac{\sum_1^n (x_i-\bar{x})^2}{n-1}=\\ \frac{(`r DKdf[1,1]`-`r barx`)^2+(`r DKdf[2,1]`-`r barx`)^2+(`r DKdf[3,1]`-`r barx`)^2...+(`r DKdf[nrow(DKdf),1]`-`r barx`)^2}{`r nrow(DKdf)-1`}=\\\\ \\ \\`r round(var(DKdf[,1]),4)`$$

<br>
<br>

<div class="Keats">
"Every two days now we create as much information as we did from the dawn of civilization up until  2003"  
- Eric Schmidt Google
</div>


### Standardafvigelsen
Standardafvigelsen er lig med kvadratroden af variansen, og er dermed ligeledes et mål for variationen omkring middelværdien. Standardafvigelsen har i modsætning til variansen samme enhed som data, hvilket gør tolkning lettere. Varians og standardafvigelse er afhængige af skala, hvilket fx. betyder, at værdier i kr. vil have 1000 gange større variation end størrelser målt i antal tusinde kr. For fx. aktie afkast vil standardafvigelsen være en vigtig parameter, da investorer er risikoaverse ønskes mindst mulig standardafvigelse i forhold til afkastet.  

$$ S=\sqrt{S^2}=\sqrt{`r s2`}=`r round(sd(DKdf[,1]),4)`$$


### Modus
<div class="Keats">
Gennemsnit   

<img src="img/moose.jpg" align="right" width="40%" height="40%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
En finansøkonom, en biolog og en statistiker er på elgjagt. De ser er flot stor elg. Finansøkonomen skyder og rammer en cm. foran snuden. Biologen skyder og rammer 1 cm. bag halen. Statistikeren jubler og råber: "Vi fik den!!! Vi fik den !!!"
</div>
Modus/modalværdi/typetallet er den hyppigst forekommende observation for et observations sæt. Typetallet er ikke nødvendigvis godt til at beskrive data. Har vi fx. observations sættet:  {1,1,2,3,4,5,6,7,8,9,10} er typetallet 1, medianen 5 og middelværdien 5.09. I dette tilfælde ville modus være en ringe deskriptor for observations sættet. 

Har vi en fordeling med en top kalder vi den for unimodal, har fordelingen 2 toppe kalder vi den bimodal.


## Medianen, kvartiler og fraktilen

Når vi ønsker at beskrive middeltendensen i et datasæt kan vi angive middelværdien, typetallet eller medianen. 

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228228875' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


Medianen også kaldet 2. kvartil eller 50% fraktilen er den midterste observation i det ordnede datasæt, er der et lige antal observationer tages gennemsnittet. Man kan nu bestemme nedre kvartil også kaldet 1. kvartil eller 25% fraktilen, som midten af den nedre halvdel af det ordnede datasæt. Tilsvarende gælder for øvre kvartil også kaldet 3. kvartil eller 75% fraktilen blot for den øvre halvdel at det ordnede datasæt.  

Hvis vi har et ordnet datasæt {11,13,15,16,16,18,20}, finder vi således medianen som den midterste observation, da vi har et ulige antal observationer. {11,13,15,***16***,16,18,20}. Vi kan udtrykke dette som at 50% af observationerne er 16 eller derover, eller ævkvivalent,  at 50% af observationerne er mindre end 16.

Vi kan bestemme 1. kvartil, som den midterste observation, i den nedre del at datasættet {11,13,15,16}. Vi har to midterste observationer {11,***13***,***15***,16}, i den nedre del af datasættet og bestemmer 0.25 fraktilen som gennemsnittet af disse: $\frac{13+15}{2}=14$. Vi kan udtrykke dette som at 75% af observationerne er 14 eller derover, eller at 25% af observationerne er mindre en 14.


<div class="Keats">
“Most murders are committed by someone who is known to the victim. In fact, you are most likely to be murdered by a member of your own family on Christmas day.”  
- Mark Haddon
</div>


    
    
Der er mere end 8 forskellige definitioner på kvartiler og fraktiler alt efter kontinent og region, vi går ikke i deltaljer med beregnings metoderne, men softwareprogrammer kan beregne fraktiler for os, disse kan altså afvige en smule alt efter beregningsmetoden. 1. og 2. kvartil er fx. ikke helt de samme når vi regner disse ud i excel.

Data for <a href="DK aktiekurser.xlsx" download> DK aktiekurser hentes her </a>, vi ønsker at beskrive det procentvise daglige afkast for Tryg vha. forskellige deskriptorer.

Medianen for Tryg findes ved at sortere data `r sort(DKdf[,1])[1]`, `r sort(DKdf[,1])[2]`, `r sort(DKdf[,1])[3]`,...,`r sort(DKdf[,1])[length(DKdf[,1])]` vi finder at medianen bliver `r median(DKdf[,1])`.

Vi bestemmer ligeledes 1. kvartil til `r quantile(DKdf[,1],0.25) `, og 2. kvartil til `r quantile(DKdf[,1],0.75) `. 1. kvartil, Medianen og 3. kvartil kan ses i nedenstående boxplot diagram, som hhv. første, anden og tredie vandrette streg i boxplottet for Tryg. Vi kan hvis vi skal forsøge at udtrykke fx. 1. kvartil med menneskeord sige at 25% af dagene var der et afkast på `r quantile(DKdf[,1],0.25) ` eller derunder. Man kunne også udtrykke det som at 75% af dagene var afkastet på mere end`r quantile(DKdf[,1],0.25) `.

Kvartilafstanden eller IQR interquantile range betyder 3. kvartil minus 1. kvartil, i Tryg eksemplet bliver kvartilafstanden  `r quantile(DKdf[,1],0.75) `- `r quantile(DKdf[,1],0.25) `= `r quantile(DKdf[,1],0.75)-quantile(DKdf[,1],0.25) `. Dette svarer præcis til højden på boksen i boxplottet for Tryg, vi kan altså konstatere at halvdelen af afkastene lå i et spænd på `r quantile(DKdf[,1],0.75)-quantile(DKdf[,1],0.25) ` procent.


```{r OMX-boxplots,echo=FALSE,message=FALSE,fig.width=9, fig.height=5, plotly=TRUE,dev='svg'}
library(ggplot2)
library(reshape2)
ggplot(data=DKdf, aes( x=factor(1), y=TRYG))+
    xlab("")+ggtitle("Dagsafkast Tryg aktien") +
  geom_boxplot()

```



### Fraktiler
Vi kan ligeledes bestemme alle mulige andre fraktiler end 25% 50% og 75% fraktilerne, software angiver ofte en række af disse så man hurtigt kan danne sig et billede af datasættet. Nedenfor er en del fraktiler for Tryg datasættet angivet, mange af disse kan direkte aflæses i boxplottet.  

10% fraktilen, 20% fraktilen,...,90% fraktilen kaldes også for deciler.  


Herunder ses fraktiler for dagligt afkast på Tryg aktien.





<br>
<br>


```{r dagsafkastpcttabel, echo=FALSE,warning=FALSE, echo=FALSE }
# options(scipen=999) #disable scientific
# frak <- c(0,.005,.025,.05,.1,.2,.25,.3,.4,.5,.6,.7,.75,.8,.9,.95,.975,.995,1)
# frak2 <- c("0% Fraktilen","0.5% Fraktilen","2.5% Fraktilen","5% Fraktilen","10% Fraktilen","20% Fraktilen","25% Fraktilen","30% Fraktilen","40% Fraktilen","50% Fraktilen","60% Fraktilen","70% Fraktilen","75% Fraktilen","80% Fraktilen","90% Fraktilen","95% Fraktilen","97.5% Fraktilen","99.5% Fraktilen","100% Fraktilen")
# df <- data.frame(round(quantile(DKdf[,1],frak),3))
# names(df)[1] <- "Dagsafkast i procent"
# # names(df)[0] <- "Fraktiler"
# #rownames(df) <- c()
# datatable(df,rownames = frak2,caption = "Fraktiler for Dagligt afkast Tryg aktien")

```


<br>
<br>



<br>

 
## Skævhed


<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228226797' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>




Skævheden angiver hvor meget en fordeling afviger fra en symmetrisk fordeling.  Hvis skævheden er positiv (højreskæv), vil fordelingen have koncentrerede værdier til venstre og mere spredte værdier til højre, en hale mod højre. Er fordelingen venstreskæv vil skævheden være negativ, og fordelingen har hale mod venstre. Hvis skævheden er 0 eller tæt på nul siger vi fordelingen er symmetrisk.

Formlen for skævhed er lidt indviklet, men softwarepakker kan beregne denne, der findes et par forskellige beregnings metoder så man kan godt få forskellige resultater. I Excel bruges formlen =SKEW() eller på dansk =SKÆVHED(). Skævheden for Tryg variablen kan beregnes til `r round(skewness(DKdf[,1], type=2),2)`, det betyder fordelingen er en lille smule venstreskæv, det er svært at se men der er et par negative afkast som gør at middelværdien er mindre end medianen. Vi siger at medianen er mere stabil overfor outliers (ekstreme observationer) hvorimod middelværdien påvirkes af outliers. Bemærk man får måske et resultat, der afviger en smule fra det her beregnede, dette skyldes de forskellige metoder til beregning.  

|Navn            |Skævhed              |Typisk form          |Indikator
|:-------------        |:------------               |:------------    |:---------
Højreskæv              |Større end 0      |Hale mod højre    |Middelværdi større end Median
Venstreskæv          |Mindre end 0         |Hale mod venstre   |Median større end Middelværdi
Symmetrisk      |0 eller tæt på 0 |Samme haler mod højre og venstre   |Median tæt på middelværdi



  


```{r echo=FALSE, dev='svg', fig.width=9, fig.height=9}
par(mfrow = c(3, 1))  # 3 rows and 2 columns
xb1 <- seq(0,30,length=200)
xy1 <- dchisq(abs(xb1),5)
plot(xb1, xy1, type="l", col="gray",xlim=c(0,30), lwd=2, main="Højreskæv fordeling",xlab="x",ylab="y")

xb <- seq(-30,0,length=200)
xy <- dchisq(abs(xb),5)
plot(xb,xy, type="l", col="gray",xlim=c(-30,0), lwd=2, main="Venstreskæv fordeling",xlab="x",ylab="y")

xn<-seq(-6,6,length=200)
yn<-dnorm(xn)
plot(xn, yn, type="l", col="gray",xlim=c(-6,6), lwd=2, main="Symmetrisk fordeling",xlab="x",ylab="y")

```




## Kurtosis

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228223866' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>  

Kurtosis eller topstejlhed beskriver hvor spids eller flad en fordeling er. Hvis kurtosis er positiv, er der meget vægt helt inde ved midten og ud i halerne det giver en spids, slank bredfodet fordeling, der kaldes leptokurtisk. Hvis kurtosis er negativ er der meget vægt mellem middelværdien og halerne, er kurven platykurtisk. Et typisk leptokurtisk datasæt vil i et histogram typisk have få høje søjler i midten og en eller to lange flade haler. Et platykurtisk datasæt vil typisk have mange næsten lige høje søjler, og kun enkelte lave søjler i siderne.  Er kurtosis tæt på nul, siger vi fordelingen er mesokurtisk eller klokkeformet, normalfordelinger er mesokurtiske.

Der findes forskellige lidt indviklede beregningsformler for kurtosis, men softwarepakker rapporterer den. I Excel bruges formlen =KURT() eller på dansk =TOPSTEJL(). Kurtosis for Tryg variablen er positiv, det betyder fordelingen er spids eller leptokurtisk, hvilket man måske kan fornemme, bemærk man får ikke nødvendigvis præcis samme værdi når man beregner kurtosis, ligesom med fraktiler findes der mange forskellige måder at beregne kurtosis på. Det er ikke vigtigt hvilken metode der benyttes, tolkningen er vigtigere.


Fordeling                     | Kurtosis                        |Typisk form
:-------------                 |:------------                    |:------------
Leptokurtisk                  | Større end 0                    | Spids
Mesokurtisk                   | 0 eller tæt på 0                | Klokkeformet
Platykurtisk                  | Mindre end nul                  | Flad


```{r kurtosis-diagrammer,echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
par(mfrow=c(1,3)) 
fs = function(x,epsilon,delta) dnorm(sinh(delta*asinh(x)-epsilon))*delta*cosh(delta*asinh(x)-epsilon)/sqrt(1+x^2)
vec = seq(-5,5,0.001)
plot(vec,fs(vec,0,0.5),type="l",ylim=c(0,1),col="black",xlab="x",ylab="Sandsynligheds tæthed",main="Platykurtisk fordeling",lwd=2)
plot(vec,fs(vec,0,2),ylim=c(0,1),type="l",col="black",xlab="x",ylab="Sandsynligheds tæthed",main="Leptokurtisk fordeling",lwd=2)
plot(vec,dnorm(vec),ylim=c(0,1),type="l",col="black",xlab="x",ylab="Sandsynligheds tæthed",main="Mesokurtisk fordeling",lwd=2)

```

```{r ,include=FALSE}
library(readxl)
library(e1071)
options(scipen=999)     #disable scientific notation
forbes400 <- read_excel("/cloud/project/FILER/Forbes\ 400\ 2014\ RICH\ US.xlsx",1)
Worth <- forbes400$Worth
meanworth <- mean(forbes400$Worth)
medianworth <- median(Worth)
worth25 <- quantile(Worth,0.25)
worth75 <- quantile(Worth,0.75)
worth90 <- quantile(Worth,0.9)
worthIQR <- IQR(Worth)
worthskew <- skewness(Worth, type=2)


Age <- forbes400$Age[!is.na(forbes400$Age)]
```

## Spørgsmål deskriptiv statistik


```{r echo=FALSE,warning=FALSE, echo=FALSE}
oldport <- c(344,421,293,459,228,391,375,377,318,428)*1000
newport <- c(344,421,293,459,228,391,375,377,318,428,2000000)*1000
```

<details> 
  <summary>Spørgsmål deskriptiv statistik</summary>
  **1.** Hvad bliver medianen for datasættet {2,5,2,5,3,4}?  
**2.** Hvad bliver 25% fraktilen for datasættet {2,5,2,5,3,4}?  
**3.** Hvad bliver 1. kvartil for datasættet {2,5,2,5,3,4}?  
**4.** Hvad bliver 2. kvartil for datasættet {2,5,2,5,3,4}?  
**5.** Hvad bliver 0.75 fraktilen for datasættet {2,5,2,5,3,4}?  
**6.** Du er nystartet porteføljeforvalter i private banking afdelingen i en større bank, du forestår forvaltningen af 10 kunders formuer. I antal tusinde kroner udgør porteføljerne: {344,421,293,459,228,391,375,377,318,428}. Du er fredag aften på Victor i dit Tiger suit. Under cocktails i baren falder du i snak med en ældre svensk mand, Ingvar Kamprad. Han er meget imponeret over dine prognoser og investeringsforslag. Mandag morgen kontakter en af hans medarbejdere dig, Ingvar Kamprad ønsker du skal forvalte en formue på 2 mia. kr. altså 2.000.000 tusinde kr. for ham. 
Hvorledes vil du bedst beskrive din typiske klient ved medianen eller middelværdien?  


</details>  
<br>
<details> 
  <summary> Svar deskriptiv statistik </summary>
  **1.** Det ordnede datasæt bliver: {2,2,3,4,5,5}. Der er 2 midterste observationer 3 og 4, {2,2,**3**,**4**,5,5}, gennemsnittet af disse er 3.5
Medianen bliver altså 3.5  
**2.** Det ordnede datasæt bliver: {2,2,3,4,5,5}. 25% fraktilen bliver {2,**2**,3,4,5,5}  
**3.** Det ordnede datasæt bliver: {2,2,3,4,5,5}. 1. kvartil bliver {2,**2**,3,4,5,5}  
**4.** Det ordnede datasæt bliver: {2,2,3,4,5,5}. 2. kvartil bliver {2,2,**3**,**4**,5,5} $\frac{3+4}{2}=3.5$  
**5.** Det ordnede datasæt bliver: {2,2,3,4,5,5}. 0.75 fraktilen bliver {2,2,3,4,**5**,5}  
**6.** Middelværdi og median for den gamle portefølje er henholdsvis `r prettyNum(mean(oldport),big.mark=" ",scientific=FALSE)` og `r prettyNum(median(oldport),big.mark=" ",scientific=FALSE)`.
Middelværdi og median for den ny portefølje er henholdsvis `r prettyNum(round(mean(newport),3),big.mark = " ")` og `r prettyNum(median(newport),big.mark = " ")`.  
Den gennemsnitlige porteføljeværdi, er steget voldsomt efter den nye superklient, men den typiske klient beskrives her bedst ved medianen. Dette skyldes medianen ikke påvirkes væsentligt af denne nye store kunde, vi kan kalde denne observation for en outlier. Medianen er altså mere stabil overfor outliers i forhold til middelværdien.

</details>
<br>
<details> 
  <summary>Spørgsmål Forbes 400 rigeste i USA formue</summary>



I linket her er filen [Forbes 400 2014 RICH US](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlYTRWVWozb09PRTQ), filen indeholder data vedr. de 400 rigeste amerikanere i 2014. Formuen worth er opgjort i antal milliarder USD, de følgende spørgsmål relaterer sig udelukkende til denne variabel. 

**1.** Hvilken type variabel er variablen worth?  
**2.** Hvad er den gennemsnitlige formue for de 400 rigeste?  
**3.** Hvad er medianen for de 400 rigeste?  
**4.** Hvad er fordelingens skævhed?  
**5.** Hvad er 3. kvartil?  
**6.** Hvad er Kvartilafstanden?  
**7.** 10% af de rigeste velhavere har en formue der er større end?  
**8.** 2.5% af de rigeste velhavere har en formue der er større end?  
**9.** 90% af de fattigste velhavere har en formue der er mindre end?  
**10** Er fordelingen flad, klokkeformet eller spids?  
**11** Er fordelingen platykurtisk, mesokurtisk eller leptokurtisk?  
**12** Hvad er variationsbredden?  

</details> 
<br>
<details> 
  <summary>Svar Forbes 400 rigeste i USA formue</summary>

**1.** Variablen worth er en kvanitativ, kontinuert variabel, ratioskala.  
**2.** Den gennemsnitlige formue er `r base::round(meanworth,2)` mia. USD  
**3.** Medianen for variablen worth er `r base::round(medianworth,2)` mia. USD  
**4.** Fordelingens skævhed er `r base::round(worthskew,2)`, fordelingen er som vi vel ville forvente klart højreskæv. Der er velhavere med meget store formuer, dvs. outliers med høje værdier, vanvittigt rige mennesker, som fx Bill Gates, Warren Buffet etc. disse danner en hale mod højre.  
**5.** 3. kvartil er `r round(quantile(Worth,.75),2)`.   
**6.** Kvartilafstanden er `r round(IQR(Worth),2)` mia. USD, størrelsen findes som 3. kvartil minus 1. kvartil. 50% af velhaverne ligger i et spænd på `r round(IQR(Worth),2)` mia. USD  
**7.** 10% af velhaverne har en formue der er større end `r round(quantile(Worth,.9),2)` mia. USD, her skal vi bestemme 90% fraktilen, denne fremgår direkte af Freestat.  
**8.** 2.5% af velhaverne har en formue der er større end `r round(quantile(Worth,.975),2)` mia. USD, her skal vi bestemme 97.5% fraktilen, denne fremgår direkte af Freestat.  
**9.** 90% af velhaverne har en formue der er mindre end `r round(quantile(Worth,.9),2)` mia. USD, her skal vi bestemme 90% fraktilen, denne fremgår direkte af Freestat, dette er samme svar som i spørgsmål 7.  
**10** Fordelingen er klart spids, da kurtosis er meget høj 34.92  
**11** Fordelingen er pr. definition leptokurtisk, da kurtosis er meget høj 34.92  
**12** Variationsbredden findes som den rigeste minus den fattigste milliardær, variationsbredden bliver altså `r max(Worth)`-`r min(Worth)` = `r max(Worth)-min(Worth)`  

Vi kan da også se af histgrammet nedenfor at fordelingen er meget højreskæv og spids:  

```{r ForbesWorth-hist1,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
hc <- ggplot(data=forbes400, aes((forbes400$Worth))) + 
  
  geom_histogram( binwidth=.75,
                 col="white", 
                 aes(fill=..count..)) +
                stat_bin(binwidth=.75, geom="text", aes(label=..count..), vjust=-1.5,size=2)+
  scale_fill_gradient("Antal", low = "lightgrey", high = "black") +
  scale_size_area() + 
  xlab("Formue i milliarder USD") +
  ylab("Hyppighed") +
  ggtitle("Histogram over formuefordelingen blandt Forbes 400")
plot(hc)
```


Herunder ses det output man ville generere i Freestat.  

<img src="img/deskriptivForbes400worth.png" alt="deskriptivForbes400worth.png" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

</details> 
<br>
<details> 
  <summary>Spørgsmål Forbes 400 rigeste amerikanere</summary>

I linket her er filen [Forbes 400 2014 RICH US](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlYTRWVWozb09PRTQ), filen indeholder data vedr. de 400 rigeste amerikanere i 2014. Vi vil i de næste spørgsmål se på fordelingen af variablen alder, pas på denne variabel er ikke komplet, sørg for at fjerne observationer med manglende data. Der er 2 personer, for hvem man ikke har indhentet oplysninger om alder.

**1.** Er datasættet bivariat?  
**2.** Hvad er den gennemsnitlige alder for de 400 rigeste?  
**3.** Hvad er medianen for alder?  
**4.** Hvad er aldersfordelingens skævhed?  
**5.** Hvad er 3. kvartil for Age?  
**6.** Hvad er Kvartilafstanden for Age?  
**7.** 25% af af velhaverne er ældre end?  
**8.** 2.5% af de yngste velhavere er yngre end?  
**9.** 0.5% er yngre end?  
**10.** Er fordelingen flad, klokkeformet eller spids?  
**11.** Er fordelingen platykurtisk, mesokurtisk eller leptokurtisk?  
**12.** Hvad er aldersspændet?  
</details>
<br>
<details> 
  <summary>Svar Forbes 400 rigeste amerikanere</summary>

**1.** Nej datasættet er ikke bivariat men multivariat.  
**2.** Den gennemsnitlige alder for de 400 rigeste er `r round(mean(Age),2)` år.  
**3.** Medianen for alder er `r round(median(Age),2)` år.  
**4.** Aldersfordelingens skævhed `r round(skewness(Age, type=2),2)` fordelingen kan derfor betegnes som symmetrisk.  
**5.** 3. kvartil for Age er `r round(quantile(Age,0.75),2)` år.  
**6.** Kvartilafstanden for Age er `r round(IQR(Age),2)` år.  
**7.** 25% af af velhaverne er ældre end `r round(quantile(Age,0.75),2)` år.  
**8.** 2.5% af de yngste velhavere er yngre end `r round(quantile(Age,0.025),2)` år.  
**9.** 0.5% er ynrgre end 27.99 år.  
**10.** Fordelingen er klokkeformet da kurtosis er -0.18 dvs meget tæt på 0.  
**11.** Er fordelingen mesokurtisk, jvf. spørgsmål 10.  
**12.** Aldersspændet er `r round(max(Age)-min(Age),2)`  



```{r ForbesAge-hist,echo=FALSE, warning=FALSE, fig.width=9, fig.height=5, dev='svg'}
hc <- ggplot(data=(forbes400), aes((forbes400$Age))) + 
  
  geom_histogram( binwidth=.75,
                 col="white", 
                 aes(fill=..count..)) +
                stat_bin(binwidth=1, geom="text", aes(label=..count..), vjust=-1.5,size=2)+
  scale_fill_gradient("Antal", low = "lightgrey", high = "black") +
  scale_size_area() + 
  xlab("Alder i år") +
  ylab("Hyppighed") +
  ggtitle("Histogram over aldersfordelingen blandt Forbes 400")
plot(hc)
```

Herunder ses det output man ville generere i Freestat.

<img src="img/deskriptivForbes400Age.png" alt="deskriptivForbes400Age.png" align="right" width="50%" height="50%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>



</details> 
<br>
<details> 
  <summary>Spørgsmål BNP 2015 for verden på lande i millioner USD.</summary>




```{r ,include=FALSE}
library(readxl)
library(e1071)
GDP <- read_excel("/cloud/project/FILER/GDP2015.xlsx",1)
gdp <- GDP$`Millions USD`
```

I linket her er filen [GDP2015](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlamdFSkk4SWU4eWM). Besvar følgende spørgsmål for variablen BNP/GDP. BNP bruttonationalproduktet er værdien af de varer og ydelser som et land producerer.  

**1.** Hvilken type variabel er variablen GDP?  
**2.** Hvad er det gennemsnitlige GDP for landene?  
**3.** Hvad er medianen for landene?  
**4.** Hvad er fordelingens skævhed, er denne som du ville have forventet?  
**5.** Hvad er 3. kvartil?  
**6.** Hvad er Kvartilafstanden?  
**7.** 25% af landene med størst produktion, har et BNP der er større end?  
**8.** 2.5% af landene med mindst produktion, har et BNP der er mindre end?  
**9.** 90% af landene med mindst produktion, har et BNP der er mindre end?  
**10** Er fordelingen flad, klokkeformet eller spids?  
**11** Er fordelingen platykurtisk, mesokurtisk eller leptokurtisk?  
**12** Hvad er variationsbredden?  

</details> 
<br>
<details> 
  <summary>Svar BNP 2015 for verden på lande i millioner USD.</summary>


**1.** Variablen GDP er en kvanitativ, kontinuert variabel, ratioskala.  
**2.** Hvad er det gennemsnitlige GDP for landene `r base::round(mean(gdp),2)` mio USD.  
**3.** Medianen for variablen GDP er `r base::round(median(gdp),2)` mio USD.  
**4.** Fordelingens skævhed er `r base::round(skewness(gdp,type=2), 2)`  
**5.** 3. kvartil er `r base::round(quantile(gdp,.75),2)` mio USD.  
**6.** Hvad er Kvartilafstanden `r base::round(IQR(gdp),2)` mio USD.  
**7.** 25% af landene med størst produktion, har et BNP der er større end `r base::round(quantile(gdp,.75),2)` mio USD.  
**8.** 2.5% af landene med mindst produktion, har et BNP der er mindre end `r base::round(quantile(gdp,.025),2)` mio USD.  
**9.** 90% af landene med mindst produktion, har et BNP der er mindre end `r base::round(quantile(gdp,.9),2)` mio USD.  
**10** Fordelingen er klart spids, der er rigtig mange lande med et mindre BNP, mens vi har en gruppe lande med forholdsmæssig høj produktion hvilket som ses af histogrammet giver en meget spids fordeling.  
**11** Er fordelingen derfor leptokurtisk da den er spids.  
**12** Variationsbredden er forskellen mellem det landet med højeste og laveste produktion, dvs. `r base::round(max(gdp),2)`-`r base::round(min(gdp),2)` =`r base::round(max(gdp)-min(gdp),2)` mio USD.  

Herunder ses histogrammet for BNP for forskellige lande, vi kan af histogrammet se at fordelingen er højreskæv og leptokurtisk. Der er klare outliers fx USA.  



```{r GDP-hist,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
hc <- ggplot(data=GDP, aes(gdp)) + 
  
  geom_histogram( binwidth=1000000,
                 col="white", 
                 aes(fill=..count..)) +
                stat_bin(binwidth=1000000, geom="text", aes(label=..count..), vjust=-1.5,size=2)+
  scale_fill_gradient("Antal", low = "lightgrey", high = "black") +
  scale_size_area() + 
  xlab("BNP i mio USD") +
  ylab("Hyppighed") +
  ggtitle("Histogram over bnp i mio dollars")
plot(hc)
```
</details> 
<br>
<details> 
  <summary>Spørgsmål Danske virksomheder egenkapital.</summary>

```{r ,include=FALSE}
dkvirk <- read_excel("/cloud/project/FILER/VIRKSOMHEDER-DK.xlsx",1)
```

I linket her er filen [VIRKSOMHEDER-DK](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlVmxHTDltNk1VSG8), der viser data for 369 danske virksomheder med ekstern revision. Der er således en overvægt af virksomheder af en vis størrelse, hvorfor samtlige beløb er angivet i antal 1000 DKK.  Besvar følgende spørgsmål for variablen egenkapital i antal 1000 DKK.

**1.** Hvilken type variabel er variablen egenkapital?  
**2.** Hvad er det gennemsnitlige egenkapital for virksomhederne?  
**3.** Hvad er medianen for egenkapital?  
**4.** Hvad er fordelingens skævhed, er denne som du ville have forventet?  
**5.** Hvad er 3. kvartil?  
**6.** Hvad er Kvartilafstanden?  
**7.** 25% af de mest velpolstrede virksomheder, har en egenkapital der er større end?  
**8.** 2.5% af de mindst velpolstrede virksomheder, har en egenkapital der er mindre end?  
**9.** 90% af virksomhederne med mindst egenkapital, har en egenkapital der er mindre end?  
**10** Er fordelingen flad, klokkeformet eller spids?  
**11** Er fordelingen platykurtisk, mesokurtisk eller leptokurtisk?  
**12** Hvad er variationsbredden?  
</details> 
<br>
<details> 
  <summary>Svar Danske virksomheder egenkapital.</summary>

**1.** Variablen egenkapital er en kvanitativ, kontinuert variabel, ratioskala.  
**2.** Hvad er det gennemsnitlige egenkapital for virksomhederne `r base::round(mean(dkvirk$Egenkapital),2)` DKK.  
**3.** Medianen for variablen egenkapital er `r base::round(median(dkvirk$Egenkapital),2)` 1000 DKK.  
**4.** Fordelingens skævhed er `r base::round(skewness(dkvirk$Egenkapital,type=2), 2)`  
**5.** 3. kvartil er `r base::round(quantile(dkvirk$Egenkapital,.75),2)` 1000 DKK.  
**6.** Hvad er Kvartilafstanden `r base::round(IQR(dkvirk$Egenkapital),2)` 1000 DKK.  
**7.** 25% af de mest velpolstrede virksomheder, har en egenkapital der er større end `r base::round(quantile(dkvirk$Egenkapital,.75),2)` 1000 DKK.  
**8.** 2.5% af de mindst velpolstrede virksomheder, har en egenkapital der er mindre end `r base::round(quantile(dkvirk$Egenkapital,.025),2)` DKK.  
**9.** 90% af virksomhederne med mindst egenkapital, har en egenkapital der er mindre end `r base::round(quantile(dkvirk$Egenkapital,.9),2)` 1000 DKK.  
**10** Fordelingen er klart spids med positiv kurtosis.  
**11** Fordelingen derfor leptokurtisk da den er spids.  
**12** Variationsbredden er forskellen mellem det virksomheden med højeste og laveste egenkapital, dvs. `r base::round(max(dkvirk$Egenkapital),2)`-`r base::round(min(dkvirk$Egenkapital),2)` =`r base::round(max(dkvirk$Egenkapital)-min(dkvirk$Egenkapital),2)` 1000 DKK.  

Herunder ses histogrammet for egenkapital for de danske virksomheder i antal 1000 DKK, vi kan af histogrammet se at fordelingen er højreskæv og leptokurtisk. Der er klare outliers, dvs store etablerede virksomheder med megen egenkapital.  


```{r egenkapital2,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
hc <- ggplot(data=dkvirk, aes(dkvirk$Egenkapital)) + 
  
  geom_histogram( binwidth=100000,
                 col="white", 
                 aes(fill=..count..)) +
                stat_bin(binwidth=100000, geom="text", aes(label=..count..), vjust=-1.5,size=2)+
  scale_fill_gradient("Antal", low = "lightgrey", high = "black") +
  scale_size_area() + 
  xlab("Egenkapital i DKK") +
  ylab("Hyppighed") +
  ggtitle("Histogram over egenkapital i antal 1000 DKK")
plot(hc)
```
</details>
<br>
<details> 
  <summary>Spørgsmål Diskussions spørgsmål til dagsafkast på danske aktier.</summary>






Data for <a href="DK aktiekurser.xlsx" download> DK aktiekurser hentes her.</a>

Man siger ofte at kursfaldet ved en korrektion, er hurtigere og voldsommere end stigningen i et positivt marked. Kan man baseret på data for aktierne, konkludere at dette synes at være tilfældet?  
 
Hvorfor kan en portefølje, der ikke er volatil (dvs. porteføljen har en lille standardafvigelse), være en fordel for den risikoaverse investor?  

</details>

## Selvtest


<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=57" target="_blank">Selvtest Realkredit Deskriptiv statistik</a></h2>
<br>
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=50" target="_blank">Selvtest Diamanter Deskriptiv statistik</a></h2>







# Normalfordelingen






<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->






<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337728' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

Vi vil i dette kapitel se på forskellige typer af fordelinger. Data- stikprøve og sandsynlighedsfordelingen. For at forstå sammenhængen mellem disse er normalfordelingen essentiel. Normalfordelingen er den vigtigste sandsynligheds fordeling,<img src="img/height.png" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/> den er kontinuert symmetrisk mesokurtisk og bestemmes entydigt ud fra middelværdien $\mu$ og standardafvigelsen $\sigma$.




En undersøgelse hos [Tall life](https://tall.life/height-percentile-calculator-age-country/) viste, at danske mænds højde i gennemsnit er 180.4 centimeter, med en standardafgivelse på 7.42 centimeter. Vi udtager simpelt tilfældigt 3 stikprøver på 1000 danske mænd og måler deres højde, og markerer hver persons højde i centimeter på x-aksen. 

```{r echo=FALSE,fig.width=9, fig.height=6, dev='svg'}
par(mfrow=c(3,1)) 
s100 <- colMeans(matrix(rnorm(1000, 180.4,7.42),ncol=100))
y <- rep(1,1000)
plot(rnorm(1000, 180,7.42),y, xlim=c(140,220), type="h",lty=1, col="black", lwd=0.5, ylab="",main="Mænds højde stikprøve 1",xlab="1000 tilfældige danske mænds højde",yaxt='n')

s100 <- colMeans(matrix(rnorm(1000, 180.4,7.42),ncol=100))
y <- rep(1,1000)
plot(rnorm(1000, 180,7.42),y, xlim=c(140,220), type="h",lty=1, col="black", lwd=0.5, ylab="",main="Mænds højde stikprøve 2",xlab="1000 tilfældige danske mænds højde",yaxt='n')

s100 <- colMeans(matrix(rnorm(1000, 180.4,7.42),ncol=100))
y <- rep(1,1000)
plot(rnorm(1000, 180,7.42),y, xlim=c(140,220), type="h",lty=1, col="black", lwd=0.5, ylab="",main="Mænds højde stikprøve 3",xlab="1000 tilfældige danske mænds højde",yaxt='n')

```

Bemærk hvorledes personerne ligger meget tættere omkring middelværdien 180.4, her er figuren næsten sort. Vi kan se at der er forskellige meget høje og lave personer i de 3 stikprøver. Vi kan indtegne fordelingen af alle danske mænds højder, som en normalfordelings tæthedsfunktion. Når observationerne ligger tættere vil kurven være højere.

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
x <- seq(140,220,length.out=200)
y <- dnorm(x,180.7,7.42)
plot(x,y,type="l",main = "Fordelingen af mænds højde",xlim=c(140,220),cex.main=1,cex.axis=0.7,cex.lab=0.7,xlab="Højde danske mænd cm.",ylab="Tæthed")
```

<img src="img/popcorn.png" align="right" width="40%" height="40%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

IQ, Popcorn poptider, nedbør, vandstand etc. er normalfordelte fænomener. Tæthedsfunktionen for normalfordelingen er givet ved:

$$ f\left( x, \mu, \sigma \right) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^ { - \frac {\left( x - \mu \right)^2} {2 \sigma^2} }$$



Grafen nedenfor viser 3 normalfordelinger alle med middelværdi $\mu=0$ og standardafvigelser $\sigma$ på hhv. 1, 2 and 4.


```{r 3Normalfordelingersd3, echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
X1<-seq(-6,6,length=200)
Y1<-dnorm(X1)
Y2<-dnorm(X1, sd=2)
Y3<-dnorm(X1, sd=4)
plot(X1,Y1, xlim=c(-5,5), type="l", col="lightgrey", lty=1,lwd=4, xlab="x", ylab="Sandsynligheds tæthed",main="3 Normalfordelinger middel 0, sd=1,2,3")
points(X1, Y2, type="l", lty=2, col="darkgrey", lwd=4)
points(X1, Y3, type="l", lty=3, col="black", lwd=4)
legend("topright", legend=c("sd=1","sd=2","sd=3"), col=c("lightgrey", "darkgrey", "black") ,lty=c(1,2,3), lwd=4)
```


Grafen nedenfor viser 3 normalfordelinger med middelværdier $\mu$ på hhv. -1, 0, 4 alle med standardafvigelse $\sigma=1$.

```{r 3Normalfordelinger-1_0_4,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
X1<-seq(-6,10,length=200)
Y1<-dnorm(X1,mean=-1)
Y2<-dnorm(X1, mean=0)
Y3<-dnorm(X1, mean=4)
plot(X1,Y1, xlim=c(-5,10), type="l", lty=1, col="lightgrey", lwd=4, xlab="x", ylab="Sandsynligeheds tæthed",main="3 Normalfordelinger middel=-1,0,4 sd=1")
points(X1, Y2, type="l", lty=2, col="darkgrey", lwd=4)
points(X1, Y3, type="l", lty=3, col="black", lwd=4)
legend("topright", legend=c("Middel=-1","Middel=0","Middel=4"), col=c("lightgrey", "darkgrey", "black"),lty=c(1,2,3), lwd=4)
```

  
Middelværdi, median og modus/typetal er altid identisk for normalfordelingen, skævhed og kurtosis er 0.




## Normalfordelt Stokastisk variabel

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337765' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>  

En stokastisk variabel X inden for sandsynlighedsregning, er en variabel hvis værdi påvirkes af tilfældigheder. Når der er tilknyttet et sandsynlighedsmål, kan vi måle sandsynligheden for forskellige udfald. 

Hvis sandsynlighedsmålet fx. er normalfordelt skriver vi $X\sim N(\mu,\sigma)$. Vi kan så beregne sandsynligheder for at X antager forskellige værdier. 
Ønsker vi at bestemme sandsynligheden for at at få et udfald mindre end fx 3, skriver vi dette som $P(X<3)$, hvor P står for probability sandsynligheden. Vi skriver altid stort P, lille p betyder proportion andel indenfor statistik.  Skal vi bestemme sandsynligheden for at X antager en værdi mellem 3 og 5, skriver vi dette som $P(3 < X < 5)$.

Ser vi på eksemplet med danske mænds højde, kan vi definere en normalfordelt stokastisk variabel $X\sim N(\mu=180.4,\sigma=7.42)$. Skal vi bestemme sandsynligheden for at en person er lavere end 178 cm, skriver vi dette som $P(X<178)$. Vi kan beregne sandsynligheder i det meste software. I Excel ville vi beregne $P(X<178)=0.37$, ved hjælp af formlen =NORMAL.FORDELING(178;180,4;7,42;1). 

### Standard normalfordelingen
Der findes en særlig kendt normalfordeling, kaldet standard normalfordelingen, denne har parametrene $\mu=0$ og $\sigma=1$, hvilket altså betyder den har middel, median og modus 0 og standardafvigelse 1. Standard normalfordelingen ses i figuren herunder. 

```{r stdnormal,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
#z <- seq(-3,1,length.out=200)
plot(x,y,type="l",main = "Standard Normalfordelingen",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
#polygon(c(-3,z,-1),c(0,dnorm(z),0),col="grey90",border="NA")
#text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
#text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
#text(x=0,y=.1,"68%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
#text(x=-1.7,y=0.03,label="16%",cex = .7)
#text(x=1.7,y=0.03,label="16%",cex = .7)
#segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
# arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-2.56,-1.64,-1,1,1.64,2.56,5),cex.axis=0.6)
grid()
```

Ligesom for andre fordelinger, kan vi beregne fraktiler for alle normalfordelinger, vi kan således beregne fx. 5% fraktilen -1.64 for standard normalfordelingen. Dette betyder at der er 5% sandsynlighed for at få værdier mindre end -1.64 og således 95% sandsynlighed for at få værdier der er større end -1.64, dette er illustreret i figuren.
```{r 5fraktil,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-5,-1.64,length.out=200)
plot(x,y,type="l",main = "Standard Normalfordelingen 5% fraktilen",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-5,z,-1.64),c(0,dnorm(z),0),col="grey90",border="NA")
text(x=-3.5,y=0.12,"\n5% af \nsandsynlighedsmassen\n er markeret med\ngråt",cex = 0.9)
#text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
#text(x=0,y=.1,"68%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-2,y=0.023,label="5%",cex = .9)
text(x=-1.64,y=0.23,label="-1.64\n5% fraktilen",cex = .9)
segments( -1.64,  0,  -1.64 , 0.2,lty=1,lwd=1.5)
arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-2.56,-1.64,-1,1,1.64,2.56,5),cex.axis=0.6)
grid()
```

På grund af symmetrien for normalfordelingen, og da standardnormalfordelingen har middel 0 bliver 95% fraktilen bliver 1.64. Denne er vist i figuren herunder. Der gælder at hvis en vilkårlig $\alpha$%-fraktil for standard normalfordelingen er $-a$, bliver $1-\alpha$%-fraktilen $a$.
```{r 95fraktil,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-5,1.64,length.out=200)
plot(x,y,type="l",main = "Standard Normalfordelingen 95% fraktilen",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-5,z,1.64),c(0,dnorm(z),0),col="grey90",border="NA")
text(x=-3.5,y=0.12,"\n95% af \nsandsynlighedsmassen\n er markeret med\ngråt",cex = 0.9)
#text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
#text(x=0,y=.1,"68%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=0,y=0.23,label="95%",cex = 0.9)
text(x=1.64,y=0.23,label="1.64\n95% fraktilen",cex = .9)
segments( 1.64,  0,  1.64 , 0.2,lty=1,lwd=1.5)
arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-2.56,-1.64,-1,1,1.64,2.56,5),cex.axis=0.6)
grid()
```
  
### 68% Normalfordelingen

Hvis man trækker 1 gange standardafvigelsen $\sigma$ fra $\mu$ og lægger 1 gange standardafvigelsen til $\mu$, får man for en vilkårlig normalfordeling altid 68.27% af sandsynlighedsmassen. Denne egenskab er illustreret for standard normalfordelingen nedenfor, arealet er markeret med mørkegråt, dermed har man naturligvis 15.87% i hver hale da arealet under tæthedfunktionen er 1 eller 100%.

$$P(\mu-1\cdot \sigma \leq X \leq \mu+1\cdot \sigma) \approx 0.68$$



```{r 68label,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-1,1,length.out=200)
plot(x,y,type="l",main = "Standard Normalfordelingen 68%",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-1,z,1),c(0,dnorm(z),0),col="grey90",border="NA")
# text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
# text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=0,y=.1,"68%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-1.7,y=0.03,label="16%",cex = .7)
text(x=1.7,y=0.03,label="16%",cex = .7)
#segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
# arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-2.56,-1.96,-1,1,1.96,2.56,5),cex.axis=0.7)
grid()
```

### 90% Normalfordelingen

Hvis man trækker 1.6448 gange standardafvigelsen $\sigma$ fra $\mu$ og lægger 1.6448 gange standardafvigelsen til $\mu$, får man i normalfordelingen altid 90% af sandsynlighedsmassen.

$$P(\mu-1.64\cdot \sigma \leq X \leq \mu+1.64\cdot \sigma) \approx 0.9$$

```{r 90,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-1.64,1.64,length.out=200)
plot(x,y,type="l",main = "Standard Normalfordelingen 90%",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-1.64,z,1.64),c(0,dnorm(z),0),col="grey90",border="NA")
# text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
# text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=0,y=.1,"90%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-1.7,y=0.03,label="5%",cex = .7)
text(x=1.7,y=0.03,label="5%",cex = .7)
#segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
# arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-2.56,-1.96,-1.64,1,1,1.64,1.96,2.56,5),cex.axis=0.7)
grid()
```


### 95% Normalfordelingen

Hvis man trækker 1.96 gange standardafvigelsen $\sigma$ fra $\mu$ og lægger 1.96 gange standardafvigelsen til $\mu$, får man i normalfordelingen altid 95% af sandsynlighedsmassen. Denne z-score 0.975 fraktilen i standard normalfordelingen, er meget vigtig, vi bruger den fx. når vi beregner 95% konfidensinterval for middelværdien. Vi har alså følgende resultat:

$$P(\mu-1.96\cdot \sigma \leq X \leq \mu+1.96\cdot \sigma)\approx 0.95$$


```{r 95,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-1.96,1.96,length.out=200)
plot(x,y,type="l",main = "Standard Normalfordelingen 95%",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-1.96,z,1.96),c(0,dnorm(z),0),col="grey90",border="NA")
# text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
# text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=0,y=.1,"95%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-2.1,y=0.03,label="2.5%",cex = .7)
text(x=2.1,y=0.03,label="2.5%",cex = .7)
#segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
# arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-2.56,-1.96,-1.64,1,1,1.64,1.96,2.56,5),cex.axis=0.7)
grid()
```

### 99% Normalfordelingen
Hvis man trækker 2.5758 gange standardafvigelsen $\sigma$ fra $\mu$ og lægger 2.5758 gange standardafvigelsen til $\mu$, får man i normalfordelingen altid 99% af sandsynlighedsmassen. Vi illustrerer igen for standard normalfordelingen, men resultatet er ækvivalent for samtlige normalfordelinger.  

$$P(\mu-2.58\cdot \sigma \leq X \leq \mu+2.58\cdot \sigma)\approx 0.99$$

```{r 99,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-2.56,2.56,length.out=200)
plot(x,y,type="l",main = "Standard Normalfordelingen 99%",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-2.56,z,2.56),c(0,dnorm(z),0),col="grey90",border="NA")
# text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
# text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=0,y=.1,"99%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-3.4,y=0.06,label="0.5%",cex = .7)
text(x=3.4,y=0.06,label="0.5%",cex = .7)
#segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-2.56,-1.96,-1.64,1,1,1.64,1.96,2.56,5),cex.axis=0.7)
grid()
```

### Addition af normalfordelinger
Der er en lang række gode egenskaber for normalfordelinger, der gør disse fordelinger særlig nemme at arbejde med.
Hvis man har n uafhængige stokastiske normalfordelte variable $X_1\sim N(\mu_1,\sigma^2_1),X_2\sim N(\mu_2,\sigma^2_2)...X_n\sim N(\mu_n,\sigma^2_n)$, så er deres sum Z også normalfordelt med parametrene
$Z\sim N(\mu_1+\mu_2...+\mu_n,\sigma^2_1+\sigma^2_2+..+\sigma^2_n)$
Middelværdien er altså summen af middelværdierne, variansen er summen af varianserne. Husk der er tale om summen af varianserne ikke standardafvigelserne.

Hvis man fx. har en investering med fremtidige tilbagediskonterede cashflows 4, 2 og 3 fra tidspunkt 1, 2 og 3, hvor der er en usikkerhed på de tilbagediskonterede fremtidige cashflows beskrevet ved variansen for de 3 cashflows 2, 3, 4. Vi antager de fremtidige tilbagediskonterede cashflows er normalfordelte, hvor den forventede værdi for tilbagediskonterede cashflows er middelværdierne og usikkerheden for betalingsstrømmene beskrives ved variansen. Dette giver god mening, jo længere ude i fremtiden, des større usikkerhed dvs. varians.
$X_1\sim N(\mu =4,\sigma^2=2)$
$X_2\sim N(\mu =2,\sigma^2=3)$
$X_3\sim N(\mu =3,\sigma^2=4)$
Det betyder summen af de tilbagediskonterede cashflows er normalfordelt med parametrene
$X_{cashflow}\sim N(\mu =4+2+3=9,\sigma^2=2+3+4=9)$ 
Man kan således bruge reglen om addition af normalfordelinger, til at få et overblik over det samlede forventede tilbagediskonterede cashflow og usikkerheden.

### Linearkombinationer af normalfordelinger
Vi kan sammensætte n normalfordelte variable $X_1\sim N(\mu_1,\sigma^2_1),X_2\sim N(\mu_2,\sigma^2_2)...X_n\sim N(\mu_n,\sigma^2_n)$ med en vektor af af n reelle tal $(a_1,a_2,..a_n)$ samt en konstant b, denne linearkombinationen Y også normalfordelt med parametrene
$Y\sim N(a_1 \cdot \mu_1+a_2 \cdot \mu_2...+a_n \cdot \mu_n+b,a_1^2 \cdot \sigma^2_1+a_2^2 \cdot \sigma^2_2+..+a_n^2 \cdot \sigma^2_n)$

Betragter man fx 3 aktiver, der kan beskrives ved normalfordelinger, med forventet afkast $\mu_1=120, \mu_2=100\ og\  \mu_3=150$ og usikkerhed $\sigma^2_1=3, \sigma^2_3=9\ og\  \sigma^2_3=4$, samt et risikofrit aktiv med afkast 100. Har man en portefølje der indholder hhv. 3, 2, 4 enheder af aktiver 1, 2 og 3 samt 1 risikofrit aktiv. Kan det forventede afkast af den samlede portefølje beskrives ved en normalfordelt stokastisk variabel med parametrene:
$$X_{portefø\ lje}\sim N(a_1 \cdot \mu_1+a_2 \cdot \mu_2...+a_n \cdot \mu_n+b,a_1^2 \cdot \sigma^2_1+a_2^2 \cdot \sigma^2_2+..+a_n^2 \cdot \sigma^2_n)=$$
$$X_{portefø\ lje}\sim N(\mu=3 \cdot 120+2 \cdot 100+4 \cdot 150+100=1260,\sigma^2=3^2 \cdot 3+2^2 \cdot 9+4^2 \cdot 4=127)$$  

### Transformation af normalfordelinger 

En anden god egenskab ved normalfordelinger, er at de kan transformeres til standardnormalfordelingen, dette gør det nemmere at beregne sandsynligheder hvis man ikke har software til at udregne disse.

$$X\sim N(\mu,\sigma^2)\rightarrow\ Z=\frac{X-\mu}{\sigma}\sim N(\mu=0,\sigma^2=1)$$
Vi kan nu beregne sandsynligheder for at den oprindelige normalfordelte variabel er mindre end a $P(X<a)$, ved hjælp af standard normalfordelingen $P(Z<\frac{a-\mu}{\sigma})$.

Hvis vi ser på investeringen ovenfor $X_{cashflow}\sim N(\mu =9,\sigma^2=9)$ kan vi transformere $X_{cashflow}$ til standard normalfordelingen.

$$X_{cashflow}\sim N(\mu =9,\sigma^2=9)\rightarrow\ Z=\frac{X-9}{3}\sim N(\mu=0,\sigma^2=1)$$
Vi kan bestemme, hvor stor sandsynligheden er, for at de fremtidige diskonterede cashflows er negative vha. standardnormalfordelingen dvs.
$$P(X_{cashflow}<0)= P(Z<\frac{0-9}{3}=-3)=0135\%$$ 
Nedenfor ses begge fordelinger med 0.00135 fraktilen.
```{r port,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-3,21,length.out=200)
y <- dnorm(x,9,3)
z <- seq(-3,0,length.out=200)
plot(x,y,type="l",main = "Normalfordelingen med middel 9 og standardafvigelse 3 0.00135 fraktilen",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-3,z,0),c(0,dnorm(z,9,3),0),col="grey90",border="NA")
text(x=0,y=0.06,"\nPorteføljeafkast 0",cex = 0.9)
#text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
#text(x=0,y=.1,"68%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-1.5,y=0.025,label="Sandsynligheden for\n et negativt\n afkast er 0.00135",cex = .9)
segments( 0,  0,  -0 , 0.05,lty=1,lwd=1.5)
arrows( -1, 0.01,-0.5, 0.001,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(0,3,6,9,12,15,18),cex.axis=0.6)
grid()
```

```{r port2,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x,0,1)
z <- seq(-5,-3,length.out=200)
plot(x,y,type="l",main = "Standard normalfordelingen 0.00135 fraktilen",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-5,z,-3),c(0,dnorm(z),0),col="grey90",border="NA")
text(x=-3,y=0.22,"\nPorteføljeafkast 0",cex = 0.9)
#text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
#text(x=0,y=.1,"68%",cex = 1)
#text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-4,y=0.06,label="Sandsynligheden for\n et negativt\n afkast er 0.00135",cex = .9)
segments( -3,  0,  -3 , 0.2,lty=1,lwd=1.5)
arrows( -3.5, 0.01,-3.2, 0.001,length=0.05,angle = 15)
# arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-3,0,3,5),cex.axis=0.6)
grid()
```



## Normalfraktildiagram

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337668' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

Hvis vi har mindre stikprøver, skal vi sikre os at data stammer fra normalfordelte populationer. Dette kan vi gøre vha. normalfraktildiagrammer, disse skal ligge pænt omkring den rette linje. Har man en lille stikprøve og ønsker at sikre sig data stammer fra en normalfordelt population, kan man i Freestat indsætte stikprøven i 1 kvantitativ stikprøve og sikre sig at punkterne ligger pænt omkring den rette linje. En stikprøve er lille, når den er mindre end 30 observationer. Det kan ofte være svært at se om data stammer en normalfordeling. Som det fremgår af nedenstående normalfraktildiagrammer er kun 4 af de 18 normalfordelte, specielt ved de mindre stikprøver er det svært at se præcis om data er normalfordelte. Man kan generelt sige at afvigelser fra den rette linje i enderne, er mindre kritiske en afvigelser omkring midten. Hvis man i forbindelse med analyse fx. konfidensinterval eller hypotesetest, konstaterer data ikke er normalfordelte, bør man bemærke dette og illustrere vha. normalfraktildiagrammet. Når man har rapporteret problemet gennemfører man herefter analysen. 

```{r,echo=FALSE,message=FALSE}
list.of.packages <- c("gridExtra", "exams")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library("gridExtra")
library("exams")
library("gridExtra")
```



```{r qqplots15_25label, echo=FALSE ,fig.width=9, fig.height=9, dev='svg'}


qqplot.data <- function (vec) # argument: vector of numbers
{
  # following four lines from base R's qqline()
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x <- qnorm(c(0.25, 0.75))
  slope <- diff(y)/diff(x)
  int <- y[1L] - slope * x[1L]
  d <- data.frame(resids = vec)
  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope, intercept = int)

}

qq1 <- qqplot.data(rnorm(15))+ labs(title = "Normalfordelte data\n15 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq2 <- qqplot.data(runif(15))+ labs(title = "Uniformt fordelte data\n15 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq3 <- qqplot.data(rchisq(15,4))+ labs(title = "Chi i anden df 4 fordelte data\n15 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq4 <- qqplot.data(rbeta(15,8,2))+ labs(title = "Beta(5,3) fordelte data\n15 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq5 <- qqplot.data(rexp(15))+ labs(title = "Eksponential fordelte data\n15 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq6 <- qqplot.data(rnorm(25))+ labs(title = "Normalfordelte data\n25 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq7 <- qqplot.data(runif(25))+ labs(title = "Uniformt fordelte data\n25 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq8 <- qqplot.data(rchisq(25,4))+ labs(title = "Chi i anden df 4 fordelte data\n25 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq9 <- qqplot.data(rexp(25,3))+ labs(title = "Eksponential fordelte data\n25 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")

grid.arrange(qq1,qq2,qq3,qq4,qq5,qq6,qq7,qq8,qq9,nrow=3, ncol=3)
```

```{r qqplots100_500, echo=FALSE ,fig.width=9, fig.height=9, dev='svg'}


qq1 <- qqplot.data(rnorm(100))+ labs(title = "Normalfordelte data\n100 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq2 <- qqplot.data(runif(100))+ labs(title = "Uniformt fordelte data\n100 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq3 <- qqplot.data(rchisq(100,4))+ labs(title = "Chi i anden df 4 fordelte data\n100 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq4 <- qqplot.data(rbeta(100,8,2))+ labs(title = "Beta(8,2) fordelte data\n100 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq5 <- qqplot.data(rexp(100))+ labs(title = "Eksponential fordelte data\n100 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq6 <- qqplot.data(rnorm(500))+ labs(title = "Normalfordelte data\n500 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq7 <- qqplot.data(runif(500))+ labs(title = "Uniformt fordelte data\n500 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq8 <- qqplot.data(rchisq(500,4))+ labs(title = "Chi i anden df 4 fordelte data\n500 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq9 <- qqplot.data(rexp(500,3))+ labs(title = "Eksponential fordelte data\n500 observationer",x="teoretiske fraktiler",y="Stikprøve fraktiler")

grid.arrange(qq1,qq2,qq3,qq4,qq5,qq6,qq7,qq8,qq9,nrow=3, ncol=3)

```


## Parametre og parameter-estimater

#### Stikprøvefordelingen

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337553' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>



#### Stikprøvefordelingen 2
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337520' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
#### Parameter-estimat
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337632' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>



Når man indsamler en stikprøve fx 100 studerendes højde, kan vi bruge denne stikprøve til at sige noget om alle studerendes højde. I dette tilfælde er alle studerende, det vi kalder populationen, det er dem vi ønsker at vide noget om. Den gennemsnitlige højde i populationen er den ukendte parameter $\mu$. Den gennemsnitlige højde på de studerende i stikprøven kalder vi parameterestimatet, estimatet betyder vores gæt på den ukendte sande gennemsnitlige højde på alle studerende, altså parameteren $\mu$. Vi bruger betegnelsen $\hat{\mu}$, når vi taler om paramterestimater, så vores gæt angiver vi  med en hat $\hat{}$. Da paramterestimatet er et gæt, er vi interesserede i kvaliteten af vort gæt. Vi ser nedenfor på stikprøvefordelingen, som vi kan bruge til at måle præcision af estimatet ved hjælp af konfidensintervaller.



### Parameter-estimat for middelværdi
 Hvis vi ønsker at udtale os om det gennemsnitlige daglige afkast af Tryg aktien den sande middelværdi $\mu$, kan vi estimere det gennemsnitlige afkast i populationen, ved gennemsnittet i stikprøven $\bar{x}$.


$$\hat{\mu}=\bar{x}=\frac{\sum_1^n (x_i)}{n}=\frac{`r sum(DKdf[,1])`}{`r length(DKdf[,1])`}=`r round(mean(DKdf[,1]),4)`$$




### Parameter-estimat for standardafvigelsen
Vi har nævnt at standardafvigelsen af afkastet, er en vigtig faktor, når en investor skal bestemme volatiliteten i en aktie. Vi kan estimere den sande standardafvigelse i populationen $\sigma$, ud fra estimatet af standardafvigelsen $\hat{\sigma}$ vha. stikprøven. For Tryg aktien regnes dette ud som:

$$Parameteren\  \sigma\  estimeres\ ved\ \hat{\sigma}=S=\sqrt[]{\frac{\sum_1^n (x_i-\bar{x})^2}{n-1}}=\sqrt[]{\frac{`r round(sum((DKdf[,1]-mean(DKdf[,1]))^2),4)`}{`r length(DKdf[,1])`-1}}=`r round(sd(DKdf[,1]),2) `$$



Nedenfor er en oversigt over vigtige parametre samt deres estimater. Vi er udover estimatet interesseret i, hvor sikre vi er på dette estimat, her er det vi vil benytte konfidensintervaller.

Parameter       | Estimat                       |Beregning af estimatet
-------------   | ------------                  |------------
$Andelen\ p$             | $\hat{p}$                     | $\hat{p}=\frac{x}{n}=\frac{antal\ succeser}{antal\ trials}$
$Middel\ \mu$           | $\hat{\mu}$                   | $\hat{\mu}=\bar{x}=\frac{\sum_1^n (x_i)}{n}$
$Variansen\ \sigma^2$        | $\hat{\sigma}^2\ eller \ s^2$     | $s^2=\frac{\sum_1^n (x_i-\bar{x})^2}{n-1}$
$Spredningen\ \sigma$        | $\hat{\sigma}\ eller \ s$     | $s=\sqrt[]{\frac{\sum_1^n (x_i-\bar{x})^2}{n-1}}$

### Data- stikprøve- og populationsfordelingen
Vi sondrer mellem flere forskellige typer af fordelinger.

* Populations fordelingen af størrelse N. Denne er ikke kendt, men vi ønsker at drage slutninger om fordelingen, baseret på en stikprøve.  

* Datafordeligen er fordelingen af den stikprøve af størrelse n, vi har indsamlet.

* Stikprøve fordelingen fremkommer, hvis man fra populationen, udtager alle stikprøver, af størrelse n. Fordelingen af parameter estimaterne kaldes stikprøve fordelingen.


<div class="Keatswide">
<img src="img/finanstilsynet.jpg" align="right" width="50%" height="50%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
Vi forestiller os nu at Finanstilsynet, ønsker at estimere det gennemsnitlige indestående på danskernes nem konti. Den ukendte populations parameter Finanstilsynet er interesseret er altså $\mu$. Her er populationen samtlige nem konti, hvis der er fx. er 3 mio konti er N altså 3 mio. Vi ved at der i populationen, vil være personer med meget store indståender på deres konti, nok flere mio. DKK. og nogle konti med negativt indestående. Sandsynligvis vil standard afvigelsen $\sigma$ være stor. Vi kan formode at fordelingen vil være højreskæv, i en eller anden grad, da der vil være enkelte ekstremt store indeståender der danner en lang hale mod højre.

Hvis vi simpelt tilfældigt udvælger en stikprøve på n=10000, vil gennemsnittet $\bar{x}$ (som jo er parameterestimatet $\hat{\mu}$) i stikprøven udviske outliers.

Hvis man udtog alle mulige stikprøver af populationen og beregnede samtlige gennemsnit, ville disse gennemsnit ligge ganske tæt omkring den sande parameter $\mu$. Denne sandsynlighedsfordeling af stikprøve gennemsnit er stikprøvefordelingen Vi kan med den centrale grænseværdisætning vise at stikprøvefordelingen vil være approximativt normal med middelværdi $\mu$ og standardafvigelse $\frac{\sigma}{\sqrt[]{10000}}$. Standardafvigelsen for stikprøvefordelingen vil være 100 gange mindre, end standardafvigelsen for  populationen. Bemærk havde stikprøven været på n=100 i stedet, ville standard afvigelsen for stikprøvefordelingen kun være $\sqrt[]{100}=10$ gange mindre end standard afvigelsen for populationen.
</div>

### Den centrale grænseværdisætning CLT
Den centrale grænseværdisætning CLT siger, at hvis man med tilbagelægning udtager tilstrækkeligt store stikprøver af størrelse n af en population, vil stikprøvefordelingen af middelværdien være approximativt normal. Er populationsfordelingen hverken symmetrisk eller mesokurtisk vil stikprøve fordelingen stadig være tilnærmelsesvist normal, når blot stikprøve størrelsen er tilstrækkelig stor (mange bøger sætter denne grænse ved 30). 

Nedenfor har vi en højreskæv populationsfordeling med $\mu=8$ og $\sigma=4$, dette er jo den sædvanligvis ukendte population, fra hvilken vi trækker en  stikprøve på størrelse n.

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
X1<-seq(0,30,length=200)
Y1<-dchisq(X1,8)

plot(X1,Y1,xlim=c(0,30), type="l",lty=1, col="black", lwd=2, xlab="Højreskæv population\n middelværdi 8, standardafvigelse 4", ylab="Sandsynligeheds tæthed",cex.lab=0.75,main="Population",cex.main=0.75)
```


Middelværdien for stikprøvefordelingen skrives i mange bøger med notationen $\mu_{\bar{X}}$ er:
$$\mu_{\bar{X}}=\mu$$

Standardafvigelsen for stikprøvefordelingen kaldes standardfejlen for middelværdien (engelsk standard error of the mean SEM eller SE)  $\sigma_{\bar{X}}$ er:

$$SEM=\sigma_{\bar{X}}=\frac{\sigma}{\sqrt[]{n}}$$

Vi bruger standardfejlen for middelværdien SEM til at beregne konfidensintervaller som vi ser på senere. Der gælder jo mindre SEM jo smallere konfidensinterval, og når stikprøvestørrelsen bliver større bliver SEM mindre. Det giver jo god mening, større stikprøve giver mindre SEM og dermed smallere konfidensinterval dvs. større præcision.

På figurerne er udtaget 3 gange 100 stikprøver af størrelse n hhv. 30, 100 og 1000. På hver figur er gennemsnittene af de 100 stikprøver angivet. Der er altså 100 pinde i hvert diagram. Bemærk CLT siger at for alle tre stikprøvefordelinger er $\mu=8$, det ses af figurerne at gennemsnittene i stikprøverne er centreret omkring middelværdien i populationen $\mu=8$.

Vi kan ligeledes se at variationen falder (stikprøvegennemsnittene ligger mere snævert), når stikprøvestørrelsen vokser.

```{r echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
#100 stikprøver n 10, 100, 1000 
par(mfrow=c(3,1)) 
s10 <- colMeans(matrix(rchisq(3000, 8),ncol=100))
s100 <- colMeans(matrix(rchisq(10000, 8),ncol=100))
s1000 <- colMeans(matrix(rchisq(100000, 8),ncol=100))
y <- rep(1,100)
plot(s10,y, xlim=c(4,12), type="h",lty=1, col="black", lwd=0.5, ylab="",xlab="Gennemsnit af de 100 stikprøver n=30",yaxt='n')
plot(s100,y, xlim=c(4,12), type="h",lty=1, col="black", lwd=0.5, ylab="",xlab="Gennemsnit af 100 stikprøver n=100",yaxt='n')
plot(s1000,y, xlim=c(4,12), type="h",lty=1, col="black", lwd=0.5, ylab="",xlab="Gennemsnit af de 100 stikprøver n=1000",yaxt='n')
```

På de 3 figurer nedenfor ses de tilsvarende stikprøvefordelinger.  

Når stikprøvestørrelsen er n=30, kan standard fejlen da $\sigma=4$ jvf. CLT udregnes til:

$$SEM=\sigma_{\bar{X}}=\frac{\sigma}{\sqrt[]{n}}=\frac{4}{\sqrt[]{30}}=`r round(4/30^0.5,2)`$$

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
xs<-seq(4,12,length=200)
y1<-dnorm(xs,mean = 8, sd = 4/30^0.5)
plot(xs,y1, xlim=c(4,12), type="l",lty=1, col="black", lwd=0.5, ylab="",xlab="x",main="Stikprøvefordelingen n=30 ",cex.main=0.75,cex.lab=0.75)
```

Når stikprøvestørrelsen er n=100, kan standard fejlen da $\sigma=4$ jvf. CLT udregnes til:

$$SEM=\sigma_{\bar{X}}=\frac{\sigma}{\sqrt[]{n}}=\frac{4}{\sqrt[]{100}}=`r round(4/100^0.5,2)`$$

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
xs<-seq(4,12,length=200)
y2<-dnorm(xs,mean = 8, sd = 4/100^0.5)
plot(xs,y2, xlim=c(4,12), type="l",lty=1, col="black", lwd=0.5,main="Stikprøvefordelingen n=100 ", ylab="",xlab="x",cex.main=0.75,cex.lab=0.75)
```

Når stikprøvestørrelsen er n=1000, kan standard fejlen da $\sigma=4$ jvf. CLT udregnes til:

$$SEM=\sigma_{\bar{X}}=\frac{\sigma}{\sqrt[]{n}}=\frac{4}{\sqrt[]{1000}}=`r round(4/1000^0.5,2)`$$


```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
xs<-seq(4,12,length=200)
y3<-dnorm(xs,mean = 8, sd = 4/1000^0.5)
plot(xs,y3, xlim=c(4,12), type="l",lty=1, col="black", lwd=0.5, ylab="",xlab="x",main="Stikprøvefordelingen n=1000 ",cex.main=0.75,cex.lab=0.75)
```

Da stikprøvefordelingerne er normalfordelte, ved vi at hvis man trækker 1.96 gange standard fejlen SEM $\frac{\sigma}{\sqrt[]{n}}$ fra middelværdien $\mu$ og lægger 1.96 gange SEM $\frac{\sigma}{\sqrt[]{n}}$ til middelværiden $\mu$, er der i hver hale 2.5% og imellem halerne 95% af sandsynligheden. Vi kan altså beregne følgende nedre og øvre intervalgrænser for de tre stikprøvefordelinger, jo større stikprøve jo smallere interval.

Vi udregner nedre intervalgrænse når n er 30 som:    

$\mu-1.96\cdot\frac{\sigma}{\sqrt[]{n}}=8-1.96\cdot\frac{4}{\sqrt[]{30}}=`r round(8-1.96*4/30^0.5,2)`$

Vi udregner øvre intervalgrænse når n er 30 som:     

$\mu+1.96\cdot\frac{\sigma}{\sqrt[]{n}}=8+1.96\cdot\frac{4}{\sqrt[]{30}}=`r round(8+1.96*4/30^0.5,2)`$

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
x <-seq(4,12,length=200)
x2 <-seq(8-1.96*4/30^0.5,8+1.96*4/30^0.5,length=200)
y1<-dnorm(x,mean = 8, sd = 4/30^0.5)
y2<-dnorm(x2,mean = 8, sd = 4/30^0.5)
plot(x,y1,type="l",bty="L",xlab="Middelværdi 8, SEM=0.73",ylab="",xlim=c(4,12),main="Stikprøvefordelingen n=30")
polygon(c(8-1.96*4/30^0.5,x2,8+1.96*4/30^0.5),c(0,y2,0),col="grey90")
text(8-1.96*4/30^0.5,0,round(8-1.96*4/30^0.5,2), cex = .8,srt = 90,pos = 4,offset=-0.5)
text(8+1.96*4/30^0.5,0,round(8+1.96*4/30^0.5,2), cex = .8,srt = 90,pos = 4,offset=0.7)
points(8-1.96*4/30^0.5,2, type="h",lty=1, col="red", lwd=1,yaxt='n')
points(8+1.96*4/30^0.5,2, type="h",lty=1, col="red", lwd=1,yaxt='n')
text(8,0.3,"95% af sandsynligheden", cex = 1)
arrows((8-1.96*4/30^0.5)*0.95-.4,0.2,(8-1.96*4/30^0.5)*0.98-.4,0.05,length = 0.05)
arrows((8+1.96*4/30^0.5)*1.038+.4,0.2,(8+1.96*4/30^0.5)*1.013+.4,0.05,length = 0.05)
text((8-1.96*4/30^0.5)*0.95-.4,0.2,"2.5%",pos=2,cex=.8)
text((8+1.96*4/30^0.5)*1.038+.4,0.2,"2.5%",pos=4,cex=.8)
```

Vi udregner nedre intervalgrænse når n er 100 som:    

$\mu-1.96\cdot\frac{\sigma}{\sqrt[]{n}}=8-1.96\cdot\frac{4}{\sqrt[]{100}}=`r round(8-1.96*4/100^0.5,2)`$

Vi udregner øvre intervalgrænse når n er 100 som:     

$\mu+1.96\cdot\frac{\sigma}{\sqrt[]{n}}=8+1.96\cdot\frac{4}{\sqrt[]{100}}=`r round(8+1.96*4/100^0.5,2)`$

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
x <-seq(4,12,length=200)
x2 <-seq(8-1.96*4/100^0.5,8+1.96*4/100^0.5,length=200)
y1<-dnorm(x,mean = 8, sd = 4/100^0.5)
y2<-dnorm(x2,mean = 8, sd = 4/100^0.5)
plot(x,y1,type="l",bty="L",xlab="Middelværdi 8, SEM=0.4",ylab="",xlim=c(4,12),main="Stikprøvefordelingen n=100")
polygon(c(8-1.96*4/100^0.5,x2,8+1.96*4/100^0.5),c(0,y2,0),col="grey90")
text(8-1.96*4/100^0.5,0,round(8-1.96*4/100^0.5,2), cex = .8,srt = 90,pos = 4,offset=-0.5)
text(8+1.96*4/100^0.5,0,round(8+1.96*4/100^0.5,2), cex = .8,srt = 90,pos = 4,offset=0.7)
points(8-1.96*4/100^0.5,2, type="h",lty=1, col="red", lwd=1,yaxt='n')
points(8+1.96*4/100^0.5,2, type="h",lty=1, col="red", lwd=1,yaxt='n')
text(8,0.3,"95%", cex = 1)
arrows((8-1.96*4/100^0.5)*0.95-.4,0.2,(8-1.96*4/100^0.5)*0.98-.4,0.05,length = 0.05)
arrows((8+1.96*4/100^0.5)*1.038+.4,0.2,(8+1.96*4/100^0.5)*1.013+.4,0.05,length = 0.05)
text((8-1.96*4/100^0.5)*0.95-.4,0.2,"2.5%",pos=2,cex=.8)
text((8+1.96*4/100^0.5)*1.038+.4,0.2,"2.5%",pos=4,cex=.8)
```

Vi udregner nedre intervalgrænse når n er 1000 som:    

$\mu-1.96\cdot\frac{\sigma}{\sqrt[]{n}}=8-1.96\cdot\frac{4}{\sqrt[]{1000}}=`r round(8-1.96*4/1000^0.5,2)`$

Vi udregner øvre intervalgrænse når n er 1000 som:     

$\mu+1.96\cdot\frac{\sigma}{\sqrt[]{n}}=8+1.96\cdot\frac{4}{\sqrt[]{1000}}=`r round(8+1.96*4/1000^0.5,2)`$


```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
x <-seq(4,12,length=200)
x2 <-seq(8-1.96*4/1000^0.5,8+1.96*4/1000^0.5,length=200)
y1<-dnorm(x,mean = 8, sd = 4/1000^0.5)
y2<-dnorm(x2,mean = 8, sd = 4/1000^0.5)
plot(x,y1,type="l",bty="L",xlab="Middelværdi 8, SEM=0.4",ylab="",xlim=c(4,12),main="Stikprøvefordelingen n=1000")
polygon(c(8-1.96*4/1000^0.5,x2,8+1.96*4/1000^0.5),c(0,y2,0),col="grey90")
text(8-1.96*4/1000^0.5,0,round(8-1.96*4/1000^0.5,2), cex = .8,srt = 90,pos = 4,offset=-0.5)
text(8+1.96*4/1000^0.5,0,round(8+1.96*4/1000^0.5,2), cex = .8,srt = 90,pos = 4,offset=0.7)
points(8-1.96*4/1000^0.5,2, type="h",lty=1, col="red", lwd=1,yaxt='n')
points(8+1.96*4/1000^0.5,2, type="h",lty=1, col="red", lwd=1,yaxt='n')
text(8,0.3,"95%", cex = 1)
arrows((8-1.96*4/1000^0.5)*0.95-.2,0.2,(8-1.96*4/1000^0.5)*0.98-.2,0.05,length = 0.05)
arrows((8+1.96*4/1000^0.5)*1.038+.2,0.2,(8+1.96*4/1000^0.5)*1.013+.2,0.05,length = 0.05)
text((8-1.96*4/1000^0.5)*0.95-.2,0.2,"2.5%",pos=2,cex=.8)
text((8+1.96*4/1000^0.5)*1.038+.2,0.2,"2.5%",pos=4,cex=.8)
```


## Frihedsgrader
Frihedsgrader eller degrees of freedom df betyder, hvor mange observationer kan variere frit. Hvis man fx. har en stikprøve med 4 observationer ${1,2,2,3}$ og ønsker at estimere (gætte på) gennemsnittet i populationen $\mu$, så bliver vores bedste estimat for (gæt på) gennemsnittet $\hat{\mu}=\bar{x}=\frac{1+2+2+3}{4}=\frac{8}{4}=2$. Her er antallet af observationer, der kan variere frit, når gennemsnittet $\bar{x}=2$ er givet $4-1=3$, hvilket er antallet af frihedsgrader. Hvis de 3 første observationer er ${1,2,2}$, vil den sidste observation være givet som 3, for at gennemsnittet bliver 2. Havde vi haft de 3 første observationer var ${1,1,1}$ ville den sidste observation være givet som 5 for at gennemsnittet var 2. Ved 4 observationer, er der således $4-1=3$ frihedsgrader, ved 10 observationer, er der således $10-1=9$ frihedsgrader osv. Antallet af frihedsgrader når vi estimerer middelværdien, svarer til antallet af observationer i stikprøven n minus 1.


## t-fordelingen

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337473' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

Useendet af t-fordelinger bestemmes af parameteren antal frihedsgrader. Samtlige t-fordelinger har middelværdi $\mu=0$ og approximerer/tilnærmer sig standard normalfordelingen, når antallet af frihedsgrader vokser. Vi benytter populært sagt t-fordelinger i stedet for z-fordelinger, når populations variansen $\sigma^2$ er ukendt. Antallet af frihedsgrader for t-fordelingen, ved konfidensinterval for middelværdi, svarer til antallet af observationer i stikprøven n minus 1.

I figuren er indtegnet 3 t-fordelinger med hhv. 5, 10 og 100 frihedsgrader (df degrees of fredom). Vi kan se fordelingerne har tykkere haler end normalfordelingen og når antallet at frihedsgrader er 100 ser z- og t-fordelingen næsten identiske ud.  

```{r zogtfordelinger,echo=FALSE,fig.width=9, fig.height=7, dev='svg'}
X1<-seq(-6,6,length=200)
Y1<-dnorm(X1)
Y2<-dt(X1,df=5)
Y3<-dt(X1, df=10)
Y4<-dt(X1, df=100)
plot(X1,Y1, xlim=c(-3,3), type="l",lty=3, col="black", lwd=4, xlab="x", ylab="Sandsynligeheds tæthed",main="z-fordelingen samt\n3 t-fordelinger df=5,10,100")
points(X1, Y2, type="l", col="orange", lwd=2)
points(X1, Y3, type="l", col="lightblue", lwd=2)
points(X1, Y4, type="l", col="red", lwd=2)
legend("topright", legend=c("z-fordelingen","t-fordelingen df 5","t-fordelingen df 10","t-fordelingen df 100"), col=c("black", "orange", "lightblue","red"),text.col=c("black", "orange", "lightblue","red"), lwd=4,lty=c(3,1,1,1))
```


```{r echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
# data = data.frame(x=seq(-3,3,length.out=1000))
# data$y=dnorm(data$x)
# data$Quantile <- with(data,ifelse(x<qnorm(0.25),"1. Quantile",
#                                ifelse(x<qnorm(0.5),"Median",
#                                       ifelse(x<qnorm(0.75),"3. Quantile",
#                                              ifelse(x<qnorm(0.975),"Fourth","Top")))))
# data$Quantile <- factor(data$Quantile, levels=c("Bottom","Second","Middle","Fourth","Top"))
# 
# ggplot(data,aes(x=x,y=y,fill=Quantile))+geom_ribbon(aes(ymax=y),ymin=0,alpha=0.5)+
#   geom_line(color="black")+theme_bw()+theme(legend.position="bottom")+
#   scale_fill_manual(values=c("darkgreen","red","purple","blue","gray"))+
#   geom_vline(xintercept=c(qnorm(c(0.25,0.5,0.75,.975))),color=c("darkgreen","red","purple","blue"),size=1)+
#   scale_y_continuous("",breaks=NULL)+scale_x_continuous("",breaks=NULL)
```

# Konfidensintervaller





<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->






<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337810' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

  
<br>
  
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/257603202' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


Konfidensintervallet også kaldet KI eller CI (engelsk), fortæller os, baseret på en simpelt tilfældigt udvalgt stikprøve, med en bestemt konfidens- eller sikkerhed, indenfor hvilken nedre og øvre grænse, en populationsparameter ligger.  

Vi taler om et 95% konfidensniveau, det betyder at i 19 ud af 20 simpelt tilfældigt udtrukne stikprøver af samme størrelse, ligger populationsparameteren i konfidensintervallet (populationsparameteren kan fx. være andelen, middelværdien eller standardafvigelsen i populationen). Sandsynligheden for at populationens parameter, ikke ligger i konfidensintervallet er 5%, dette kalder vi signifikansniveauet og betegner med $\alpha$. I 1 ud af 20 simpelt tilfældigt udtrukne stikprøver af samme størrelse, ligger populationsparameteren, altså ikke i vores konfidensinterval. Typiske konfidensniveauer er 90%, 95% og 99%, med tilhørende signifikansniveauer på 10%, 5% og 1%, disse må nødvendigvis summere til 1 eller 100%.

### Konfidensinterval for middelværdien
Vi bestemmer nedre og øvre grænse for konfidensintervallet, når vi ikke kender populationens standardafvigelse $\sigma$ og estimerer denne vha. S altså $\hat{\sigma}$, ved hjælp af følgende (bliv ikke bange software beregner grænserne for os) formel:

$$(1-\alpha)\ KI=\left[\bar{X} - t_{1-\frac{\alpha}{2}}\cdot \frac{s}{\sqrt[]{n}};\bar{X} + t_{1-\frac{\alpha}{2}}\cdot \frac{S}{\sqrt[]{n}}\right]$$

Hvor $t_{1-\frac{\alpha}{2}}$ er $1-\alpha$ fraktilen for t-fordelingen. En forudsætning for at benytte ovennævnte fordeling, ved små stikprøver (n ca. mindre end 30), er at populationen er appoximativt (tilnærmelsesvist) normalfordelt. Man kan fx. teste normaliteten af populationen, ved at undersøge om observationerne fra stikprøven ligger pænt i et normalfraktildiagram. Er populationen ikke normal, kan man altså benytte en større stikprøve.

<img src="img/crop-realty-graph-diagram.jpg" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>



En ejendomsmægler, der ønsker at vide, hvor langt kunderne har til nærmeste filial, indsamler en repræsentativ
stikprøve ved 200 respondender. Det viser sig, at den gennemsnitlige afstand er 748 meter i stikprøven. Hvis mægleren ønsker at vide hvor lang den gennemsnitlige afstand i populationen til nærmeste filial er med en bestemt sikkerhed, kan han beregne et konfidensinterval. Det er klart man ikke kan få en sikkerhed på 100%, man har jo kun en stikprøve, men man beregner ofte et 95% konfidensinterval. Hvis standard afvigelsen er 102 meter, kan han nu ved ovenstående formel bestemme et 95% konfidensinterval.

Han ved at når han har beregnet formlen kan han sætte de nedre og øvre grænser for konfidensintervallet ind i nedenstående sætning: 

*Vi kan med 95% sikkerhed sige at den gennemsnitlige afstand til filialen, for kunderne i populationen ligger mellem nedre bla bla og øvre bla bla meter*

Vi bestemmer nedre grænse for 95% KI ved:  

$$\bar{X} - t_{1-\frac{\alpha}{2}}\cdot \frac{S}{\sqrt[]{n}}=$$
$$748-`r round(qt(0.975,199),4)`\cdot \frac{102}{\sqrt[]{200}}=`r round(748-qt(0.975,199)*((102)/200^0.5),4)`$$

Hvor vi har benyttet 97.5% fraktilen for t-fordelingen med $n-1=199$ frihedsgrader denne er `r round(qt(0.975,199),4)`, bemærk denne er ikke langt fra 97.5% fraktilen for z-fordelingen 1.96, når vi har en stikprøve på 200.

Vi bestemmer tilsvarende øvre grænse for 95% KI ved:  

$$\bar{X} + t_{1-\frac{\alpha}{2}}\cdot \frac{S}{\sqrt[]{n}}=$$
$$748+`r round(qt(0.975,199),4)`\cdot \frac{102}{\sqrt[]{200}}=`r round(748+qt(0.975,199)*((102)/200^0.5),4)`$$

*Vi kan med 95% sikkerhed sige at den gennemsnitlige afstand til filialen, for kunderne i populationen ligger mellem `r round(748-qt(0.975,199)*((102)/200^0.5),4)` og `r round(748+qt(0.975,199)*((102)/200^0.5),4)` meter*

#### Middelværdi standardafvigelse KI Freestat
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226077779' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


#### Fejlmargin teori
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337972' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


#### Fejlmargin ved middelværdi

Fejlmarginen er den halve længde af konfidensintervallet, denne kan altså i forrige eksempel beregnes som:

$$\frac{`r round(748+qt(0.975,199)*((102)/200^0.5),4)`-`r round(748-qt(0.975,199)*((102)/200^0.5),4)`}{2}=`r round(((748+qt(0.975,199)*((102)/200^0.5))- (748-qt(0.975,199)*((102)/200^0.5)))/2,4)`$$

Vi kan også udregne fejlmarginen ved formlen:

$$`r round(qt(0.975,199),4)`\cdot \frac{102}{\sqrt[]{200}}=`r round(qt(0.975,199)*((102)/200^0.5),4)`$$

Vi bruger t-fordelingen når vi ikke kender standardafvigelsen $\sigma$ for populationen. Hvis standardafvigelsen $\sigma$ for populationen er kendt bruger vi standard normalfordelingen vi kalder også denne z-fordelingen. Er stikprøven stor kan vi ligeledes bruge z-fordelingen. Forskellen på z-fordelingen og t-fordelingen er at t-fordelingen har federe haler i forhold til z-fordelingens klokkeform. I Figuren til venstre er forskellen mellem disse indtegnet.  

KI beregnes ved z-fordelingen som:

$$(1-\alpha)\ KI=\left[\bar{X} - z_{1-\frac{\alpha}{2}}\cdot \frac{S}{\sqrt[]{n}};\bar{X} + z_{1-\frac{\alpha}{2}}\cdot \frac{S}{\sqrt[]{n}}\right]$$

### Eksempler konfidensinterval middelværdi  

#### Tryg aktien
Hent seneste data for dagsafkastet i procent på trygaktien <a href="DK aktiekurser.xlsx" download>her.</a>

```{r echo=FALSE}
trygm <- mean(DKdf[,1])
trygn <- length(DKdf[,1])
trygsd <- sd(DKdf[,1])
CImlow <- function(m,n,p,sd) round(m+qt(p/200,(n-1))*(sd/n^0.5),4)
CImup <- function(m,n,p,sd) round(m-qt(p/200,(n-1))*(sd/n^0.5),4)
list.of.packages <- c("readxl")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(readxl)
bank <- read_excel("/cloud/project/FILER/BANKDATA.xls",1)
```



Vi bestemmer nedre grænse for 95% KI ved:  

$$\bar{X} - t_{1-\frac{\alpha}{2}}\cdot \frac{S}{\sqrt[]{n}}=$$
$$`r trygm` - `r round(qt(0.975,trygn-1),4)`\cdot \frac{`r trygsd`}{\sqrt[]{`r trygn`}}=$$
$$`r CImlow(trygm,trygn,5,trygsd)`$$

Hvor vi har benyttet 97.5% fraktilen for t-fordelingen med `r trygn-1` frihedsgrader denne er `r round(qt(0.975,trygn-1),4)`, bemærk denne er ikke langt fra 97.5% fraktilen for z-fordelingen 1.96, når vi har en stikprøve på `r trygn`  

Vi bestemmer tilsvarende øvre grænse for 95% KI ved:  

$$\bar{X} + t_{1-\frac{\alpha}{2}}\cdot \frac{S}{\sqrt[]{n}}=$$
$$`r trygm` + `r round(qt(0.975,trygn-1),4)`\cdot \frac{`r trygsd`}{\sqrt[]{`r trygn`}}=$$
$$`r CImup(trygm,trygn,5,trygsd)`$$

Vi kan altså med 95% sikkerhed sige at det gennemsnitlige dagsafkast i populationen ligger mellem `r CImlow(trygm,trygn,5,trygsd)`% og `r CImup(trygm,trygn,5,trygsd)`%.  

Tilsvarende bestemmer vi 90% KI for Tryg aktien:  

Vi kan altså med 90% sikkerhed sige at det gennemsnitlige dagsafkast i populationen ligger mellem `r CImlow(trygm,trygn,10,trygsd)`% og `r CImup(trygm,trygn,10,trygsd)`%.  

99% KI for Tryg aktien bliver:  

Vi kan altså med 99% sikkerhed sige at det gennemsnitlige dagsafkast i populationen ligger mellem `r CImlow(trygm,trygn,1,trygsd)`% og `r CImup(trygm,trygn,1,trygsd)`%.  

## Spørgsmål konfidensinterval og fejlmargin  

<br>
<details> 
  <summary>Spørgsmål konfidensinterval og fejlmargin</summary>
  
Vi har en indsamlet data for dagsafkastet i procent for en aktie på 80 vilkårlige handelsdage. Aktien har et gennemsnitligt dagsafkast i procent på 0.05% og en standardafvigelse på 0.6% 

**1.** Hvad bliver 95% konfidensintervallet for middelværdien i populationen, som er alle handelsdage for aktien?  

**2.** Hvor stor skal stikprøven være for at fejlmarginen er 0.1?  

**3.** Hvor stor skal stikprøven være for at fejlmarginen er 0.1, hvis vi kender populationen, og denne er 500 handelsdage?  
</details>
<br>
<details> 
  <summary>Svar konfidensinterval og fejlmargin</summary> 


Vi har ikke rådata for de 80 handelsdage, derfor må vi i stedet benytte beregnede data i Freestat fanen Middelværdi standardafvigelse.

**1.** Vi kan med 95% sikkerhed sige at middelværdien i populationen $\mu$ ligger mellem 0.52% og 0.71%. Den ukendte middelværdi blandt alle handelsdage ligger med 95% sikkerhed mellem -0.08% og 0.18%  

<img src="img/stdafvKI.png" alt="stdafvKI" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

Vi kan se Freestat beregner konfidensintervallet KI i celle U6 og U7, ligeledes står en kort sætning i celle T18, der beskriver konfidensintervallet.  

**2.** Stikprøven skal mindst være 139 handelsdage for at fejlmarginen bliver 0.1 eller derunder. Bemærk for at finde stikprøvestørrelsen skrives ønsket fejlmargin i celle U12 i Freestat.  

<img src="img/kimargin.png" alt="kimargin" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

**3.** Stikprøven skal mindst være 127 handelsdage for at fejlmarginen bliver 0.1 eller derunder, når populationen er kendt og mindre end 500 handelsdage. Pas meget på hvis du skriver i gule felter fx. celle V6, slet tallene bagefter ellers korrigeres for den mindre populationen i alle følgende beregninger.  

  <img src="img/kimarginkendt.png" alt="kimarginkendt" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

</details>
<br>
<details> 
  <summary>Spørgsmål konfidensinterval</summary> 


Vi kan ligeledes se på data for bankansatte betragt variablen gennemsnitligt antal års uddannelse EDUCATION. Datasættet kan hentes her  [bankdata](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM)  
**1.** Bestem 90% Konfidensintervallet for middelværdien  
**2.** Bestem 95% Konfidensintervallet for middelværdien  
**3.** Bestem 99% Konfidensintervallet for middelværdien  

</details>
<br>
<details> 
  <summary>Svar konfidensinterval</summary>
  
**1.** Antal års uddannelse i populationen ligger med 90% sikkerhed mellem `r round(CImlow(mean(bank$education),length(bank$education),10,sd(bank$education)),2)` og `r round(CImup(mean(bank$education),length(bank$education),10,sd(bank$education)),2)` år  
  

<img src="img/stdKI90.png" alt="stdKI90" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
  

**2.** Antal års uddannelse i populationen ligger med 95% sikkerhed mellem `r round(CImlow(mean(bank$education),length(bank$education),5,sd(bank$education)),2)` og `r round(CImup(mean(bank$education),length(bank$education),5,sd(bank$education)),2)` år  

<img src="img/stdKI95.png" alt="stdKI95" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  


**3.** Antal års uddannelse i populationen ligger med 99% sikkerhed mellem `r round(CImlow(mean(bank$education),length(bank$education),1,sd(bank$education)),2)` og `r round(CImup(mean(bank$education),length(bank$education),1,sd(bank$education)),2)` år  


<img src="img/stdKI99.png" alt="stdKI99" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

</details>


## Konfidensinterval for standardafvigelsen

Ligesom vi kan sige at middelværdien for populationen med en vis sikkerhed ligger i et bestemt interval, kan vi beregne konfidensintervaller for standardafvigelsen i populationen. Freetat beregner konfidensintervallet for standardafvigelsen for os, beregningen er lidt indviklet denne er angivet herunder for en ordens skyld, men vi vil blot benytte Freestat.

$$(1-\alpha)\  KI=\left[\sqrt[]{\frac{(n-1)s^2}{\chi^2_{1-\frac{\alpha}{2},df_{n-1}}}};\sqrt[]{\frac{(n-1)s^2}{\chi^2_{1-\frac{\alpha}{2},df_{n-1}}}}\right]$$

Hvor $\chi^2_{1-\frac{\alpha}{2},df_{n-1}}$ er $1-\frac{\alpha}{2}$ fraktilen for $\chi^2$ fordelingen med $n-1$ frihedsgrader. s er $\hat{\sigma}$



Husk at chekke for normalitet fx. i et normalfraktildiagram. Det er en forudsætning for at benytte formlen ved konfidensintervallet for standardafvigelsen, at stikprøven stammer fra en normalfordelt population. 


```{r ,include=FALSE}
imdb <- read_excel("/cloud/project/FILER/IMDB stikprøve på 759 film.xls",1)
attach(imdb)
mean <- round(mean(Rating),2)
sdek <- round(sd(Rating),4)
```

#### IMDB ratings datasæt

I datasættet [IMDB data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlWlFNLTVoMEU1WHM), findes oplysninger om 759 film inklusiv ratings for disse. Hvis vi betragter datasættet som en simpelt tilfældigt udtrukket stikprøve, kan vi udtale os om populationen. Vi undersøger vha. Freestat normalfraktildiagram, om stikprøven kan antages at stamme fra en normalfordelt population. Af nedenstående plot ses denne forudsætning at være opfyldt.


<img src="img/imdbratingqq.png" alt="freestatvirkdksem" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

Vores bedste gæt på standardafvigelsen i populationen er $\hat\sigma=1.5414$, dvs. en films rating typisk afviger 1.54 point fra gennemsnittet 5.96. 

<img src="img/imdbratingdescr.png" alt="freestatvirkdksem" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

Vi kan af Freestat se, at den sande standard afvigelse i populationen med 95% sikkerhed ligger mellem 1.4676 og 1.6231 point.  


## Spørgsmål konfidensinterval for standardafvigelsen  
  
 
<br>
<details> 
  <summary>Spørgsmål konfidensinterval for standardafvigelsen</summary>
Vi har en indsamlet data for dagsafkastet i procent for en aktie på 80 vilkårlige handelsdage. Aktien har et gennemsnitligt dagsafkast i procent på 0.05% og en standardafvigelse på 0.6% Bestem 95% konfidensintervallet for standardafvigelsen i populationen, som er alle handelsdage for aktien.
</details>
<br>
<details> 
  <summary>Svar konfidensinterval for standardafvigelsen</summary> 
Vi har ikke rådata for de 80 handelsdage, derfor må vi i stedet benytte beregnede data i Freestat fanen Middelværdi standardafvigelse.

Vi kan med 95% sikkerhed sige at standardafvigelsen i populationen $\sigma$ ligger mellem 0.52% og 0.71%. Den ukendte typiske afvigelse fra gennemsnittet blandt alle handelsdage ligger med 95% sikkerhed mellem 0.52% og 0.71%.

<img src="img/stdafvKI.png" alt="stdafvKI" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

Vi kan se Freestat beregner konfidensintervallet KI i celle U8 og U9, ligeledes står en kort sætning i celle T20 der beskriver konfidensintervallet.

</details>
<br>
<details> 
  <summary>Spørgsmål konfidensinterval for standardafvigelsen bankansatte USA</summary>
  
Vi kan ligeledes se på data for bankansatte betragt variablen gennemsnitligt antal års uddannelse EDUCATION. Datasættet kan hentes her:   [bankdata](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM)  
**1.** Bestem 90% Konfidensinterval for standardafvigelsen for variablen education.  
**2.** Bestem 95% Konfidensinterval for standardafvigelsen for variablen education.  
**3.** Bestem 99% Konfidensinterval for standardafvigelsen for variablen education.  
</details>
<br>
<details> 
  <summary>Svar konfidensinterval for standardafvigelsen bankansatte USA</summary>  
**1.** Vi kan med 90% sikkerhed sige at standardafvigelsen for antal års uddannelse i populationen σ ligger mellem 2.74 år og 3.05 år.  

<img src="img/stdKI90.png" alt="stdKI90" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

**2.** Vi kan med 95% sikkerhed sige at standardafvigelsen for antal års uddannelse i populationen σ ligger mellem 2.71 år og 3.08 år.  

<img src="img/stdKI95.png" alt="stdKI95" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

**3.** Vi kan med 99% sikkerhed sige at standardafvigelsen for antal års uddannelse i populationen σ ligger mellem 2.66 år og 3.15 år.  

<img src="img/stdKI99.png" alt="stdKI99" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

</details>  




# Hypotesetests middelværdi  



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->



<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/227337869' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

<br>

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/257601661' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


## Hypotesetest tosidet alternativ hypotese
Vi kan ud fra en stikprøve udtale os om, hvad den sande middelværdi $\mu$ i populationen er. 
I eksemplet med mægleren tidligere, var den gennemsnitlige afstand til nærmeste filial 748 meter, standardafvigelsen 102 meter og stikprøvestørrelsen 200.

 
Mægleren mener, den sande afstand til nærmeste filial i gennemsnit er 730 meter. Kan dette være korrekt? Hypotesen bliver:

$$H_0:\mu = 730$$
$$H_1:\mu \neq 730$$

Påstanden i nulhypotesen $H_0$ er vores udgangspunkt, noget vi på forhånd mener er korrekt. Der skal en del til at vi forkaster nulhypotesen og dermed konkluderer at udsagnet i alternativ hypotesen $H_1$ eller $H_a$ er korrekt. Alternativ hypotesen $H_1$ er altid det komplementære udsagn til nulhypotesen, dvs. når nulhypotesen er $=$ bliver alternativ hypotesen $\neq$.



#### Signifikansniveau
Signifikansniveauet $\alpha$ angiver sandsynligheden for at forkaste en sand nulhypotese, ofte sættes dette til 5%. Det betyder at i 1 ud af 20 tilfælde, vil vi komme til at forkaste nulhypotesen, til trods for at denne var sand. Vi udtager stikprøver simpelt tilfældigt fra populationen, enkelte af disse vil give et forkert billede af virkeligheden. Ønsker man yderligere sikkerhed, for ikke at forkaste en sand nulhypotese, kan man sætte signifikansniveauet til 1%, så vil man kun i 1 ud af 100 tilfælde forkaste en korrekt nulhypotese.

I medicinalindustrien bruger man typisk 1% signifikansniveu for at sikre at et produkt har en effekt. Hypoteserne ville da være.
$$H_0\ produktet\ har\ ingen\ effekt$$
$$H_1\ produktet\ har\ effekt$$
Man ville således kun i 1 ud af 100 tilfælde fejlagtigt konkludere at et produkt har effekt. Signifikansniveauet $\alpha$, betegner sandsynligheden for at begå en type 1 fejl. En type 1 fejl, er alså sandsynligheden for at forkaste en nulhypotese der er sand.
   
   

Konfidensniveauet angiver sandsynligheden for at ikke forkaste en sand nulhypotese, summen af konfidensniveau og signifikansniveau er således 100%. 5% signifikansniveau svarer til 95% konfidensniveau, 1% signifikansniveau svarer til 99% konfidensniveau. De gængse signifikansniveauer er 1%, 5% og 10%. Er intet angivet, tester vi på 5% signifikansniveu, man beslutter sig inden testet for hvilket signifikansniveau man sætter.

#### Teststørrelse
Vi kalder hypoteseværdien $\mu_0=730$, vores teststørrelse bliver:

$$\frac{\hat{\mu}-\mu_0}{SEM}=\frac{748-730}{\frac{\hat{\sigma}}{\sqrt{n}}}=\frac{18}{\frac{102}{\sqrt{200}}}=\frac{18}{7.2125}=`r round(18/7.2125,4)`$$

Hvor vi fra stikprøven, har gennemsnittet $\hat{\mu}$ 748 meter, standardafvigelsen i stikprøven $\hat{\sigma}$ 102 meter og stikprøvestørrelsen 200. Teststørrelser er et centralt begreb i hypotesetests, tælleren  748-730, er et mål for hvor stor forskellen er mellem det vi har observeret i stikprøven 748, og den værdi vi antager under nulhypotesen 730. Der gælder for alle typer af tests at store teststørrelser er kritiske for nulhypotesen. Store teststørelser betyder vi ikke tror på nulhypotesen. I dette tilfælde er nulhypotesen, at afstanden til nærmeste filial er 730 meter. Hvornår er en teststørrelse så stor? Det afhænger af testtypen og stikprøvestørrelsen. Her er der tale om en tosidet (da alternativ hypotesen er $\neq$) t-test, det betyder at numerisk store teststørrelser er kritiske. Havde vi fx observeret afstanden til nærmeste filial var 700 meter, var tælleren 700-730 blevet negativ, da nævneren altid er positiv ville teststørrelsen blive negativ. Var afstanden kun 700 meter i stikprøven, ville vi ikke tro på at afstanden i populationen er 730 meter. Når vi tester tosidet er meget negative eller positive teststørrelser kritiske for nulhypotesen, dvs. når teststørrelsen numerisk bliver stor, tror vi ikke på nulhypotesen. Da vi ser på en t-test afhænger fraktilerne af antallet af frihedsgrader og signifikansniveauet, når vi har en stor stikprøve på 5% signifikansniveau, vil værdier mindre end -1.96 eller større end 1.96 være kritiske for nulhypotsen. Her er stikprøvestørrelsen 200, dvs. vi benytter t-fordelingen med 199 frihedsgrader, hvilket gør at de kritiske værdier bliver -1.97 og 1.97. I teststørrelsen dividerer vi med standardfejlen SEM, dette er for at skalere teststørrelsen korrekt, så den altid er i en skala, der svarer til t-fordelingen. Havde vi fx målt afstanden til nærmeste filial i centimeter, ville tælleren blive 74800-73000=1800, vi korrigerer for skala ved at dividere med SEM, skalerer vi så teststørrelsen bliver den samme uanset om vi måler i meter eller centimeter. 


#### Signifikanssandsynlighed p-værdi
Signifikanssandsynligheden også kaldet p-værdien, angiver sandsynligheden for at få en mere ekstrem teststørrelse, hvis vi udtager en ny tilsvarende stikprøve, når nulhypotesen er sand. I mægler eksemplet er p-værdien lille 0.0134, der kun 1.34% chance for at få en teststørrelse der numerisk er større end 2.4957, hvis vi udtog en ny stikprøve på 200, hvis nulhypotesen er sand. Da 1.34% er mindre end 5%, tror vi ikke på nulhypotesen om at der gennemsnitligt er 730 meter til nærmeste filial.Vi beregner p-værdien ved arealet af halen, der skæres af ved teststørrelsen eller teststørrelsen numerisk. Arealet ved højre hale, der skæres af 2.4957 er 0.0067, arealet ved venstre hale, der skæres af -2.4957 er ligeledes 0.0067. Når vi tester 2-sidet lægger vi begge halearealer sammen og får 0.0067+0.0067=0.0134, hvilket er p-værdien.

Nedenstående figurer viser p-værdi på 0.0134. Vi forkaster altså nulhypotesen på 5% signifikansniveauet. 

Den sande afstand til nærmeste filial, er altså forskellig fra 730 meter. Afstanden er større end 730 meter kan vi af konstatere da p-værdien 0.0067 er mindre end signifikansniveauet.




```{r t-score,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dt(x,199)
z <- seq(-1.97,1.97,length.out=200)
plot(x,y,type="l",main = "t-teststørrelsen acceptområde\ntosidet alternativ hypotese",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-1.96,z,1.96),c(0,dnorm(z),0),col="grey90",border="NA")
grid()
text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår t-teststørrelsen er\ni dette interval",cex = .7)
text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår t-teststørrelsen er\ni dette interval",cex = .7)
text(x=0,y=.1,"95%\nAfvis ikke\nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=2.5,0.3*1.02,label="t-teststørrelsen\n2.4957",cex = .7)
text(x=-2.4,y=0.01,label="2.5%",cex = .7)
text(x=2.4,y=0.01,label="2.5%",cex = .7)
segments( 2.5,  0,   2.5, 0.3,lty=3,lwd=.9)
arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.97,1.97,2.5,5),cex.axis=0.7)

```






```{r t-score2,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dt(x,199)
z <- seq(-round(18/7.2125,4),round(18/7.2125,4),length.out=200)
plot(x,y,type="l",main = "t-teststørrelsen\ntosidet alternativ hypotese",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-round(18/7.2125,4),z,round(18/7.2125,4)),c(0,dnorm(z),0),col="grey90",border="NA")
grid()
text(x=-3.5,y=0.1,"\nSandsynligheden,\nhvis middel=730, for at\n stikprøvens middelværdi\ni en ny stikprøve er\nmindre end 730-18=712\nsvarer til venstre hale 0.0067",cex = .7)
text(x=3.5,y=0.1,"\nSandsynligheden,\nhvis middel=730, for at\n stikprøvens middelværdi\ni en ny stikprøve er\nstørre end 730+18=748\nsvarer til højre hale 0.0067",cex = .7)
text(x=0,y=.1,"98.66% er\nsandsynligheden,\nhvis middel=730,for at\n stikprøvesandsynligheden\ni en ny stikprøve\nligger mellem\n712 og 748",cex = .7)
text(x=2.5,0.3*1.02,label="t-teststørrelsen\n2.4957",cex = .7)
# text(x=-2.4,y=0.01,label="2.5%",cex = .7)
# text(x=2.4,y=0.01,label="2.5%",cex = .7)
segments( 2.5,  0,   2.5, 0.3,lty=3,lwd=.9)
arrows( -3, 0.03,-2.7, 0.01,length=0.05,angle = 15)
arrows( 3, 0.03,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.97,1.97,2.5,5),cex.axis=0.7)

```


Hvis vi ser på teststørrelser i stedet for afstanden i meter, har vi beregnet denne til 2.4957 svarende til de 748 meter, da alternativhypotesen er forskellig fra, skal vi se på både venstre og højre hale. Vi skal beregne sandsynligheden (p-værdien) for at få en mere ekstrem teststørrelse, det betyder her en teststørrelse mindre end -2.4957 og større end 2.4957, når  nulhypotesen om at afstanden er 730 meter er sand. At teststørrelsen er mindre end -2.4957, svarer oversat til meter at afstanden er mindre end 712 meter, sandsynligheden for en numerisk mere ekstrem teststørrelse bliver arealet af begge haler 0.0067+0.0067=0.0134.

Vi kan benytte fanen 1 kvantitativ stikprøve beregnede data i venstre side. Her skal vi benytte testen med to-sidet alternativ hypotese.
<img src="img/freestatmiddelmaegler.png" alt="freestatmiddelmaegler" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>


Vi siger ovenstående konklusion er niveaufølsom, vi ville ikke have forkastet på 1% signifikansniveau, da 1% er mindre end p-værdien på 1.34%. At konklusionen er niveaufølsom, betyder altså at forskellige signifikansniveaer giver forskellige konklusioner.

Hvis vi kender populationens standardafvigelse $\sigma$, eller vi har store stikprøver, kan vi benytte z-fordelingen, til beregning af signifikanssandsynligheder. Software benytter ofte konsekvent t-fordelingen, der approximerer z-fordelingen, når antallet af frihedsgrader vokser. Jo større stikprøven er jo mindre forskel vil der være mellem de to metoder. Vi kan for små stikprøver benytte t-fordelingen, hvis stikprøven stammer fra en normalfordelt population. I Freestat benyttes kun t-fordelingen da vi forudsætter at populationsvariansen er ukendt.

## Tosidet alternativ hypotese og konfidensintervallet.
Når vi tester med tosidet alternativ hypotese, kan vi bruge konfidensintervallet svarende til signifikansniveauet til at afgøre om en nulhypotese forkastes. Ligger parameter estimatet $\hat\mu$ indenfor konfidensintervallets nedre og øvre grænse, kan vi ikke forkaste nulhypotesen, ligger det udenfor forkaster vi nulhypotesen. Denne metode er dog ikke så præcis som testet, hvor vi finder størrelsen af p-værdien. Ud fra størrelsen af p-værdien, kan vi afgøre hvor sikker hvor konklusion er.

## Ensidet alternativ hypotese
Ovenfor undersøgte vi om den sande afstand til nærmeste filial i gennemsnit er 730 meter mod alternativ hypotesen den sande afstand til nærmeste filial i gennemsnit er forskellig fra 730 meter. Vi kunne fx. være interesseret i:

1. Afstanden til nærmeste filial er mindst 730 meter mod alternativ hypotesen at afstanden til nærmeste filial er mindre end 730 meter.  
2. Afstanden til nærmeste filial er højst 730 meter mod alternativ hypotesen at afstanden til nærmeste filial er større end 730 meter. 

I formuleringen af spørgsmålet der stilles ligger nøglen til hvilken type test vi bruger, nedenfor er et skema over de ord man oplever i en formuleringen af et spørgsmål, disse skal benyttes til at afgøre om det er den ene eller anden hypotese vi skal benytte. Bemærk når man opstiller en konkret hypotese vil $\mu_0$ blive skiftet ud med den mulige middelværdi i populationen man ønsker at teste:

|Ord              | Operator             |Hypotese                       |Passer med
|:-------------   |:------------         |:------------                 |:---------
Er, kan være,                     |$=$                             |$H_0:\mu=\mu_0$                    |$H_1:\mu\neq\mu_0$
Er ikke, er forskellig fra        |$\neq$                         |$H_1:\mu\neq\mu_0$                 |$H_0:\mu=\mu_0$
Højst                             |$\leq$                        |$H_0:\mu\leq\mu_0$                 |$H_1:\mu>\mu_0$
Større end                        |$>$                              |$H_1:\mu>\mu_0$                    |$H_0:\mu\leq\mu_0$
Mindst                            |$\geq$                        |$H_0:\mu\geq\mu_0$                 |$H_1:\mu<\mu_0$
Mindre end                        |$<$                              |$H_1:\mu<\mu_0$                    |$H_0:\mu\geq\mu_0$

### Ensidet alternativ hypotese opad
Vi kan eksempelvis spørge på følgende måder og komme til samme konklusion:

1. Afstanden til nærmeste filial er højst 730 meter
2. Afstanden til nærmeste filial er større end 730 meter
I 1. får vi givet nulhypotesen da lighedstegnet ALTID skal i nulhypotesen, alternativhypotesen følger som det komplementære udsagn.
I 2. får vi givet alternativ hypotesen da udsagnet ikke indeholder lig med, nulhypotesen følger som det komplementære udsagn.

$$H_0:\mu \leq 730$$
$$H_1:\mu > 730$$

Hvilket betyder vi skal benytte den 2. af de 3 testmuligheder i Freestat output, dvs. signifikanssandsynligheden bliver  0.67%, vi forkaster altså nulhypotesen. Vi konkluderer derfor at $\mu > 730$. Den gennemsnitlige afstand til nærmeste filial i populationen er altså større end 730 meter. p-værdien er illustreret i figuren nedenfor, som den hvide højre hale.

Hvis vi her ser på teststørrelser i stedet for afstanden i meter, har vi beregnet denne til 2.4957 svarende til de 748 meter, da alternativhypotesen er større end, skal vi se på højre hale. Vi skal beregne sandsynligheden (p-værdien) for at få en mere ekstrem teststørrelse, det betyder her en teststørrelse større end 2.4957, når  nulhypotesen om at afstanden er 730 meter er sand. At teststørrelsen er større end 2.4957, svarer oversat til meter, til at afstanden er større end end 748 meter, sandsynligheden for en mere ekstrem teststørrelse bliver arealet højre hale  0.0067 altså p-værdien.

```{r t-score3,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dt(x,199)
z <- seq(-4,round(18/7.2125,4),length.out=200)
plot(x,y,type="l",main = "t-teststørrelsen\ntosidet alternativ hypotese",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-4,z,round(18/7.2125,4)),c(0,dnorm(z),0),col="grey90",border="NA")
grid()
text(x=3.5,y=0.1,"\nSandsynligheden,hvis\n middel er højst 730, for at\n stikprøvens middelværdi\ni en ny stikprøve er\nstørre end 730+18=748\nsvarer til højre hale 0.0067",cex = .7)
text(x=0,y=.1,"99.33% er\nsandsynligheden,hvis\n middel er højst 730,for at\n stikprøvegennemsnittet\ni en ny stikprøve\ner mindre end 748",cex = .7)
text(x=2.5,0.3*1.02,label="t-teststørrelsen\n2.4957",cex = .7)
segments( 2.5,  0,   2.5, 0.3,lty=3,lwd=.9)
arrows( 3, 0.03,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.97,1.97,2.5,5),cex.axis=0.7)

```

### Ensidet alternativ hypotese nedad
Vi viser her testet for ensidet alternativ hypotese nedad. Der er ingen grund til at teste her, vi ved der skal meget til at forkaste nulhypotesen, og vi har et stikprøvegennemsnit, der er større end 730. Vi vil derfor helt sikkert finde, at nulhypotesen om at afstanden til nærmeste filial er mindst 730 meter, ikke kan forkastes. Vi viser alligevel eksemplet med samme værdier, for at man kan se hvorledes sammenhængen er mellem de 3 typer af tests.

1. Afstanden til nærmeste filial er mindst 730 meter
2. Afstanden til nærmeste filial er mindre end 730 meter
I 1 får vi givet nulhypotesen, da lighedstegnet ALTID skal i nulhypotesen, alternativhypotesen følger som det komplementære udsagn.
I 2 får vi givet alternativ hypotesen, da udsagnet ikke indeholder lig med, nulhypotesen følger som det komplementære udsagn.

$$H_0:\mu \geq 730$$
$$H_1:\mu < 730$$

Hvilket betyder vi skal benytte den 3. af de 3 testmuligheder i Freestat output, dvs. signifikanssandsynligheden bliver  99.33%, vi forkaster altså IKKE nulhypotesen. Vi konkluderer derfor at $\mu \geq 730$. Den gennemsnitlige afstand til nærmeste filial i populationen er altså mindst 730 meter. p-værdien er illustreret i figuren nedenfor, som den store grå venstre hale.

Hvis vi ser på teststørrelsen har vi beregnet denne til 2.4957, da alternativhypotesen er mindre end, skal vi se på venstre hale. Vi skal beregne sandsynligheden (p-værdien) for at få en mere ekstrem teststørrelse, det betyder her en teststørrelse mindre end 2.4957, når  nulhypotesen om at afstanden er mindst 730 meter er sand. At teststørrelsen er mindre end 2.4957, svarer oversat til meter at afstanden er mindre end 748 meter, sandsynligheden for dette er meget høj nemlig 99.33%. Dette svarer til den grå venstre hale, vi er altså meget langt fra 5% signifikansniveauet og forkaster ikke nulhypotesen.

```{r t-score4,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dt(x,199)
z <- seq(-4,round(18/7.2125,4),length.out=200)
plot(x,y,type="l",main = "t-teststørrelsen\ntosidet alternativ hypotese",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-4,z,round(18/7.2125,4)),c(0,dnorm(z),0),col="grey90",border="NA")
grid()
text(x=0,y=0.1,"\nSandsynligheden,hvis\n middel er mindst 730, for at\n stikprøvens middelværdi\ni en ny stikprøve er\nmindre end 748\nsvarer til venstre hale 0.9933",cex = .7)
#text(x=0,y=.1,"99.33% er\nsandsynligheden,hvis\n middel er højst 730,for at\n stikprøvegennemsnittet\ni en ny stikprøve\ner mindre end 748",cex = .7)
text(x=2.5,0.3*1.02,label="t-teststørrelsen\n2.4957",cex = .7)
segments( 2.5,  0,   2.5, 0.3,lty=3,lwd=.9)
#arrows( 3, 0.03,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.97,1.97,2.5,5),cex.axis=0.7)

```


### Eksempel
#### Statistik karakterer

```{r karaktererstat2, echo=FALSE}
# library(xlsx)
# library(fImport)
library("readxl")
kar <- read_excel("/cloud/project/FILER/statkarakterer.xlsx",1)
se <- function(x) sqrt(var(x)/length(x))
tsize <- function(x,mu0) (mean(x)-mu0)/sqrt(var(x)/length(x))

```

I datasættet [Statkarakterer](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRURnNjk0UnJSYzQ)   <img src="img/12-Ball-Real.pngc200.png" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/> findes 54 statistik 2015 finansøkonom karakterer. Man kan med rette diskutere om karakterer for specifikke klasser/undervisere/lokationer etc. er repræsentative for populationen. 
Her antager vi at stikprøven er respræsentativ. Det er ligeledes tvivlsomt om vi kan behandle karakterer som en kontinuert variabel, der er tale om en kvalitativ ordinal variabel. I uddannelsesmæssige sammenhænge behandles karakterer som en kontinuert variabel, der beregnes gennemsnit og standardafvigelser, derfor forudsætter vi her variablen er kontinuert.

Vi finder parameterestimatet ved stikprøvegennemsnittet som $\hat{\mu}=`r round(mean((kar$Grade)),2)`$ 

Vi ønsker nu at undersøge om gennemsnittet i populationen, kan antages at ligge præcis mellem 4 og 7 dvs. 5.5. Det betyder vores $\mu_0=5.5$. Hypoteserne bliver:

$$H_0: \mu = 5.5$$
$$H_1: \mu \neq 5.5$$

Standard fejlen SE for middelværdien er `r round(se(kar$Grade),2)`, . Det betyder teststørrelsen bliver `r round(tsize(kar$Grade,5.5),2)`.
Vi kan nu bestemme p-værdien, arealet af de 2 haler i t-fordelingen med 53 frihedsgrader. bliver `r round(pt(tsize(kar$Grade,5.5),53)*2,4)`, da teststørrelsen er større end 5%, kan vi altså ikke forkaste nulhypotesen. 

Vi konkluderer altså gennemsnittet i populationen, kan antages at være 5.5.

## Standardafvigelse test

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226076398' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


#### FPC endelig populations korrektion og z-test




<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226018075' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

#### Type 1 og type 2 fejl

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/249729447' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

<img src="img/mandoc.jpg" align="right" width="100%" height="100%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

Hvis man forkaster en sand nulhypotese, kaldes det en type 1 fejl, det betyder nulhyposen er sand, men vi forkaster fejlagtigt nulhypotesen, dette kaldes en falsk positiv. Man kan tænke på nulhypotesen som den generelle opfattelse, alternativhypotesen er den den nye tanke/revolutionen der går imod den gængse opfattelse. Vi kan forestille os følgende eksempler på nulhypoteser:

1. En mand anklaget for mord er uskyldig.
2. Du har ikke kræft.
3. Der findes ikke liv på Mars.
4. Omsætningen er ikke steget.
5. Udgifterne er uændrede.
6. Jorden er flad (i meget gamle dage).
7. Jorden er rund (nu).
8. Du er ikke gravid.
9. Medicinen har ingen effekt

Vi kan bestemme sandsynligheden for at forkaste en sand nulhypotese/en type 1 fejl/en falsk positiv, det er vores signifikansniveau $\alpha$, tilsvarende er sandsynligheden for ikke at forkaste en sand nulhypotese $1-\alpha$. Dvs. når vi tester på 5% signifikansniveu vil vi 1 ud af 20 gange (5%) begå en type 1 fejl. I medicinalindustrien skal man være helt sikker på et nyt produkt har en effekt, derfor tester man ofte på 1% signifikansnivaeu (100%-1% = 99% konfidensniveau). Dette betyder at man kun 1 ud af 100 gange begår en type 1 fejl og konkluderer et medicinalprodukt har en effekt selv om det i virkeligheden ingen effekt har. Type 1 fejl er ofte noget, vi meget gerne vil undgå. Vi kan for statistiske hypoteser styre hvor ofte der begås fejl vha. signifikansniveauet, men tankegangen gælder også når vi ikke statistisk kan måle p-værdien. Hvis nulhypotesen er en mand anklaget for mord er uskyldig, svarer en type 1 fejl til at begå justitsmord, derfor skal beviserne i straffesager være stærke for at sikre domsfældelse. Hvis omsætningen ikke er steget, men vi konkluderer den er steget er der tale om en type 1 fejl.

<img src="img/docandpregnant.jpg" align="right" width="100%" height="100%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

En type 2 fejl kaldes en falsk negativ, sandsynligheden for at begå en type 2 fejl  kan ikke beregnes direkte. En skyldig mand der frikendes, er en type 2 fejl. Hvis omsætningen er steget, men vi konkluderer den ikke er steget, er der ligeledes tale om en type 2 fejl. 


|               |$H_0\ Sand$                     |$H_0\ Falsk$ 
|:-------------   |:------------                  |:------------
$\ Forkast\ ikke\  H_0$   | Korrekt beslutning        |  Type 2 fejl, falsk negativ
$\ Forkast\ H_0$    |   Type 1 fejl falsk positiv  |Korrekt beslutning






<br>

## Spørgsmål hypotesetests

<details> 
  <summary> Spørgsmål hypotesetest dagsafkast </summary> 
Vi har en indsamlet data for dagsafkastet i procent for en aktie på 80 vilkårlige handelsdage. Aktien har et gennemsnitligt dagsafkast i procent på 0.05% og en standardafvigelse på 0.6%  

**1.** Test på 5% signifikansniveau om det gennemsnitlige dagsafkast $\mu$ i populationen antages at være 0%?  

**2.** Test på 5% signifikansniveau om standardafvigelsen $\sigma$ i populationen antages at være mindre end 0.7% dvs. 0.007?  

</details>  
<br>
<details> 
  <summary> Svar hypotesetest dagsafkast </summary>  
  
Vi har ikke rådata for de 80 handelsdage, derfor må vi i stedet benytte beregnede data i Freestat fanen Middelværdi standardafvigelse.  

**1.** Hypoteserne bliver:  

$$H_0:\mu=0$$
$$H_1:\mu\neq0$$
<img src="img/mu0test.png" alt="mu0test" align="right" width="50%" height="50%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Da p værdien/signifikanssandsynligheden 45.83% er større end 5% signifikansniveauet, kan vi ikke forkaste nulhypotesen. Det betyder det gennemsnitlige dagsafkast kan antages at være 0% for denne aktie.  

<br>
<br>
<br>


**2.** Hypoteserne bliver:  

$$H_0:\sigma\geq0.007$$
$$H_1:\sigma<0.007$$
<img src="img/sigma0.7test.png" alt="sigma0.7test" align="right" width="50%" height="50%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Da p-værdien/signifikanssandsynligheden 3.68% er mindre end 5% signifikansniveauet, afviser vi nulhypotesen. Det betyder standardafvigelsen $\sigma$ for aktien er mindre end 0.7%  

<br>
<br>
<br>

</details>  
<br>
<details> 
  <summary> Spørgsmål hypotesetest uddannelse </summary> 
  
Vi kan ligeledes se på data for bankansatte betragt variablen gennemsnitligt antal års uddannelse EDUCATION. Datasættet kan hentes her  [bankdata](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM)  
**1.** Er det gennemsnitlige antal års uddannelse i populationen 13 år?  
**2.** Er standardafvigelsen i populationen mindre end 3 år?  


</details>  
<br>
<details> 
  <summary> Svar hypotesetest uddannelse </summary>  
  
**1.** Hypoteserne bliver:    
$$H_0:\mu=13$$
$$H_1:\mu\neq13$$
<img src="img/mu13test.png" alt="mu13test" align="right" width="50%" height="50%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Da p værdien/signifikanssandsynligheden 0.02% er mindre end 5% signifikansniveauet, afviser vi nulhypotesen. Det gennemsnitlige antal års uddannelse i populationen altså ikke 13 år.  
	
<br>
<br>
<br>


**2.** Hypoteserne bliver:  
$$H_0:\sigma\geq3$$
$$H_1:\sigma<3$$
<img src="img/sigma3test.png" alt="sigma3test" align="right" width="50%" height="50%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Da p værdien/signifikanssandsynligheden 12.17% er mindre end 5% signifikansniveauet, kan vi ikke afvise nulhypotesen, standardafvigelsen er altså mindst 3 i populationen.  
	
<br>
<br>
<br>

</details>  


## Spørgsmål hypotesetests og normalfordeling


<br>
<details> 
  <summary> Spørgsmål Standard normalfordelingen </summary>  

1. Hvad er parametrene for z-fordelingen og hvad kalder man også denne fordeling?  
2. Hvad er nedre og øvre grænse for 95% konfidensintervallet for standard normalfordelingen?  
3. Hvad er nedre og øvre grænse for 90% konfidensintervallet for standard normalfordelingen?  
4. Hvad er nedre og øvre grænse for 99% konfidensintervallet for standard normalfordelingen?  
5. Hvad er 0.025 fraktilen for standard normalfordelingen (hint brug Excelfunktionen NORM.INV, angiv fraktil, middelværdi og standardafvigelse som argumenter)?  
6. Hvad er 0.975 fraktilen for standard normalfordelingen?   
7. Hvorfor er de 2 fraktiler numerisk identiske?  
8. Hvad er 0.05 fraktilen for standard normalfordelingen?  
9. Hvad er 0.95 fraktilen for standard normalfordelingen?  
10. Hvad er 0.005 fraktilen for standard normalfordelingen?  
11. Hvad er 0.995 fraktilen for standard normalfordelingen?  
</details>  
<br>
<details> 
  <summary> Svar Standard normalfordelingen </summary>  
  
1. Parametrene for z-fordelingen $\mu=0$ og $\sigma=1$, z-fordelingen kaldes også standard normalfordelingen  
2. Nedre og øvre grænse for 95% konfidensintervallet for standard normalfordelingen er -1.96 og 1.96  
3. Nedre og øvre grænse for 90% konfidensintervallet for standard normalfordelingen er -1.64 og 1.64  
4. Nedre og øvre grænse for 99% konfidensintervallet for standard normalfordelingen er -2.58 og 2.58  
5. 0.025 fraktilen for standard normalfordelingen, findes i excel som =NORM.INV(0.025;0;1) resultatet bliver -1.96, hvilket netop er nedre grænse i 95% konfidensintervallet for standard normalfordelingen.  
6. 0.975 fraktilen for standard normalfordelingen er 1.96  
7. De 2 fraktiler numerisk identiske, da normalfordelinger er symmetriske og standard normalfordelingen har middelværdi 0.  
8. 0.05 fraktilen for standard normalfordelingen er -1.64  
9. 0.95 fraktilen for standard normalfordelingen er 1.64  
10. 0.005 fraktilen for standard normalfordelingen er -2.58  
11. 0.995 fraktilen for standard normalfordelingen er 2.58  
</details>  

<br>
<details> 
  <summary> Spørgsmål Konfidensintervaller for normalfordelinger </summary>  

1. Hvad er nedre og øvre grænse for 95% konfidensintervallet for en normalfordelt stokastisk variabel $X\sim N(\mu=4,\sigma=1)$?  
2. Hvad er nedre og øvre grænse for 90% konfidensintervallet for en normalfordelt stokastisk variabel $X\sim N(\mu=4,\sigma=1)$?  
3. Hvad er nedre og øvre grænse for 99% konfidensintervallet for en normalfordelt stokastisk variabel $X\sim N(\mu=4,\sigma=2)$?  
4. Hvad er nedre og øvre grænse for 95% konfidensintervallet for en normalfordelt stokastisk variabel $X\sim N(\mu=100,\sigma=20)$?  
5. Hvad er nedre og øvre grænse for 90% konfidensintervallet for en normalfordelt stokastisk variabel $X\sim N(\mu=100,\sigma=20)$?  
6. Hvad er nedre og øvre grænse for 99% konfidensintervallet for en normalfordelt stokastisk variabel $X\sim N(\mu=1000,\sigma=100)$?  
</details>  

<br>
<details> 
  <summary> Svar Konfidensintervaller for normalfordelinger </summary>  

1. Nedre og øvre grænse for 95% konfidensintervallet for $X\sim N(\mu=4,\sigma=1)$ er $\mu-1.96\cdot\sigma=4-1.96\cdot1=`r 4-1.96*1`$ og $\mu+1.96\cdot\sigma=4+1.96\cdot1=`r 4+1.96*1`$  
2. Nedre og øvre grænse for 90% konfidensintervallet for $X\sim N(\mu=4,\sigma=1)$ er $\mu-1.64\cdot\sigma=4-1.64\cdot1=`r 4-1.64*1`$ og $\mu+1.64\cdot\sigma=4+1.64\cdot1=`r 4+1.64*1`$  
3. Nedre og øvre grænse for 99% konfidensintervallet for $X\sim N(\mu=4,\sigma=2)$ er $\mu-2.58\cdot\sigma=4-2.58\cdot2=`r 4-2.58*2`$ og $\mu+2.58\cdot\sigma=4+2.58\cdot2=`r 4+2.58*2`$  
4. Nedre og øvre grænse for 95% konfidensintervallet for $X\sim N(\mu=100,\sigma=20)$ er $\mu-1.96\cdot\sigma=100-1.96\cdot20=`r 100-1.96*20`$ og $\mu+1.96\cdot\sigma=100+1.96\cdot20=`r 100+1.96*20`$  
5. Nedre og øvre grænse for 90% konfidensintervallet for $X\sim N(\mu=100,\sigma=20)$ er $\mu-1.64\cdot\sigma=100-1.64\cdot20=`r 100-1.64*20`$ og $\mu+1.64\cdot\sigma=100+1.64\cdot20=`r 100+1.64*20`$  
6. Nedre og øvre grænse for 99% konfidensintervallet for $X\sim N(\mu=1000,\sigma=100)$ er $\mu-2.58\cdot\sigma=1000-2.58\cdot100=`r 1000-2.58*100`$ og $\mu+2.58\cdot\sigma=1000+2.58\cdot100=`r 1000+2.58*100`$  
</details>  

<br>
<details> 
  <summary> Spørgsmål t-fordelingen </summary>  

1. Hvad er 0.025 og 0.975 fraktilerne for t-fordelingen, for en stikprøvestørrelse n=1000 dvs. 999 frihedsgrader  (hint brug Excelfunktionen =TINV(0,025;999) eller =TINV(0,05;999) lidt afhængigt af office-version er værdien den numeriske værdi af fraktilen)?  
2. Hvad er 0.025 og 0.975 fraktilerne for t-fordelingen, for en stikprøvestørrelse n=100 dvs. 99 frihedsgrader?  
3. Hvad er 0.025 og 0.975 fraktilerne for t-fordelingen, for en stikprøvestørrelse n=25 dvs. 24 frihedsgrader?  
4. Hvorfor ændres fraktilerne for t-fordelingen sig afhængigt af antallet af frihedsgrader?  
</details>  

<br>
<details> 
  <summary> Svar t-fordelingen </summary>  
1. 0.025 fraktilen er -1.9623 og 0.975 fraktilen 1.9623  
2. 0.025 fraktilen er -1.9842 og 0.975 fraktilen 1.9842  
3. 0.025 fraktilen er -2.0639 og 0.975 fraktilen 2.0639  
4. t-fordelingerne nærmer sig standard normalfordelingen når antallet af frihedsgrader dvs. stikprøvestørrelsen vokser, dvs fraktilerne nærmer sig 1.96  
</details>  

<br>
<details> 
  <summary> Spørgsmål Standardfejlen for middelværdien, og konfidensinterval for middelværdien. </summary>  

1. Der er udtaget en stikprøve på 100, fra en population med kendt standardafvigelse $\sigma=10$, hvad bliver standardfejlen for middelværdien?  
2. Der er udtaget en stikprøve på 900, fra en population med kendt standardafvigelse $\sigma=15$, hvad bliver SEM?  
3. Der er udtaget en stikprøve på 81, fra en population med kendt standardafvigelse $\sigma=36$, hvad bliver standardfejlen for middelværdien?  
4. Der er udtaget en stikprøve på 100, fra en population med kendt standardafvigelse $\sigma=10$, stikprøvegennemsnittet dvs. parameterestimatet $\hat\mu$, for den ukendte middelværdi $\mu$ i populationen er $\bar{x}=\hat\mu=20$, hvad bliver nedre og øvre grænser 95% konfidensintervallet for middelværdien?  
5. Der er udtaget en stikprøve på 900, fra en population med kendt standardafvigelse $\sigma=15$, stikprøvegennemsnittet dvs. parameterestimatet $\hat\mu$, for den ukendte middelværdi $\mu$ i populationen er $\bar{x}=\hat\mu=20$, hvad bliver nedre og øvre grænser 95% konfidensintervallet for middelværdien?  
6. Der er udtaget en stikprøve på 81, fra en population med kendt standardafvigelse $\sigma=36$, stikprøvegennemsnittet dvs. parameterestimatet $\hat\mu$, for den ukendte middelværdi $\mu$ i populationen er $\bar{x}=\hat\mu=100$, hvad bliver nedre og øvre grænser 95% konfidensintervallet for middelværdien?  
7. Hvad ville 95% konfidensintervallet blive i 4. hvis standardafvigelsen i $\sigma$ i populationen ikke var kendt og derfor blev estimeret ud fra stikprøven til $\hat\sigma=10$?  
8. Hvad ville 95% konfidensintervallet blive i 5. hvis standardafvigelsen i $\sigma$ i populationen ikke var kendt og derfor blev estimeret ud fra stikprøven til $\hat\sigma=15$?  
9. Hvad ville 95% konfidensintervallet blive i 6. hvis standardafvigelsen i $\sigma$ i populationen ikke var kendt og derfor blev estimeret ud fra stikprøven til $\hat\sigma=36$?  
</details>  
<br>
<details> 
  <summary> Svar Standardfejlen for middelværdien, og konfidensinterval for middelværdien. </summary>  
1. Standardfejlen for middelværdien kan udregnes til $\frac{\sigma}{\sqrt{n}}=\frac{10}{\sqrt{100}}=1$  
2. Standardfejlen for middelværdien kan udregnes til $\frac{\sigma}{\sqrt{n}}=\frac{15}{\sqrt{900}}=0.5$  
3. Standardfejlen for middelværdien kan udregnes til $\frac{\sigma}{\sqrt{n}}=\frac{36}{\sqrt{81}}=4$  
4. 95% konfidensintervallet for middelværdien udregnes vha. standardfejlen vi fandt i 1. Nedre grænse bliver $\hat\mu-1.96\cdot\frac{\sigma}{\sqrt{n}}=20-1.96\cdot1=18.04$, øvre grænse for 95% konfidensintervallet for middelværdien bliver $\hat\mu+1.96\cdot1=20+1.96=21.96$. Sagt med andre ord: "Vi kan med 95% sikkerhed sige at den sande middelværdi i populationen ligger mellem 18.04 og 21.96"  
5. 95% konfidensintervallet for middelværdien udregnes vha. standardfejlen vi fandt i 2. Nedre grænse bliver $\hat\mu-1.96\cdot\frac{\sigma}{\sqrt{n}}=\hat\mu-1.96\cdot0.5=20-0.98=19.02$, øvre grænse for 95% konfidensintervallet for middelværdien bliver $\hat\mu+1.96\cdot0.5=20+0.98=20.98$. Sagt med andre ord: "Vi kan med 95% sikkerhed sige at den sande middelværdi i populationen ligger mellem 19.02 og 20.98"  
6. 95% konfidensintervallet for middelværdien udregnes vha. standardfejlen vi fandt i 3. Nedre grænse bliver $\hat\mu-1.96\cdot\frac{\sigma}{\sqrt{n}}=100-1.96\cdot4=100-7.84=92.16$, øvre grænse for 95% konfidensintervallet for middelværdien bliver $\hat\mu+1.96\cdot4=100+7.84=107.84$. Sagt med andre ord: "Vi kan med 95% sikkerhed sige at den sande middelværdi i populationen ligger mellem 92.16 og 107.84"  
7. Hvis standardafvigelsen i $\sigma$ i populationen ikke var kendt og derfor blev estimeret ud fra stikprøven til $\hat\sigma=10$, benytter vi t-fordelingen med 100-1=99 frihedsgrader. I Excel kan denne udregnes ved =TINV(0.05;99) hvilket giver 1.9842. 95% konfidensintervallet for middelværdien bliver:  
Nedre grænse $20-1.9842\cdot1=18.02$  
Øvre grænse $20+1.9842\cdot1=21.98$  
"Vi kan med 95% sikkerhed sige at den sande middelværdi i populationen ligger mellem 18.02 og 21.98"  
8. Hvis standardafvigelsen i $\sigma$ i populationen ikke var kendt og derfor blev estimeret ud fra stikprøven til $\hat\sigma=15$, benytter vi t-fordelingen med 900-1=899 frihedsgrader. I Excel kan denne udregnes ved =TINV(0.05;899) hvilket giver 1.9626.  
95% konfidensintervallet for middelværdien bliver:  
Nedre grænse $20-1.9626\cdot0.5=19.02$  
Øvre grænse $20+1.9626\cdot0.5=20.98$  
"Vi kan med 95% sikkerhed sige at den sande middelværdi i populationen ligger mellem 19.02 og 20.98"  
9. Hvis standardafvigelsen i $\sigma$ i populationen ikke var kendt og derfor blev estimeret ud fra stikprøven til $\hat\sigma=36$, benytter vi t-fordelingen med 81-1=80 frihedsgrader. I Excel kan denne udregnes ved =TINV(0.05;80), hvilket giver 1.9901. 95% konfidensintervallet for middelværdien bliver:  
Nedre grænse $100-1.9901\cdot4=92.04$  
Øvre grænse $100+1.9901\cdot4=107.96$  
"Vi kan med 95% sikkerhed sige at den sande middelværdi i populationen ligger mellem 92.04 og 107.96"  
</details>  

<br>
<details> 
  <summary> Spørgsmål Danske virksomheder egenkapital</summary>  


```{r ,include=FALSE}
options(scipen=999)
library("ggplot2")
dkvirk <- read_excel("/cloud/project/FILER/VIRKSOMHEDER-DK.xlsx",1)
attach(dkvirk)
meanek <- round(mean(Egenkapital),2)
sdek <- round(sd(Egenkapital),2)
semek <- round(sdek/length(Egenkapital)^0.5,2)

```

I linket her er filen [VIRKSOMHEDER-DK](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlVmxHTDltNk1VSG8), der viser data for 369 danske virksomheder med ekstern revision. Der er således en overvægt af virksomheder af en vis størrelse, hvorfor samtlige beløb er angivet i antal 1000 DKK. Besvar følgende spørgsmål for variablen egenkapital i antal 1000 DKK.  


1. Hvad bliver parameterestimatet for middelværdien for variablen egenkapital?  
2. Hvad bliver parameterestimatet for standard afvigelsen for variablen egenkapital?  
3. Hvad bliver standardfejlen for middelværdien (engelsk standard error of the mean SEM eller SE) for variablen egenkapital?  
4. Når vi skal finde nedre og øvre grænser for et 95% konfidensinterval vha. z-fordelingen ganger vi med faktoren 1.96. Her har vi imidlertid ukendt standardafvigelse for populationen, derfor benytter vi t-fordelingen. I dette tilfælde er antallet af frihedsgrader n-1=369-1=368, faktoren bliver 1.9664 næsten det samme for z-fordelingen. Hvad bliver nedre og øvre grænser for 95% konfidensintervallet, for den gennemsnitlige egenkapital for virksomheder i populationen?  
5. Hvad bliver parameterestimatet for standardafvigelsen $\hat\sigma$ for variablen egenkapital?  
6. Hvad bliver nedre og øvre grænse for 95% konfidensintervallet for standard afvigelsen for variablen egenkapital?  
</details>  

<br>
<details> 
  <summary> Svar Danske virksomheder egenkapital</summary>  

1. Parameterestimatet for middelværdien for variablen egenkapital, udregnes som gennemsnittet af stikprøven   
$\hat\mu=\bar{x}=\frac{\sum_1^nx_i}{n}=\frac{\sum_1^nx_i}{369}=$$`r round(mean(Egenkapital),2)`$. Resultatet står som stikprøve gennemsnit i output fra Freestat herunder.  
2. Parameterestimatet for standard afvigelsen for variablen egenkapital findes som $\hat\sigma=S=\sqrt{\frac{\sum_1^n(x_i-\bar{x})^2}{n-1}}=\frac{\sum_1^nx_i}{368}=$$`r round(sd(Egenkapital),2)`$. Resultatet står som standard afvigelse spredning i Freestat herunder.round(sd(Egenkapital),2). Husk vi korrigerer ved at fratrække 1 fra stikprøvestørrelsen i nævneren dvs. n-1.  
3. Standardfejlen for middelværdien kan udregnes som   $SEM=\sigma_\bar{X}=\frac{\hat\sigma}{\sqrt{n}}=$$\frac{`r round(sd(Egenkapital),2)`}{\sqrt{369}}=`r semek`$. Resultatet står som standard fejl middel i Freestat herunder.  
4. Grænserne for 95% konfidensintervallet for middelværdien i populationen, kan udregnes til:  
  $\hat\mu-1.966431\cdot \sigma_\bar{X}=`r meanek`-1.966431\cdot`r semek`$$=`r round(meanek-1.966431*semek,2)`$ og
$\hat\mu+1.966431\cdot \sigma_\bar{X}=$$`r meanek`+1.966431\cdot `r semek`$$=`r round(meanek+1.966431*semek,2)`$  
  5. Parameterestimatet for standardafvigelsen $\hat\sigma$ bliver $676727.53$  
  6. Nedre og øvre grænse for 95% konfidensintervallet for standard afvigelsen bliver hhv. $631170.46$ og $729427.12$  
  
  Herunder ses det output man ville generere i Freestat Deskriptiv statistik.  

<img src="img/freestatvirkdksem.png" alt="freestatvirkdksem" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
  
  </details>  

<br>
<details> 
  <summary> Spørgsmål Danske virksomheder årets resultat</summary>



```{r ,include=FALSE}
dkvirk <- read_excel("/cloud/project/FILER/VIRKSOMHEDER-DK.xlsx",1)
attach(dkvirk)
ar <- unlist(na.omit(dkvirk[,10]))
meanar <- round(mean(ar),2)
sdar <- round(sd(ar),2)
semar <- round(sdar/length(ar)^0.5,2)

```

I linket her er filen [VIRKSOMHEDER-DK](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlVmxHTDltNk1VSG8), der viser data for 369 danske virksomheder med ekstern revision. Der er således en overvægt af virksomheder af en vis størrelse, hvorfor samtlige beløb er angivet i antal 1000 DKK. For at benytte stikprøven til at udtale sig om populationen, forudsættes det at denne er simpelt tilfældigt udtrukket fra populationen. Besvar følgende spørgsmål for variablen årets resultat i antal 1000 DKK.  


1. Hvad bliver parameterestimatet for middelværdien for variablen årets resultat?  
2. Hvad bliver parameterestimatet for standard afvigelsen for variablen årets resultat?  
3. Hvad bliver standardfejlen for middelværdien (engelsk standard error of the mean SEM eller SE) for variablen årets resultat?  
4. Når vi skal finde nedre og øvre grænser for et 95% konfidensinterval vha. z-fordelingen ganger vi med faktoren 1.96. Her har vi imidlertid ukendt standardafvigelse for populationen, derfor benytter vi t-fordelingen. I dette tilfælde er antallet af frihedsgrader n-1=369-1=368, faktoren bliver 1.9664 næsten det samme for z-fordelingen. Hvad bliver nedre og øvre grænser for 95% konfidensintervallet, for den gennemsnitlige egenkapital for virksomheder i populationen?  
5. Hvad bliver parameterestimatet for standardafvigelsen $\hat\sigma$ for variablen årets resultat?  
6. Hvad bliver nedre og øvre grænse for 95% konfidensintervallet for standard afvigelsen?  


 </details>  

<br>
<details> 
  <summary> Svar Danske virksomheder årets resultat</summary>

1. Parameterestimatet for middelværdien for variablen årets resultat, udregnes som gennemsnittet af stikprøven  
$\hat\mu=\bar{x}=\frac{\sum_1^nx_i}{n}=\frac{\sum_1^nx_i}{369}=`r round(mean(ar),2)`$. Resultatet står som stikprøve gennemsnit i output fra Freestat herunder.  
2. Parameterestimatet for standard afvigelsen for variablen årets resultat findes som $\hat\sigma=S=\sqrt{\frac{\sum_1^n(x_i-\bar{x})^2}{n-1}}=\frac{\sum_1^nx_i}{368}=`r round(sd(ar),2)`$. Resultatet står som standard afvigelse spredning i Freestat   herunder.round(sd(ar),2). Husk vi korrigerer ved at fratrække 1 fra stikprøvestørrelsen i nævneren dvs. n-1.  
3. Standardfejlen for middelværdien kan udregnes som $SEM=\sigma_\bar{X}=\frac{\sigma}{\sqrt{n}}=\frac{`r round(sd(ar),2)`}{\sqrt{369}}=`r semar`$. Resultatet står som standard fejl middel i Freestat herunder.  
4. Grænserne for 95% konfidensintervallet for middelværdien i populationen, kan udregnes til:$\hat\mu-1.966431\cdot \sigma_\bar{X}=`r meanar`-1.966431\cdot`r semar`=`r round(meanar-1.96643126706281*semar,2)`$ og $\hat\mu+1.966431\cdot\sigma_\bar{X}=`r meanar`+1.966431\cdot`r semar`=`r round(meanar+1.96643126706281*semar,2)`$  
  5. Parameterestimatet for standardafvigelsen $\hat\sigma$ bliver 374398.75  
6. Nedre og øvre grænse for 95% konfidensintervallet for standard afvigelsen bliver hhv. 349194.35 og 403554.74 i antal 1000 DKK.  

Herunder ses det output man ville generere i Freestat Deskriptiv statistik.  

<img src="img/freestatvirkar.png" alt="freestatvirkar" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
  
 </details>  

<br>
<details> 
  <summary> Spørgsmål til diskussion dagsafkast på danske aktier.</summary>












<a href="DK aktiekurser.xlsx" download> DK aktiekurser hentes her </a>

Man siger ofte at kursfaldet ved en korrektion, er hurtigere og voldsommere end stigningen i et positivt marked. Kan man baseret på data for aktierne, konkludere at dette synes at være tilfældet?  

Hvorfor kan en portefølje, der ikke er volatil(lille standardafvigelse), være en fordel for den risikoaverse investor?  

Man siger at man bør have cykliske og defensive aktier/aktiver i sin portefølje, kan man ud fra formlen for variansen forklare, hvorfor dette kunne være en god ide (hint tænk på dagsafkastet som det gennemsnitlige afkast af porteføljen)?  

[/toggle]











</details>  

<br>
<details> 
  <summary> Spørgsmål Hypotesetests danske virksomheders omsætning.</summary>



```{r ,include=FALSE}
dkvirk <- read_excel("/cloud/project/FILER/VIRKSOMHEDER-DK.xlsx",1)
oms <- dkvirk$Omsætning
```

I linket her er filen [VIRKSOMHEDER-DK](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlVmxHTDltNk1VSG8), der viser data for 369 danske virksomheder med ekstern revision. Der er således en overvægt af virksomheder af en vis størrelse, hvorfor samtlige beløb er angivet i antal 1000 DKK. Vi betragter i det følgende variablen omsætning.  

1. Hvilken type variabel er variablen Omsætning?  
2. Hvad bliver standardfejlen?  
3. Hvad bliver 95% konfidensintervallet for den gennemsnitlige omsætning i populationen?  
4. Ville vi kunne afvise en antagelse om at den gennemsnitlige omsætning i populationen kunne være 500.000.000 DKK, dvs. en halv mia. DKK, på et 5% signifikans niveau? Hvorledes ville hypoteserne for et test af denne påstand se ud?  
5. Ville vi kunne afvise en antagelse om at den gennemsnitlige omsætning i populationen kunne være 600.000.000 DKK på et 5% signifikans niveau? Hvorledes ville et hypoteserne for et test af denne påstand se ud?  
6. Ville vi kunne afvise en antagelse om at den gennemsnitlige omsætning i populationen kunne være 700.000.000 DKK, på et 5% signifikans niveau? Hvorledes ville et hypoteserne for et test af denne påstand se ud?  
7. Har de 3 tests ensidede eller tosidede alternativ hypoteser, eller et mix af disse?  
8. Hvad bliver 90% konfidensintervallet for den gennemsnitlige omsætning i populationen? Er dette konfidensinterval smallere eller bredere end 95% konfidensintervallet?  
9. En revisionsteam har en begrundet formodning om at den gennemsnitlige omsætning i populationen kan antages at være 250 mio. DKK. Opstil hypoteser og undersøg på 5% signifikansniveau, om denne påstand kan antages at være korrekt, bestem herunder signifikanssandsynligheden og hold denne op mod signifikansniveauet.  
10. Kunne revisorteamet ud fra teststørrelsen afgøre at man ikke kunne forkaste nulhypotesen?
11. Test på 10% signifikansniveau, om den gennemsnitlige omsætning i populationen kan antages at være 250 mio. DKK, bestem herunder signifikanssandsynligheden og hold denne op mod signifikansniveauet.  
12. Er konklusionen niveaufølsom?  
13. Test om den gennemsnitlige omsætning i populationen er højst 250 mio. DKK?  
14. Test på 1% signifikansniveau om den gennemsnitlige omsætning i populationen er højst 250 mio. DKK?  
15. Test om den gennemsnitlige omsætning i populationen er mindst 600 mio. DKK?  
16. Test på 1% signifikansniveau om den gennemsnitlige omsætning i populationen er mindst 600 mio. DKK?  
</details>  

<br>
<details> 
  <summary> Svar Hypotesetests danske virksomheders omsætning.</summary>

Herunder ses histogrammet for omsætning for de danske virksomheder, vi kan af histogrammet se at fordelingen er stærkt højreskæv og leptokurtisk. Der er endnu tydeligere outliers end for variablen egenkapital, dvs kæmpe  virksomheder med høj omsætning.  


```{r egenkapital1,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
hc <- ggplot(data=dkvirk, aes(dkvirk$Omsætning)) + 
  
  geom_histogram( binwidth=100000,
                 col="white", 
                 aes(fill=..count..)) +
                stat_bin(binwidth=100000, geom="text", aes(label=..count..), vjust=-1.5,size=2)+
  scale_fill_gradient("Antal", low = "lightgrey", high = "black") +
  scale_size_area() + 
  xlab("Omsætning i antal 1000 DKK.") +
  ylab("Hyppighed") +
  ggtitle("Histogram over omsætning i antal 1000 DKK.")
plot(hc)
```
1. Variablen Omsætning er en kvanitativ, kontinuert variabel, ratioskala, vi kan således benytte fanen 1 Kvantitativ stikprøve i Freestat.  
2. Standardfejlen for middelværdien bliver $SEM=\frac{\sigma}{\sqrt{n}}=\frac{1.829.195.752}{\sqrt{369}}=95.224.127$ DDK eller ca. 95 mio.  
3. Vi kan med 95% sikkerhed sige at den gennemsnitlige omsætning i populationen ligger mellem 240.136 og 614.639 1.000 DKK. Dette er et meget stort spænd fra ca 240 til 615 mio. DKK. Dette skyldes den store variation i data, hvilket øger standardfejlen som påvirker grænserne i konfidensintervallet. Nedre grænse findes fx. som $427.387.680-1.9664\cdot95.224.127$ Den typiske afvigelse fra middelværdien er da også 1.829.196 1000 DKK, altså næsten 2 mia DKK i datafordelingen. Herunder ses output fra Freestat, bemærk vi sætter signifikansniveauet i den hvide celle til 5% for at ændre konfidensniveaet til 95%.  
<img src="img/dkvirkoms5.png" alt="dkvirkoms5" align="middle" width="80%" height="80%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
4. Nej, da den gennemsnitlige omsætning i populationen med 95% sikkerhed ligger mellem 240 til 615 mio. DKK, og 500 mio. DKK er indeholdt i dette interval. Kan vi ikke afvise en antagelse om at den gennemsnitlige omsætning skulle være 500 mio. DKK.  
Hypoteserne ville være:  
$$H_0: \mu=500\ mio.$$  
$$H_1: \mu\neq500\ mio.$$  
Vi kan således ikke forkaste nulhypotesen, og konkluderer den gennemsnitlige omsætning i populationen kan antages at være 500 mio.  
5.  Nej, da den gennemsnitlige omsætning i populationen med 95% sikkerhed ligger mellem 240 til 615 mio. DKK, og 600 mio. DKK er indeholdt i dette interval, kan vi ikke afvise en antagelse om at den gennemsnitlige omsætning skulle være 600 mio. DKK.  
Hypoteserne ville være:  
$$H_0: \mu=600\ mio.$$  
$$H_1: \mu\neq600\ mio.$$  
Vi kan således ikke forkaste nulhypotesen, og konkluderer den gennemsnitlige omsætning i populationen kan antages at være 600 mio.  
6. Ja, da den gennemsnitlige omsætning i populationen med 95% sikkerhed ligger mellem 240 til 615 mio. DKK, kan vi afvise en antagelse om at den gennemsnitlige omsætning skulle være 700 mio. DKK.
Hypoteserne ville være:  
$$H_0: \mu=700\ mio.$$  
$$H_1: \mu\neq700\ mio$$  
Vi forkaster nulhypotesen, og konkluderer den gennemsnitlige omsætning i populationen, ikke kan antages at være 700 mio.  
7. Alle tre tests har tosidede alternativ hypoteser, alle tre indeholder forskellig fra operatoren $\neq$  
8. Vi kan med 90% sikkerhed sige at den gennemsnitlige omsætning i populationen ligger mellem 
270.363 og 584.413 1.000 DKK. Dette konfideninterval er altså smallere end 95% konfidensintervallet, hvilket giver god mening nu har hver hale 5% af sandsynligheden mod 2.5% før. Vi er jo også kun 90% sikre på at $\mu$ ligger i intervallet. Ønsker man smallere konfidensinterval øget præcision, uden at øge stikprøvestørrelsen kan man således slække på konfidensniveauet. Herunder ses output fra Freestat, bemærk vi ændrer signifikansniveauet i den hvide celle til 10% for at ændre konfidensniveaet til 90%.  
<img src="img/dkvirkoms10.png" alt="dkvirkoms10" align="middle" width="80%" height="80%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
9. Testet bliver:  
$$H_0:\mu=250\ mio.$$  
$$H_0:\mu\neq250\ mio.$$  
Af nedenstående output fra Freestat ses at p-værdien bliver 6.33%, hvilket lige er større end 5% signifikansniveauet. Vi kan altså ikke forkaste nulhypotesen. Vi kan ikke afvise revisorteamets påstand om at den gennemsnitlige omsætning er 250 mio. DKK. Bemærk husk at sætte de hvide felter, signifikansniveau til 5% og Test middel af populationen til 250000 1000 DKK.  
<img src="img/dkvirkomshyp5.png" alt="dkvirkomshyp5" align="middle" width="80%" height="80%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
10 Ja, da alternativhypotesen er tosidet skal teststørrelsen ligge mellem -1.9664 og 1.9664 svarende til 2.5% og 97.5% fraktilerne for t-fordelingen med 368 frihedsgrader. Man kan se den numeriske værdi af disse i Excel med kommandoen =TINV(5%;368). Teststørrelsen er angivet i Freestat til 1.8628 denne er således ikke så stor at det er kritisk for nulhypotesen, men teststørrelsen er dog tæt på den øvre grænse, hvilket tydeligere illustreres af at p-værdien er tæt på 5%.  
11 Testet bliver:  
$$H_0:\mu=250\ mio.$$  
$$H_0:\mu\neq250\ mio.$$  
Af ovenstående output fra Freestat ses at p-værdien bliver 6.33%, hvilket er mindre end 10% signifikansniveauet. Vi må forkaste nulhypotesen. Vi afviser revisorteamets påstand om at den gennemsnitlige omsætning er 250 mio. DKK. Bemærk husk at sætte de hvide felter, signifikansniveau til 10% og Test middel af populationen til 250000 1000 DKK. 
12 Ja konklusionen er niveaufølsom, p-værdien betyder vi forkaster nulhypotesen på 10% signifikansniveau, men ikke på 5% signifikansniveau.  
13. Vi kan oversætte højst til symbolet $\leq$, da symbolet indeholder lighedstegn, skal det i nulhypotesen. Da signifikansniveauet ikke er angivet tester vi på 5% signifikansniveau.  
Testet bliver:  
$$H_0:\mu\leq 250\ mio.$$  
$$H_1:\mu>250\ mio.$$  
Af output fra Freestat under svar 11 test nr. 2, ses at p-værdien bliver 3.16%, hvilket er mindre end 5% signifikansniveauet. Vi må forkaste nulhypotesen. Vi afviser nulhypotesen om at den gennemsnitlige omsætning er højst 250 mio. DKK. Vi konkluderer at den gennemsnitlige omsætning er signifikant større end 250 mio. DKK.  
14. Testet bliver ligesom i 13 igen:  
$$H_0:\mu\leq 250\ mio.$$  
$$H_1:\mu>250\ mio.$$  
Af output fra Freestat ses som før at p-værdien bliver 3.16%, hvilket er større end 1% signifikansniveauet. Vi kan ikke forkaste nulhypotesen. Vi kan ikke afvise nulhypotesen om at den gennemsnitlige omsætning er højst 250 mio. DKK. Vi konkluderer at den gennemsnitlige omsætning er højst end 250 mio. DKK. Når vi har 1% signifikansniveau, skal her mere til at vi forkaster nulhypotesen, p-værdien skal være mindre end 1% i modsætning til før hvor p-værdien skulle være mindre end 5%.  
15. Vi kan oversætte mindst til symbolet $\geq$, da symbolet indeholder lighedstegn, skal det i nulhypotesen. Da signifikansniveauet ikke er angivet tester vi på 5% signifikansniveau.
Testet bliver:  
$$H_0:\mu\geq 600\ mio.$$  
$$H_1:\mu<600\ mio.$$  
Vi får følgende output fra Freestat:  
<img src="img/freestat600hyp.png" alt="freestat600hyp" align="middle" width="80%" height="80%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
Vi får en p-værdi på 3.53%, hvilket er mindre end 5% signifikansniveauet. Vi kan altså afvise nulhypotesen om at den gennemsnitlige omsætning er mindst 600 mio. DKK.  
16. Testet bliver ligesom i 15 igen:  
$$H_0:\mu\geq 600\ mio.$$  
$$H_1:\mu<600\ mio.$$  
Af output fra Freestat under svar 15 test nr. 3, ses at p-værdien bliver 3.53%, hvilket er større end 1% signifikansniveauet. Vi kan altså ikke forkaste nulhypotesen. Vi konkluderer at den gennemsnitlige omsætning er mindst 600 mio. DKK. Når vi har 1% signifikansniveau, skal her mere til at vi forkaster nulhypotesen, halen bliver jo mindre. Konklusionen er niveaufølsom.  

</details>  

<br>
<details> 
  <summary> Spørgsmål Eksamen Januar 2015 spørgsmål 2.1 og 2.2 Finansøkonom.</summary>


ABC-Bank, som er en større udenlandsk bank, overvejer at etablere sig i Danmark.
Men ABC-Bank har indtryk af, at det danske bankmarked er kendetegnet ved relativt mange filialer og bankansatte i forhold til antallet af kunder. Inden den endelige beslutning træffes, ønsker ABC- Banks bestyrelse derfor en analyse af bankmarkedet Danmark.  
Man tilfældigt udvalgt 24 danske banker og undersøgt følgende:  
1. Antal nye kunder i 3. kvartal 2014 - Netto tilgang af kunder i kvartalet.  
2. Antal medarbejdere pr. 1.000 kunder - Gennemsnitligt antal fuldtidsansatte delt med samlet antal privat- og erhvervskunder målt i tusinder. Tallene stammer fra de 24 bankers årsrapporter 2013.  
3. Rente på en almindelig indlånskonto - Bankens annoncerede indlånsrente på en anfordringskonto ved udgangen af 3. kvartal 2014.  
4. Rente på boliglån - Bankens annoncerede rente på boliglån ved udgangen af 3. kvartal 2014.  
5. Har banken samarbejde med en ejendomsmægler/mæglerkæde - 0 angiver ikke samarbejde 1 angiver samarbejde  

Resultaterne af ABC-Banks dataindsamling vises i Excel-filen [2015 Januar Data.xlsx](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldkt1OUx6LTEyMXM). Du bedes med udgangspunkt i disse resultater besvare nedenstående opgaver.  
I bedømmelsen bliver der lagt vægt på, at du argumenterer for dine valg af løsningsmetoder, undersøger om eventuelle forudsætninger er opfyldt samt fortolker dine resultater.  

Opgave 2  
På ABC-Banks hjemmemarked har banken 4,9 ansatte pr. 1.000 kunder. Bestyrelsen vil gerne have undersøgt, om der virkelig er flere ansatte pr. 1.000 kunder i danske banker.  
Spørgsmål 2.1 (10 %)  
Du bedes teste på 5 % signifikansniveau om det gennemsnitlige antal ansatte pr. 1.000 kunder er over 4,9 i danske banker.  
Forskellen på kundesammensætningen i filialerne påvirker behovet for ansatte i forhold til antal kunder. Bestyrelsen i ABC-Bank vil gerne vide, hvor stor variation der er i antal ansatte pr. 1.000 kunder.  
Spørgsmål 2.2 (10 %)  
Du bedes derfor udarbejde et 95 % konfidensinterval for standardafvigelsen for antal ansatte pr. 1.000 kunder i de danske banker.  
</details>  

<br>
<details> 
  <summary> Svar Eksamen Januar 2015 spørgsmål 2.1 og 2.2 Finansøkonom.</summary>

Opgave 2.1  
Bemærk da antallet af observationer i stikprøven er mindre end 30 skal vi sikre os at data er approximativt normalfordelte. Dette afgøres vha. QQ plot, hvor vi ser at observationerne ligger nogenlunde på en ret linje.  
<img src="img/freestatjan2015qq.png" alt="freestatjan2015qq" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Vi indsætter data i Freestat i fanen 1 kvantitativ stikprøve:  

Af teksten ses:  

"der virkelig er **flere** ansatte pr. 1.000 kunder"  

Vi ved således vi skal benytte større end >, symbolet er uden lighedstegn dette hører derfor til i alternativ hypotesen. Altså skal vi benytte $\leq$ i nulhypotesen. Testet bliver således:  

$$H_0:\mu\leq 4.9$$  
$$H_1:\mu> 4.9$$  


<img src="img/freestatjan2015hyp.png" alt="freestatjan2015hyp" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Da signifikanssandsynligheden/p-værdien er 0.0077 mindre end signifikans niveauet 5% forkaster vi nulhypotesen.  
Antal ansatte pr. 1000 kunder er altså større end 4.9.  
Opgave 2.2  
Vi kan med 95% sikkerhed sige at standardafvigelsen i populationen ligger mellem 0.3500 og 0.6317
<img src="img/freestatstdki.png" alt="freestatstdki" align="left" width="60%" height="60%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
</details>  

<br>
<details> 
  <summary> Spørgsmål US aktier</summary>



I datasættet  <a href="https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldVZtS2tzV0RqVjQ" target="_blank">USA aktier</a> findes månedlige aktieafkast i %, fra 5 store amerikanske virksomheder siden år 2000. Virksomhederne er Coca Cola, Bank of America, JP Morgan Chase, Microsoft og Kellogs den sidste variabel US portefølje er en portefølje bestående at 20% af hver af disse 5 aktier. Vi forudsætter at stikprøven er repræsentativ for populationen. Angiv korte præcise svar, angiv hypoteser, p-værdier teknisk og ikke-teknisk konklusion hvor det er relevant.  

1.	Angiv 95% konfidensintervallet for middelværdien for Bank of America og for US porteføljen.  

2.	Angiv 95% konfidensintervallet for standardafvigelsen for Bank of America og for US porteføljen.  

3.	Angiv mindste og største månedlige afkast for Bank of America og for US porteføljen.  

4.	Test om det gennemsnitlige afkast for Bank of America er mindst 1%?  

5.	Test om det gennemsnitlige afkast for US porteføljen er mindst 1%?  

6.	Undersøg om vi kan være sikre på (5% signifikansniveau), at det gennemsnitlige afkast for Bank of America er større end 0%?  

7.	Undersøg om vi kan være sikre på (5% signifikansniveau), at det gennemsnitlige afkast for US porteføljen er større end 0%?  

8.	Test på 1% signifikansniveau om standardafvigelsen er højst 5% for Bank of America afkastet.    

9.	Test på 1% signifikansniveau om standardafvigelsen er højst 5% for US portefølje afkastet.  

Ville du helst investere i US porteføljen eller en af aktierne i dag? angiv en kort begrundelse.  


</details>  

<br>
<details> 
  <summary> Svar US aktier</summary>
Du kan se en videogennemgang af opgaven [her](https://youtu.be/jAPfCsEvndE)  


Du kan hente løsningen til opgaven <a href="https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlSDNPZi1zSTlqNk0" target="_blank">hent USA aktier løsning</a>  

</details>  

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=56" target="_blank">Selvtest konfidensinterval og middelværdi med videoløsning.</a></h2> 

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=51" target="_blank">Selvtest middel Dow Jones med videoløsning.</a></h2> 

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=67" target="_blank">Selvtest normalfordelingen med videoløsning</a></h2>





# 1 Andel


<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->


## Parameterestimat for andele

Hvis vi har spurgt 100 danskere om de bruger MobilePay, er vi ikke specifikt interesseret i hvor mange af netop disse 100 personer, der benytter MobilePay. Vi har udtaget en stikprøve af en population (populationen er her alle danskere med en konto), som vi benytter til at udtale os om, hvor stor en andel i populationen, der kan antages at benytte MobilePay. Hvis 31 ud af 100 danskere bruger MobilePay, er vores bedste gæt på andelen i populationen der benytter MobilePay 0.31. Vi er imidlertid godt klar over, at det ville være højst besynderligt, at netop 31,000...% af alle danskere benytter MobilePay. Vi kalder $\hat{p}$ for vores estimat (vores bedste gæt) på populationsandelen $p$ "den sande ukendte andel af kontohavere der benytter MobilePay". 

$$Parameterestimatet\  for\  p\ er\ \hat{p} = \frac{31}{100}=0.31$$  

Vi betragter nu igen Tryg aktien i datasættet<a href="DK aktiekurser.xlsx" download> DK aktiekurser hentes her </a>. Vi vil nu se på andelen af dage hvor der var et positivt afkast, `r length(which(DKdf[,1]>0))` dage ud af `r length(DKdf[,1])` dage var der et positivt afkast.

Vi kan nu bestemme parameterestimatet for p den sande andel af dage med overskud i Tryg aktien.
$$\hat{p}=\frac{x}{n}=\frac{`r length(which(DKdf[,1]>0))`}{`r length(DKdf[,1])`}=`r round(length(which(DKdf[,1]>0))/length(DKdf[,1]),2)`$$

Bemærk at den kvantitative kontinuerte variabel dagligt afkast for Trygaktien, blev omdannet til en kvalitativ binær variabel, når vi i stedet for dagligt afkast kun ser på positivt/ikke positivt afkast. Vores stikprøve fra populationen, skal være respræsentativ for populationen. Det er tvivlsomt om denne forudsætning er opfyldt, for aktier vil konjunkturer have en vis overordnet indflydelse på kursen. Vores stikprøve stammer jo fra en bestemt periode, en repræsentativ stikprøve, burde således være udtrukket tilfældigt blandt alle registrerede dagsafkast af aktien.




## Konfidensinterval for en andel
Konfidensinterval for en andel beregnes som:

$$(1-\alpha)\  KI=\left[\hat{p} - z_{1-\frac{\alpha}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}};\hat{p} + z_{1-\frac{\alpha}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}\right]$$

Hvor $z_{1-\frac{\alpha}{2}}$ er $1-\frac{\alpha}{2}$ fraktilen for z-fordelingen altså standard normalfordelingen. Hvis vi betragter et 95% konfidensinterval, er $\alpha$ altså signifikansniveauet 5%, det betyder vi benytter $1-\frac{0.05}{2}=0.975$ fraktilen eller 97.5% fraktilen for z-fordelingen 

Vi ser igen på MobilePay eksemplet 31 ud af 100 brugte MobilePay $\hat{p}=0.31$. Hvis vi skal bestemme et 95% konfidensinterval af andelen af brugere af MobilePay i populationen, kan vi vha. formlen ovenfor udregne nedre grænse som:

$$\hat{p} - z_{1-\frac{\alpha}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$0.31-1.96\cdot\sqrt[]{\frac{0.31(1-0.31)}{100}}=0.2194$$

På samme måde kan vi beregne vi øvre grænse vha. formlen for konfidensinterval for en andel.

$$\hat{p} + z_{1-\frac{\alpha}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$0.31+1.96\cdot\sqrt[]{\frac{0.31(1-0.31)}{100}}=0.4006$$

Hvis vi skal tolke hvad dette betyder med menneskeord kan vi altså sige:  

*Vi kan med 95% sikkerhed sige at andelen af MobilePay brugere i populationen ligger mellem 21.94% og 40.06%.*

Havde vi ønsket større sikkerhed/konfidens, kunne vi opnå dette på bekostning af præcisionen. Vi kunne sætte signifikansniveauet til 1% dvs. konfidensniveauet til 99%. Vi skulle da benytte 99.5% fraktilen for z-fordelingen denne er ca. 2.58, dette ville være den eneste ændring i udregningen af konfidensintervallet.

$$\hat{p} - z_{1-\frac{\alpha}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$0.31-2.5758\cdot\sqrt[]{\frac{0.31(1-0.31)}{100}}=0.1909$$

På samme måde kan vi beregne vi øvre grænse vha. formlen for konfidensinterval for en andel.

$$\hat{p} + z_{1-\frac{\alpha}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$0.31+2.5758\cdot\sqrt[]{\frac{0.31(1-0.31)}{100}}=0.4291$$

Tolkningen ville være:  

*Vi kan med 99% sikkerhed sige at andelen af MobilePay brugere i populationen ligger mellem 19.09% og 42.91%.*

Vi mister altså præcision (konfidensintervallet blev jo bredere), når vi får større sikkerhed (99% i stedet for 95%). Hvis man ønsker at øge sikkerheden uden at konfidensintervallet bliver bredere, kan man se på formlen at vi også kan øge stikprøve størrelsen n. Stikprøve størrelsen er jo i nævneren i formlen for konfidensintervallet, så hvis vi øger n bliver faktoren mindre, og dermed bliver konfidens intervallet smallere.

### Fejlmargin ved andele

Fejlmarginen er den halve længde af konfidensintervallet, denne kan altså i sidste eksempel beregnes som:

$$\frac{0.4291-0.1909}{2}=0.1191$$

Eller direkte ved formlen:
$$z_{1-\frac{\alpha}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$2.5758\cdot\sqrt[]{\frac{0.31(1-0.31)}{100}}=0.1191$$

## Eksempler, konfidensinterval for andele  


### Tryg aktien

```{r echo=FALSE,results="hide"}
phat=round(length(which(DKdf[,1]>0))/length(DKdf[,1]),4)

CIlow <- function(a,s,n) round(s/n+qnorm(a/200)*((s/n*(1-s/n))/n)^0.5,4)
CIup <- function(a,s,n) round(s/n-qnorm(a/200)*((s/n*(1-s/n))/n)^0.5,4)

```

Vi fandt tidligere parameterestimatet for p den sande andel af dage med overskud i Tryg aktien som:

$$\hat{p}=\frac{x}{n}=\frac{`r length(which(DKdf[,1]>0))`}{`r length(DKdf[,1])`}=`r phat` $$


Vi kender antallet af succeser dvs gunstige udfald `r length(which(DKdf[,1]>0))`, ud af den totale stikprøvestørrelse $n=`r length(DKdf[,1])`$. Vi kan nu ved at indsætte i formlen for KI for andele bestemme et 95% KI (det betyder $\alpha=5\%$).

Den nedre grænse bliver:

$$\hat{p}-z_{1-\frac{0.05}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$`r phat`-1.96\cdot\sqrt[]{\frac{`r phat`(1-`r phat`)}{100}}=`r CIlow(5,length(which(DKdf[,1]>0)),length(DKdf[,1]))`$$

Den øvre grænse bliver:

$$\hat{p}+z_{1-\frac{0.05}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$`r phat`+1.96\cdot\sqrt[]{\frac{`r phat`(1-`r phat`)}{100}}=`r CIup(5,length(which(DKdf[,1]>0)),length(DKdf[,1]))`$$

Vi kan altså med 95% sikkerhed sige, at andelen af dage med overskud i Tryg aktien i populationen ligger mellem `r CIlow(5,length(which(DKdf[,1]>0)),length(DKdf[,1]))*100`% og `r CIup(5,length(which(DKdf[,1]>0)),length(DKdf[,1]))*100`%

Vi kan, hvis vi ønsker at finde 90% KI, blot ændre z-fraktilen fra 97.5% til 95%, dvs. fra 1.96 til 1.6448.
Den nedre grænse bliver:

$$\hat{p}-z_{1-\frac{0.1}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$`r phat`-1.6448\cdot\sqrt[]{\frac{`r phat`(1-`r phat`)}{100}}=`r CIlow(10,length(which(DKdf[,1]>0)),length(DKdf[,1]))`$$

Den øvre grænse bliver:

$$\hat{p}+z_{1-\frac{0.1}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$`r phat`+1.6448\cdot\sqrt[]{\frac{`r phat`(1-`r phat`)}{100}}=`r CIup(10,length(which(DKdf[,1]>0)),length(DKdf[,1]))`$$

Vi kan altså med 90% sikkerhed sige, at andelen af dage med overskud i Tryg aktien i populationen ligger mellem `r CIlow(10,length(which(DKdf[,1]>0)),length(DKdf[,1]))*100`% og `r CIup(10,length(which(DKdf[,1]>0)),length(DKdf[,1]))*100`%

99% KI findes ved at benytte 0.995 z-fraktilen der er 2.5758
Den nedre grænse bliver:

$$\hat{p}-z_{1-\frac{0.01}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$`r phat`-2.5758\cdot\sqrt[]{\frac{`r phat`(1-`r phat`)}{100}}=`r CIlow(1,length(which(DKdf[,1]>0)),length(DKdf[,1]))`$$

Den øvre grænse bliver:

$$\hat{p}+z_{1-\frac{0.01}{2}}\cdot \sqrt[]{\frac{\hat{p}(1-\hat{p})}{n}}=$$
$$`r phat`+2.5758\cdot\sqrt[]{\frac{`r phat`(1-`r phat`)}{100}}=`r CIup(1,length(which(DKdf[,1]>0)),length(DKdf[,1]))`$$

Vi kan altså med 99% sikkerhed sige, at andelen af dage med overskud i Tryg aktien i populationen ligger mellem `r CIlow(1,length(which(DKdf[,1]>0)),length(DKdf[,1]))*100`% og `r CIup(1,length(which(DKdf[,1]>0)),length(DKdf[,1]))*100`%



## Spørgsmål konfidensinterval andele

<br>
<details> 
  <summary> Spørgsmål konfidensinterval andel utroskab</summary>
  

I linket her er filen [Fairs Affairs](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRlVQcFBtdVlHZ1U), filen indeholder data fra en kendt undersøgelse af 601 respondenters svar på blandt andet om og hvor ofte de har været utro. Bestem konfidensintervaller for andelen i populationen der er utro (utro er når antallet af affærer er større end nul).  

```{r echo=FALSE}
list.of.packages <- c("readxl")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(readxl)
Aff <- read_excel("/cloud/project/FILER/AFFAIRS.xls",1)
n1 <- length(which(Aff[,2]>0))
n01 <- length(Aff[[2]])
phat <- n1/n01
```

</details>  
<br>
<details> 
  <summary> Svar konfidensinterval andel utroskab</summary>

Du skulle gerne komme frem til at `r n1` respondenter ud af `r n01` har været utro, hvilket giver et parameter estimat for andelen af utro i populationen $\hat{p}=`r phat`$.
Konfidensintervallerne kan tolkes som.  

Vi kan med 90% sikkerhed sige at andelen af utro i populationen ligger mellem `r CIlow(10,n1,n01)*100`% og `r CIup(10,n1,n01)*100`%.  

Vi kan med 95% sikkerhed sige at andelen af utro i populationen ligger mellem `r CIlow(5,n1,n01)*100`% og `r CIup(5,n1,n01)*100`%.  

Vi kan med 99% sikkerhed sige at andelen af utro i populationen ligger mellem `r CIlow(1,n1,n01)*100`% og `r CIup(1,n1,n01)*100`%.  

Konfidensintervallerne forudsætter som vanligt at stikprøven er repræsentativ for populationen, hvilket kan sikres ved simpel tilfældig udvælgelse.  

</details>  
<br>
<details> 
  <summary> Spørgsmål konfidensinterval andel køn bankdata</summary>
  

```{r echo=FALSE}
bank <- read_excel("/cloud/project/FILER/BANKDATA.xls",1)
n1 <- length(which(bank[,4]=="female"))
n01 <- length(bank[[4]])
phat <- n1/n01
```


I linket  [bankdata](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM), findes data på funktion, antal års uddannelse, køn og race for 474 amerikanske bankansatte. Bestem konfidensintervaller for andelen i populationen der er kvinder.

</details>  
<br>
<details> 
  <summary> Svar konfidensinterval andel køn bankdata</summary>


Vi betragter nu andelen af kvinder blandt de bankansatte. Du skulle gerne komme frem til at `r n1` respondenter ud af `r n01` er kvinder, hvilket giver et parameter estimat for andelen af kvinder i populationen $\hat{p}=`r phat`$.

Vi kan med 90% sikkerhed sige at andelen af kvinder i populationen ligger mellem `r CIlow(10,n1,n01)*100`% og `r CIup(10,n1,n01)*100`%.

Vi kan med 95% sikkerhed sige at andelen af kvinder i populationen ligger mellem `r CIlow(5,n1,n01)*100`% og `r CIup(5,n1,n01)*100`%.

Vi kan med 99% sikkerhed sige at andelen af kvinder i populationen ligger mellem `r CIlow(1,n1,n01)*100`% og `r CIup(1,n1,n01)*100`%.

Konfidensintervallerne forudsætter at stikprøven er repræsentativ for populationen.  
</details>  
<br>
<details> 
  <summary> Spørgsmål konfidensinterval andel minoriteter bankdata</summary>


```{r echo=FALSE, include=FALSE}
n1 <- length(which(bank[,5]=="yes"))
n01 <- length(bank[[5]])
phat <- n1/n01
```
Vi betragter fortsat bankdata. Estimer for populationen andelen af ikke hvide dvs. minoriteter, på hhv. 0.1, 0.05 og 0.01 signifikansniveauet.  

</details>  
<br>
<details> 
  <summary> Svar konfidensinterval andel minoriteter bankdata</summary>

Konfidensintervallerne bliver:  

Vi kan med 90% sikkerhed sige at andelen af minoriteter i populationen ligger mellem `r CIlow(10,n1,n01)*100`% og `r CIup(10,n1,n01)*100`%.  

Vi kan med 95% sikkerhed sige at andelen af minoriteter i populationen ligger mellem `r CIlow(5,n1,n01)*100`% og `r CIup(5,n1,n01)*100`%.  

Vi kan med 99% sikkerhed sige at andelen af minoriteter i populationen ligger mellem `r CIlow(1,n1,n01)*100`% og `r CIup(1,n1,n01)*100`%.  


</details>  
<br>
<details> 
  <summary> Spørgsmål konfidensinterval andel ledelse bankdata </summary>



```{r echo=FALSE}
n1 <- length(which(bank[,2]=="manage"))
n01 <- length(bank[[2]])
phat <- n1/n01
```
Vi betragter fortsat bankdata. Estimer for populationen andelen af ansatte i ledelsesfunktioner (dvs. manage), på hhv. 0.1, 0.05 og 0.01 signifikansniveauet.  

</details>  
<br>
<details> 
  <summary> Svar konfidensinterval andel bankdata </summary>
Konfidensintervallerne bliver:  


Vi kan med 90% sikkerhed sige at andelen af ansatte i ledelsesfunktioner i populationen ligger mellem `r CIlow(10,n1,n01)*100`% og `r CIup(10,n1,n01)*100`%.  

Vi kan med 95% sikkerhed sige at andelen af ansatte i ledelsesfunktioner i populationen ligger mellem `r CIlow(5,n1,n01)*100`% og `r CIup(5,n1,n01)*100`%.  

Vi kan med 99% sikkerhed sige at andelen af ansatte i ledelsesfunktioner i populationen ligger mellem `r CIlow(1,n1,n01)*100`% og `r CIup(1,n1,n01)*100`%.   

</details>  

## Hypotesetest 1 andel

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/225968110' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>  

Når vi tester en hypotese, undersøger vi om en egenskab ved en populationsparameter (eller flere parametre) er opfyldt. Vi siger i udgangspunktet at nulhypotesen er sand, så der skal vægtige grunde til at vi forkaster (afviser) denne. Nulhypotesen kan fx. være:  

Andelen p er lig med 50%, dette skriver vi som: 

$$H_0: p=0.5$$

Bemærk en nulhypotesen indeholder altid udsagnet med lighedstegnet.

Alternativ hypotesen er altid det modsatte udsagn, det vil altså sige:

Andelen er ikke lig med 50% 

Vores alternativ hypotese skrives som:

$$H_1: p \neq 0.5$$

eller

$$H_a: p \neq 0.5$$

Husk når vi tester en hypotese, er det altid parameteren vi skriver i hypoteserne, ALDRIG parameterestimaterne. Vi ved jo præcis hvad andelen i stikprøven er, derfor ved vi præcis hvad $\hat{p}$ er, derfor giver det ingen mening at teste dette.

## Hypotesetest en andel, tosidet alternativ hypotese

Vi fandt i en stikprøve at 31 ud af 100 brugte MobilePay i Freestat test af andele taster vi:  

<img src="img/mobilepay.jpg" align="right" width="30%" height="30%"/><br><br>  










Kan vi sige at andelen af MobilePay brugere i populationen er 35%? For at undersøge dette opstiller vi nul- og alternativhypotesen.

$$H_0: p = 0.35$$

$$H_1: p \neq 0.35$$

Vi siger at alternativhypotesen er tosidet, da både stikprøve resultater, væsentlig mindre og større end 0.35, medfører at vi forkaster nulhypotesen.

Vi taler om at forkaste nulhypotesen, eller at vi ikke kan forkaste nulhypotesen. Vi skriver helst ikke vi accepterer nulhypotesen. Det ville jo strengt taget betyde vi mente $p=0.3500000...$

Notationen er lidt forskellig for værdien af andelen 0.35, vi ønsker at teste, nogle bøger benævner den $\pi$, her kalder vi den $p_0$.

Stikprøven er tilstrækkelig stor da $n\cdot\hat{p}(1-\hat{p})=100\cdot0.31(1-0.31)=21.39$ er større end 9. Approximationsbetingelsen er altså opfyldt.  

### z-teststørrelsen
Hvis vi ikke kan afvise nulhypotesen betyder det at den sande populations parameter p er $p=p_0$. Så gælder fra CLT, at stikprøvefordelingen er normalfordelt med middelværdi $\mu=p_0$. Vi ved at standardfejlen for andele SE er:

$$\sqrt{\frac{p_0(1-p_0)}{n}} = \sqrt{\frac{0.35(1-0.35)}{100}}=`r round(((0.35*0.65)/100)^.5,4)`$$  


Vi ønsker at teste om andelen i populationen, der bruger MobilePay, kan antages at være 35%, derfor ønsker vi at måle hvor stor forskellen er mellem den observerede andel 31% og hypotese andelen $P_0$ 35%. Til dette bruger vi z-teststørrelsen.  


```{r pnormfunktion, echo=FALSE}
ptest <- function(x,n,p0) list(z = (x/n-p0)/((p0*(1-p0))/n)^0.5, pv = pnorm((x/n-p0)/((p0*(1-p0))/n)^0.5))
```

$$z-score=\frac{\hat{p}-p_0}{SE}=\frac{0.31-0.35}{0.0462}=`r round(ptest(31,100,0.35)$z,4)`$$  


Når vi bestemmer teststørrelsen ser vi på forskellen mellem $\hat{p}$ og $p_0$. Vi skalerer teststørrelsen til standard normalfordelingen ved at dividere med standardfejlen . Her bruges z-fordelingen dvs. standard normalfordelingen. Vi kalder teststørrelsen for z-teststørrelsen eller z-scoren. Andre tests hvor man benytter fx. t-fordelingen eller F-fordelingen, kaldes t-teststørrelsen og F-teststørrelsen.

Vi bemærker teststørrelsen er negativ, da parameter estimatet $\hat{p}=0.31$ er mindre end $p_0=0.35$. z-teststørrelsen er tilpasset til standard normalfordelingen, det betyder vi kan sammenligne denne med nedre og øvre grænser for KI i z-fordelingen. Når vi tester på 5% signifikansniveau, er den nedre og øvre grænse for 95% KI i z-fordelingen -1.96 og 1.96, vi har derfor en kritiske værdier -1.96 og 1.96. Når vi tester på 1% signifikansniveau, vi har  kritiske værdier -2.58 og 2.58 og på 10% signifikansniveau -1.64 og 1.64.

Teststørrelsen `r round(ptest(31,100,0.35)$z,4)`, ligger mellem -1.96 og  1.96, derfor vil vi ikke forkaste nulhypotesen på 5% signifikansniveau, i øvrigt heller ikke på 10% signifikansniveu. Det betyder vi kan ikke afvise, nulhypotesen.

I figuren nedenfor er indtegnet z-scoren, samt forkast ikke regionen samt forkast halerne når vi betragter 95% KI dvs. et 5% signifikansniveu.

```{r z-scoreensidetnedad1,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-1.96,1.96,length.out=200)
plot(x,y,type="l",main = "Acceptområde tosidet alternativ\n hypotese nedad",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-1.96,z,1.96),c(0,dnorm(z),0),col="grey90",border="NA")
grid()
text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=0,y=.1,"95%\nAfvis ikke\nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-2.4,y=0.01,label="2.5%",cex = .7)
text(x=2.4,y=0.01,label="2.5%",cex = .7)
segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
arrows( 3.2, 0.05,2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.96,-1.64,-0.84,0.84,1.64,1.96,5),cex.axis=0.7)

```








```{r OMX-data1,include=FALSE}
library("readxl")
ptest <- function(x,n,p0) list(z = (x/n-p0)/((p0*(1-p0))/n)^0.5, pv = pnorm((x/n-p0)/((p0*(1-p0))/n)^0.5))
```
#### 1 Andel fejlmargin og FPC
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226076060' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

## Hypotesetest en andel, ensidet alternativ hypotese nedad
Hvis vi baseret på MobilePay stikprøven i stedet havde spurgt:

Er andelen af MobilePay brugere i populationen mindre end 35%? 
Er andelen af MobilePay brugere i populationen mindst 35%? 

Begge disse udsagn leder hver sin vej til samme hypotese test. 

Andelen af MobilePay brugere i populationen er mindre end 35%?  
Kan omskrives til en alternativ hypotese
$$H_1:p<0.35$$
Bemærk da operatoren mindre end $<$ ikke indeholder et lighedstegn, ved vi at udsagnet skal skrives som en alternativ hypotese. Det komplementære udsagn er altså nulhypotesen:
$$H_0:p\geq 0.35$$

Andelen af MobilePay brugere i populationen er mindst 35%? 
Kan omskrives til nulhypotesen
$$H_0:p\geq 0.35$$
Det komplementære udsagn bliver:
$$H_1:p<0.35$$

Vi siger, vi har en ensidet alternativ hypotese, da kun stikprøveandele signifikant mindre end 0.35 ($H_1:p<0.35$), vil være kritiske for nulhypotesen. Det betyder at kun venstre hale i z-fordelingen vil medføre at vi forkaster nulhypotesen.

Vi får, som tidligere samme z-teststørrelse `r round(ptest(31,100,0.35)$z,4)`. Men som det ses af standard normalfordelingen i figuren nedenfor interesserer vi os kun for venstre hale.

```{r z-scoreensidetnedad2,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-1.64,5,length.out=200)
plot(x,y,type="l",main = "Acceptområde ensidet alternativ\n hypotese nedad",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-1.64,z),c(0,dnorm(z)),col="grey90",border="NA")
text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=-0.4,y=.1,"95%\nAfvis ikke\nnulhypotesen\nnår teststørrelsen er\ni dette interval",cex = .7)
text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-1.64,y=0.31,label="Kritisk værdi",cex = .7)
text(x=-2.4,y=0.01,label="5%",cex = .7)
segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
segments( -1.64,  0,   -1.64, 0.3,lty=3,lwd=1.5,col="red")
arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.64,-0.84,0.84,1.64,5),cex.axis=0.7)
grid()
```

Tilsvarende finder vi p-værdien ved:


```{r pvaerdiensidetned,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-0.84,5,length.out=200)
plot(x,y,type="l",main = "P-værdi ensidet alternativ\n hypotese nedad",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(-0.84,z),c(0,dnorm(z)),col="grey90",border="NA")
text(x=-3.5,y=0.1,"P-værdien=20.08%\nSandsynligheden,\nhvis p=0.35, for at\n andelen\ni en ny stikprøve er\nmindre end 0.31",cex = .7)
text(x=0,y=.1,"79.92% er\nsandsynligheden,\nhvis p=0.35,for at\n andelen\ni en ny stikprøve\ner større\nend 0.31",cex = .7)
text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=-1.64,y=0.31,label="Kritisk værdi",cex = .7)
text(x=-2.4,y=0.01,label="20.08%",cex = .7)
segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
segments( -1.64,  0,   -1.64, 0.3,lty=3,lwd=1.5,col="red")
arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.64,-0.84,0.84,1.64,5),cex.axis=0.7)
grid()
```

Da p-værdien er større end 5% er forskellen mellem stikprøvens andel 31% og den hypoteseværdien 35% ikke signifikant. Vi kan altså ikke afvise nulhypotesen, og konkluderer at andelen af Mobilepay brugere er mindst 35%. I Freestat vil vi altså vælge den 3. hypotesetest i test af andele, illustreret herunder.

<img src="img/freestattestpropmobilepayhyp.png"  width="50%" height="50%"style="border:0.0px solid #eeeeee; padding:0px; margin:0px;"/>


## Hypotesetest en andel, ensidet alternativ hypotese opad
Hvis vi baseret på MobilePay stikprøven i stedet havde spurgt:

Er andelen af MobilePay brugere i populationen større end 35%? 
Er andelen af MobilePay brugere i populationen højst 35%? 

Begge disse udsagn leder hver sin vej til samme hypotese test.  
Andelen af MobilePay brugere i populationen er større end 35%?  
Kan omskrives til en alternativ hypotese
$$H_1:p>0.35$$
Bemærk da operatoren større end $>$ ikke indeholder et lighedstegn, ved vi at udsagnet skal skrives som en alternativ hypotese. Det komplementære udsagn er altså nulhypotesen:
$$H_0:p\leq 0.35$$

Andelen af MobilePay brugere i populationen er højst 35%? 
Kan omskrives til nulhypotesen
$$H_0:p\leq 0.35$$
Det komplementære udsagn bliver:
$$H_1:p>0.35$$

Så begge udsagn fører altså til samme hypotesetest med ensidet alternativ hypotese opad
Vi siger, vi har en ensidet alternativ hypotese opad, da kun stikprøveandele signifikant større end 0.35 ($H_1:p>0.35$), vil være kritiske for nulhypotesen. Det betyder at kun højre hale i z-fordelingen vil medføre at vi forkaster nulhypotesen.

Vi får, igen samme z-teststørrelse `r round(ptest(31,100,0.35)$z,4)`. Men som det ses af standard normalfordelingen i figuren nedenfor interesserer vi os nu kun for højre hale.

```{r zscoreensidetop,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-5,1.64,length.out=200)
plot(x,y,type="l",main = "Acceptområde ensidet alternativ\n hypotese opad",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(z,1.64),c(dnorm(z),0),col="grey90",border="NA")
text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=-0.1,y=.1,"95%\nAfvis ikke\nnulhypotesen\nnår teststørrelsen er\ni dette interval",cex = .7)
text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=2.4,y=0.01,label="5%",cex = .7)
text(x=1.64,y=0.31,label="Kritisk værdi",cex = .7)
segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
segments( 1.64,  0,   1.64, 0.3,lty=3,lwd=1.5,col="red")
arrows( 3, 0.04, 2.7, 0.02,length=0.05,angle = 15)
axis(side = 1, at=c(-5,-1.64,-0.84,0.84,1.64,5),cex.axis=0.7)
grid()
```

Vi kan nu finde p-værdien som arealet af den hvide højre hale.

```{r pvaerdiplotensidetop,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(-5,5,length.out=200)
y <- dnorm(x)
z <- seq(-5,-0.84,length.out=200)
plot(x,y,type="l",main = "P-værdi ensidet alternativ\n hypotese opad",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(z,-0.84),c(dnorm(z),0),col="grey90",border="NA")
text(x=0.5,y=0.1,"P-værdien=79.92%\nSandsynligheden,\nhvis p=0.35, for at\n andelen\ni en ny stikprøve er\nstørre end 0.31",cex = .7)
text(x=-2,y=.1,"20.08% er\nsandsynligheden,\nhvis p=0.35,for at\n andelen\ni en ny stikprøve\ner mindre end 0.31",cex = .7)
text(x=-0.84,y=dnorm(0)*1.02,label="z-teststørrelsen",cex = .7)
text(x=2,y=0.01,label="79.92%",cex = .7)
text(x=1.64,y=0.31,label="Kritisk værdi",cex = .7)
segments( -0.84,  0,   -0.84, dnorm(0),lty=3,lwd=.9)
segments( 1.64,  0,   1.64, 0.3,lty=3,lwd=1.5,col="red")
axis(side = 1, at=c(-5,-1.96,-0.84,0.84,1.96,5),cex.axis=0.7)
grid()
```

Vi kan se der er stor forskel på teststørrelsen og den kritiske værdi, p-værdien det hvide areal er meget stort. Vi er her meget langt fra en p-værdi på 5%, så vi forkaster klart ikke nulhypotesen. Vi konkluderer at andelen af mobilepay brugere er højst 35%. 

<img src="img/testandelemobilepay.png" alt="testandelemobilepay" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  
I Freestat vil vi vælge den 2. hypotesetest i test af andele, hvilket ses på billedet ovenfor.  


<br>
<br>
<br>
<br>
<br>
<br>
   

## Spørgsmål hypotesetests 1 andel.  

<details> 
  <summary> Spørgsmål andelen af MobilePay brugere </summary>
Vi benytter fortsat undersøgelsen med 31 MobilePay brugere ud af 100 adspurgte.  
Kan man antage at andelen af MobilePay brugere er 25%?  
Angiv både hypoteser teststørrelse samt p-værdi. Angiv både en teknisk samt let forståelig konklusion.   

</details>  
<br>
<details>  
  <summary> Svar andelen af MobilePay brugere </summary>
  
Her bliver hypoteserne:    

$H_0: p=0.25$  

$H_1:p\neq 0.25$  

z-teststørrelsen bliver her:  
`r ptest(31,100,0.25)$z`

p-værdien altså signifikanssandsynligheden bliver:  
`r round(2*(1-ptest(31,100,0.25)$pv),4)`

Da der ikke er angivet et signifikansniveau sættes dette til 5%.  

Da `r round(2*(1-ptest(31,100,0.25)$pv),4)`>0.05 kan vi ikke afvise nulhypotesen. Det betyder vi kan ikke afvise nulhypotesen p=0.25.  

Vi konkluderer altså andelen af MobilePay brugere er 25%.  
</details>  
<br>
<details>  
  <summary> Spørgsmål andelen af MobilePay brugere </summary>

Kan man antage at andelen af MobilePay brugere er 20%?  
Angiv både hypoteser teststørrelse samt p-værdi. Angiv både en teknisk samt let forståelig konklusion.  

</details>  
<br>
<details> 
  <summary> Svar andelen af MobilePay brugere </summary>

Her bliver hypoteserne  

$H_0: p=0.2$  

$H_1:p\neq 0.2$  

z-teststørrelsen bliver her:  
`r ptest(31,100,0.2)$z`

p-værdien altså signifikanssandsynligheden bliver:  
`r round(2*(1-ptest(31,100,0.2)$pv),4)` 

Da der ikke er angivet et signifikansniveau sættes dette til 5%.  

Da `r round(2*(1-ptest(31,100,0.2)$pv),4)`<0.05 kan afviser vi nulhypotesen. Det betyder $p \neq0.2$.  

Vi konkluderer altså andelen af MobilePay brugere ikke er 20%.  

Da signifikanssandsynligheden er mindre end 1% ville vi også have nået samme konklusion selv med 1% signifikansniveau.  

</details>  
<br>
<details> 
  <summary> Spørgsmål andelen af MobilePay brugere </summary>


Kan man antage at andelen af MobilePay brugere højst er 22%?   
Angiv både hypoteser teststørrelse samt p-værdi. Angiv både en teknisk samt let forståelig konklusion.  

</details>  
<br>
<details> 
  <summary> Svar andelen af MobilePay brugere </summary>
Her bliver hypoteserne  

$H_0: p\leq 0.22$  

$H_1:p > 0.22$  

z-teststørrelsen bliver her:  
`r ptest(31,100,0.22)$z`

p-værdien altså signifikanssandsynligheden bliver:  
`r round((1-ptest(31,100,0.22)$pv),4)`

Da der ikke er angivet et signifikansniveau sættes dette til 5%.  

Da `r round((1-ptest(31,100,0.22)$pv),4)`<0.05 kan afviser vi nulhypotesen. Det betyder p>0.22.  

Vi konkluderer altså andelen af MobilePay brugere er større end 22%.  

Da signifikanssandsynligheden er større end 1%, ville vi ikke have afvist nulhypotesen hvis vi havde testet på 1% signifikansniveau. Vi siger derfor at konklusionen er niveaufølsom.  

</details>  
<br>
<details> 
  <summary> Spørgsmål andelen af kvinder i ledelse bankdata </summary>
  


```{r echo=FALSE}

bank <- read_excel("/cloud/project/FILER/BANKDATA.xls",1)
gender <- as.vector(as.matrix(bank$gender))
job <- as.vector(as.matrix(bank$job))
minority <- as.vector(as.matrix(bank$minority))
n1 <- length(which(gender=="female" & job=="manage"))
n01 <- length(which(job=="manage"))
phat <- n1/n01
```

Vi ser igen på datasættet [bankdata](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM), her findes data på funktion, antal års uddannelse, køn og race for 474 amerikanske bankansatte.  

Vi betragter nu andelen af kvinder i ledelse (manage). Er andelen af kvinder i ledelsen mindre end 50%?  Husk vi betrager kun ledelsen (manage).  
Angiv både hypoteser teststørrelse samt p-værdi. Angiv både en teknisk samt let forståelig konklusion.  

</details>  
<br>
<details> 
  <summary> Svar andelen af kvinder i ledelse bankdata </summary>

Parameterestimatet er $\hat{p}=`r phat`$. 
Vi ønsker at teste 

$$H_0:p\geq0.5 $$  
$$H_1:p<0.5 $$  

Signifikanssandsynligheden p er afrundet med 4 decimaler `r round(ptest(n1,n01,0.5)$pv,4)`, hvilket betyder vi klart forkaster nulhypotesen. Andelen er kvinder er altså mindre end 50%.  

Det er vigtigt at bemærke at stikprøven er så lille at approximationsbetingelsen $n\cdot\hat{p}(1-\hat{p})>9$ ikke er opfyldt da $n\cdot\hat{p}(1-\hat{p})=`r round(n01*phat*(1-phat),4)`$. Man skal derfor være varsom mht. konklusioner, p-værdien er dog så lille her, at der ikke kan være tvivl om konklusionen.  

</details>  
<br>
<details> 
  <summary> Spørgsmål andel kvinder i ledelse bankdata.</summary>



Test om andelen af kvinder i ledelsen mindre end 15%, opstil hypoteser samt teknisk og let forståelig konklusion?  
Angiv både hypoteser teststørrelse samt p-værdi. Angiv både en teknisk samt let forståelig konklusion.  

</details>  
<br>
<details> 
  <summary> Svar andel kvinder i ledelse bankdata.</summary>
$$H_0:p\geq0.15 $$  
$$H_1:p<0.15 $$  

Signifikanssandsynligheden p er afrundet med 4 decimaler `r round(ptest(n1,n01,0.15)$pv,4)`, hvilket betyder vi ikke kan forkaste nulhypotesen. 

Andelen er kvinder er altså ikke mindre end 15%.  

Husk at bemærke at stikprøven er så lille at approximationsbetingelsen $n\cdot\hat{p}(1-\hat{p})>9$ ikke er opfyldt da $n\cdot\hat{p}(1-\hat{p})=`r round(n01*phat*(1-phat),4)`$.  


</details>  
<br>
<details> 
  <summary> Spørgsmål andel bankdata sikkerhedsmedarbejdere blandt minoriteter.</summary>


```{r echo=FALSE}
bank <- read_excel("/cloud/project/FILER/BANKDATA.xls",1)
n1 <- length(which(minority=="yes" & job=="custodial"))
n01 <- length(which(job=="custodial"))
phat <- n1/n01
min <-  length(which(minority=="yes"))
pval <- ptest(n1,n01,0.5)$pv*2
```
Vi skal teste om halvdelen af medarbejdere i custodial tjeneste dvs. sikkerhedsmedarbejdere er minoriteter.  
Angiv både hypoteser teststørrelse samt p-værdi. Angiv både en teknisk samt let forståelig konklusion.  


</details>  
<br>
<details> 
  <summary> Svar andel bankdata sikkerhedsmedarbejdere blandt minoriteter.</summary>
I stikprøven på 474 personer, tilhører 104 personer blandt bankpersonalet minoriteter. Test om halvdelen af medarbejdere i custodial tjeneste dvs. sikkerhedsmedarbejdere er minoriteter.    

Hypoteserne bliver:  

$$H_0:p=0.5$$  
$$H_1:p\neq 0.5$$  

`r n1` ud af `r n01` sikkerhedsmedarbejdere er minoriteter. Det giver en z-teststørrelse på `r ptest(n1,n01,0.5)$z` hvilket fører til en meget høj signifikanssandsynlighed på `r pval*100`%. Vi kan absolut ikke forkaste nulhypotesen.  

Vi konkluderer at 50% af bankens sikkerhedspersonale er minoriteter.  
</details> 

## Selvtest 
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=58" target="_blank">Selvtest 1 andel med videoløsning.</a></h2>

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=52" target="_blank">Selvtest 1 andel OMX  med videoløsning.</a></h2>







# 2 andele


<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->



## Konfidensinterval for 2 andele

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226075888' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>  

<img src="img/mobilepay.jpg" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

Vi igen ser på MobilePay undersøgelsen hvor 31 ud af 100 brugte MobilePay, man har en 1 år gammel undersøgelse, hvor man havde spurgt 200 respondenter om de bruger MobilePay, af disse svarede 45, at de bruger Danske Banks app. 

Vi så tidligere, hvordan vi udregner konfidensintervaller for andele.
Vi fandt i den nye undersøgelse at mellem `r round2(prop.test(31,100,correct = F)$conf.int[1],2)`% og `r round2(prop.test(31,100,correct = F)$conf.int[2],2)`% i populationen med 95% sandsynlighed i dag bruger MobilPay.

Tilsvarende kan vi sige at andelen af MobilePay brugere i populationen med 95% sandsynlighed tidligere lå mellem `r round2(prop.test(45,200,correct = F)$conf.int[1],2)`% og `r round2(prop.test(45,200,correct = F)$conf.int[2],2)`%. Det kan være lidt svært af afgøre om forskellen er signifikant da vi af nedenstående grafiske præsentation kan se at der er et mindre overlap mellem de 2 konfidensintervaller.

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}

library(exams)
plot(x=NULL, y=NULL, xlim=c(0.7*min(prop.test(45,200,correct = F)$conf.int[1],prop.test(31,100,correct = F)$conf.int[1]), 1.05*max(prop.test(45,200,correct = F)$conf.int[2],prop.test(31,100,correct = F)$conf.int[2])), xlab="",ylim=c(-1, 3),bty="n",yaxt='n', ann=FALSE)
title(main = "MobilePay brugerandel\n Konfidensintervaller for andele",sub="",cex.main = 1)
segments(prop.test(45,200,correct = F)$conf.int[1], 0, prop.test(45,200,correct = F)$conf.int[2], 0, col= 'black',lty=1,lwd=1)
segments(prop.test(31,100,correct = F)$conf.int[1], 2, prop.test(31,100,correct = F)$conf.int[2], 2, col= 'black',lty=1,lwd=1)
points(c(prop.test(45,200,correct = F)$conf.int[1],prop.test(45,200,correct = F)$estimate,prop.test(45,200,correct = F)$conf.int[2]), c(0,0,0), pch = "|")
points(c(prop.test(31,100,correct = F)$conf.int[1],prop.test(31,100,correct = F)$estimate,prop.test(31,100,correct = F)$conf.int[2]), c(2,2,2), pch = "|")

text(prop.test(45,200,correct = F)$conf.int[1],0,round2(prop.test(45,200,correct = F)$conf.int[1],2),pos=1)
text(prop.test(45,200,correct = F)$conf.int[2],0,round2(prop.test(45,200,correct = F)$conf.int[2],2),pos=1)
text(prop.test(45,200,correct = F)$estimate,0,paste(round2(prop.test(45,200,correct = F)$estimate,2)),pos=1)
text(prop.test(45,200,correct = F)$conf.int[1],0,"Gammel \n undersøgelse",pos=2,cex=0.5,font= 3)

text(prop.test(31,100,correct = F)$conf.int[1],2,round2(prop.test(31,100,correct = F)$conf.int[1],2),pos=1)
text(prop.test(31,100,correct = F)$conf.int[2],2,round2(prop.test(31,100,correct = F)$conf.int[2],2),pos=1)
text(prop.test(31,100,correct = F)$estimate,2,round2(prop.test(31,100,correct = F)$estimate,2),pos=1)
text(prop.test(31,100,correct = F)$conf.int[1],2,"Ny \n undersøgelse",pos=2,font= 3,cex=0.5)

```

Hvis vi ønsker at undersøge om der er en signifikant forskel i andelen af brugere, kan vi se på konfidensintervallet for forskellen mellem andelene. Vi kan med 95% sikkerhed sige at forskellen i populationens andele er mellem `r round2(prop.test(c(31,45),c(100,200),correct = F)$conf.int[1],2)`% og `r round2(prop.test(c(31,45),c(100,200),correct = F)$conf.int[2],2)`% 

Vi kan i software beregne dette, vi undlader formlen og udregningen her


Output fra fanen andele i FreestatDK er vist herunder, bemærk vi skriver kun i de hvide felter. Nederst til højre ses konfidensintervallet for forskelle i andele:

<img src="img/freestat2andelemobilepay.png"  width="70%" height="70%"/><br>


Vi sammenligner altså de 2 andele og betragter et konfidensinterval for differencen mellem disse. Hvis 0 er indeholdt i dette interval som her, er der ikke signifikant forskel på andelene. Det er altså en mulighed, at forskellen mellem MobilePay brugere før og nu er 0, hvilket er det samme som ingen forskel på andelene.

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
plot(x=NULL, y=NULL, xlim=c(2*(prop.test(c(31,45),c(100,200),correct = F)$conf.int[1]), 1.05*prop.test(c(31,45),c(100,200),correct = F)$conf.int[2]), xlab="",ylim=c(-1, 1),bty="n",yaxt='n', ann=FALSE)
title(main = "MobilePay brugerandel\n Konfidensinterval for forskel i andele",sub="",cex.main = 1)
segments(prop.test(c(31,45),c(100,200),correct = F)$conf.int[1], 0, prop.test(c(31,45),c(100,200),correct = F)$conf.int[2], 0, col= 'black',lty=1,lwd=1)
abline(v=0,lty=2)
points(c(prop.test(c(31,45),c(100,200),correct = F)$conf.int[1],prop.test(c(31,45),c(100,200),correct = F)$conf.int[2]), c(0,0), pch = "|")
text(prop.test(c(31,45),c(100,200),correct = F)$conf.int[1],0,round2(prop.test(c(31,45),c(100,200),correct = F)$conf.int[1],2),pos=1)
text(prop.test(c(31,45),c(100,200),correct = F)$conf.int[2],0,round2(prop.test(c(31,45),c(100,200),correct = F)$conf.int[2],2),pos=1)
text(prop.test(c(31,45),c(100,200),correct = F)$conf.int[1],0,"Forskel \nandele",pos=2,cex=0.5,font= 3)
```

Vi kan altså ikke konkludere, at der er forskel på andelen af MobilePay brugere før og nu.

## Spørgsmål 2 andele konfidensintervaller

<br>
<details> 
  <summary> Spørgsmål 2 andele utroskab.</summary>


Vi ser igen på data om utroskab, [Fairs Affairs](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRlVQcFBtdVlHZ1U). Er der forskel på andelen af utro mænd og kvinder, bestem konfidensintervaller på 90% og 95% signifikansniveau?  

</details>
<br>
<details> 
  <summary> Svar 2 andele utroskab.</summary>

```{r echo=FALSE}
Aff <- as.matrix(read_excel("/cloud/project/FILER/AFFAIRS.xls",1))

xm <- 78
xf <- 72
nm <- length(which(Aff[,3]=="male"))
nf <- length(which(Aff[,3]=="female"))
```

Forskellen i andelene af utro kvinder og mænd ligger med 95% sikkerhed mellem `r round2(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf[1],2)` og `r round2(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf[2],2)`, en signifikant forskel kan således ikke påvises ved 5% signifikans niveau. Det er dog  tæt på, vi vil når vi begynder at teste, se at denne konklusion er tæt på at være niveaufølsom. Andelen af utro mænd, ligger på `r round2(xm*100/nm,2)`%, og andelen af kvinder er `r round2(xf*100/nf,2)`%.

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
plot(x=NULL, y=NULL, xlim=c(2*(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1]), 1.05*prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2]), xlab="",ylim=c(-1, 1),bty="n",yaxt='n', ann=FALSE)
title(main = "Utro mænd og kvinder\n 95% Konfidensinterval for forskel i andele",sub="",cex.main = 1)
segments(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1], 0, prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2], 0, col= 'black',lty=1,lwd=1)
abline(v=0,lty=2)
points(c(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1],prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2]), c(0,0), pch = "|")
text(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1],0,round2(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2],0,round2(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1],0,"Forskel \nandele",pos=2,cex=0.5,font= 3)
```

Benytter vi i stedet et 90% konfidensniveau, får vi Forskellen i andelene af utro kvinder og mænd ligger med 90% sikkerhed mellem `r round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf[1],2)` og `r round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf[2],2)`, det er nu tættere på at forskellen er signifikant.

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
plot(x=NULL, y=NULL, xlim=c(2*(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1]), 1.05*prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2]), xlab="",ylim=c(-1, 1),bty="n",yaxt='n', ann=FALSE)
title(main = "Utro mænd og kvinder\n 90% Konfidensinterval for forskel i andele",sub="",cex.main = 1)
segments(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[1], 0, prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[2], 0, col= 'black',lty=1,lwd=1)
abline(v=0,lty=2)
points(c(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[1],prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[2]), c(0,0), pch = "|")
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[1],0,round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[1],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[2],0,round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[2],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.9,correct = F)$conf.int[1],0,"Forskel \nandele",pos=2,cex=0.5,font= 3)
```
</details>
<br>
<details> 
  <summary> Spørgsmål 2 andele bankdata.</summary>



 [Bankdata](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM). Er der forskel på andelen af mænd og kvinder i ledelse (manage), bestem konfidenintervaller på 5% og 1% signifikans niveau?  
 
</details>
<br>
<details> 
  <summary> Svar 2 andele bankdata.</summary>
```{r echo=FALSE}
bank <- as.matrix(read_excel("/cloud/project/FILER/BANKDATA.xls",1))
xm <- length(which(bank[,2]=="manage" & bank[,4]=="male"))
xf <- length(which(bank[,2]=="manage" & bank[,4]=="female"))

nm <- length(which(bank[,4]=="male"))
nf <- length(which(bank[,4]=="female"))

```

I populationen ligger forskellen i andelene af kvinder og mænd i ledelse med 95% sikkerhed mellem `r round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf[1],2)` og `r round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf[2],2)`, der er altså signifikant forskel ved 5% signifikans niveau. Andelen af mænd i ledelse, ligger på `r round2(xm*100/nm,2)`% og andelen af kvinder i ledelse ligger på `r round2(xf*100/nf,2)`%.  

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
plot(x=NULL, y=NULL, xlim=c(2*min(0,(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1])), 1.05*max(0.01,prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2])), xlab="",ylim=c(-1, 1),bty="n",yaxt='n', ann=FALSE)
title(main = "Mænd og kvinder i ledelse\n 95% KI for forskel i andele",sub="",cex.main = 1)
segments(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[1], 0, prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[2], 0, col= 'black',lty=1,lwd=1)
abline(v=0,lty=2)
points(c(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[1],prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[2]), c(0,0), pch = "|")
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[1],0,round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[1],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[2],0,round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[2],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[1],0,"Forskel \nandele",pos=2,cex=0.5,font= 3)
```

I populationen ligger forskellen i andelene af kvinder og mænd i ledelse med 99% sikkerhed mellem `r round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf[1],2)` og `r round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf[2],2)`, der er altså signifikant forskel ved 1% signifikans niveau. Andelen af mænd i ledelse, ligger på `r round2(xm*100/nm,2)`% er altså helt sikkert større end andelen af kvinder i ledelse ligger på `r round2(xf*100/nf,2)`%.  

```{r echo=FALSE,fig.width=9, fig.height=3, dev='svg'}
plot(x=NULL, y=NULL, xlim=c(2*min(0,(prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[1])), 1.05*max(0.01,prop.test(c(xm,xf),c(nm,nf),correct = F)$conf.int[2])), xlab="",ylim=c(-1, 1),bty="n",yaxt='n', ann=FALSE)
title(main = "Mænd og kvinder i ledelse\n 99% KI for forskel i andele",sub="",cex.main = 1)
segments(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[1], 0, prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[2], 0, col= 'black',lty=1,lwd=1)
abline(v=0,lty=2)
points(c(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[1],prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[2]), c(0,0), pch = "|")
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[1],0,round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[1],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[2],0,round2(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.99,correct = F)$conf.int[2],2),pos=1)
text(prop.test(c(xm,xf),c(nm,nf),conf.level = 0.95,correct = F)$conf.int[1],0,"Forskel \nandele",pos=2,cex=0.5,font= 3)
```
</details>  


## Hypotesetests 2 andele


I den nye undersøgelse så vi at 31 ud af 100 bruger MobilePay, mod tidligere 45 ud af 200. Er der forskel på de 2 andele?  

Da vi spørger om der er forskel svarer dette til operatoren $\neq$. Vi kan skrive hypotesetestet som:

$$H_0: p_{nu}=p_{før}$$

$$H_1: p_{nu} \neq p_{før}$$

eller som det er formuleret i Freestat:

$$H_0:p_{nu}-p_{før}=D$$

$$H_1:p_{nu}-p_{før}\neq D$$

D står for difference, denne er som udgangspunkt 0. Hvis man skriver fx. 3 det gule felt, sættes D=3. Man tester så om en forskel er større end 3 procentpoint. Pas på husk altid at slette data i det gule felt, da man ellers kan nå den forkerte konklusion.

Da signifikanssandsynligheden/p-værdien `r round2(prop.test(c(31,45),c(100,200),correct=FALSE)$p.value,4)` er større end signifikansniveauet 5%, kan vi ikke forkaste nulhypotesen. 

Vi konkluderer andelen af MobilePay brugere før og nu ikke er forskellig.

I nedenstående output fra Freestat når vi samme konklusion, her benytter vi testet med den tosidede alternativ hypotese hvor:
$$p_{nu}=p_1$$
$$p_{tidligere}=p_2$$


Bemærk ved tests af 2 andele, med ensidet alternativ hypotese, er det vigtigt at holde styr på, hvad man vælger som stikprøve 1 og stikprøve 2. 

![](img/freestattest2andeleMobilepay.png)

### Eksempler
#### Utroskab og køn
Vi ser på igen på Fairs afairs datasættet.

Test om mænd er mere utro end kvinder?

Her skal vi først filtrere data på køn, for hhv. mænd og kvinder skal vi herefter bestemme andelen af utro.

```{r aff22, echo=FALSE, error=TRUE}
library(exams,readxl)

options(scipen=999)     #disable scientific notation
aff <- as.matrix(read_excel("/cloud/project/FILER/AFFAIRS.xls",1))
f <- length(which(aff[,3]=="female" ))
uf <- 72
m <- length(which(aff[,3]=="male" ))
um <- 78
pv <- round2(prop.test(c(um,uf),c(m,f),correct = FALSE)$p.value,4)
```

`r um` ud af ialt `r m` mænd er utro, andelen af utro mænd i stikprøven er altså `r round2(um/m,4)`.  

`r uf` ud af ialt `r f` kvinder er utro, andelen af utro kvinder i stikprøven er altså `r round2(uf/f,4)`.   

Der er forskel på andelene i stikprøverne, men betyder dette at der er en signifikant forskel på andelene i populationerne?  

Hypoteserne bliver  

$$H_0:p_{mand} \leq p_{kvinde}$$
$$H_1:p_{mand}>p_{kvinde}$$

eller som det er formuleret i Freestat:

$$H_0:p_{mand}-p_{kvinde}\leq 0$$
$$H_1:p_{mand}-p_{kvinde}>0$$

Vi har altså sat

$$p_{mand}=p_1$$
$$p_{kvinde}=p_2$$

P-værdien bliver `r round2(pv/2,4)`, hvilket er større end 5%, vi kan altså ikke forkaste nulhypotesen. Vi konkluderer at mænd ikke er signifikant mere utro end kvinder i populationen. Vi har dog en p-værdi der er tæt på 10%, så det er ikke en meget sikker konklusion.

Nedenfor ses output fra Freestat:

![](img/freestattest2andeleutroskab.png)

#### Utroskab og religiøsitet

```{r aff23, echo=FALSE, error=TRUE}
library(exams)
options(scipen=999)     #disable scientific notation
aff <- as.matrix(readxl::read_excel("/cloud/project/FILER/AFFAIRS.xls",1))

r <- length(which(as.numeric(aff[,7])>3 ))
ur <- length(which(as.numeric(aff[,7])>3 & as.numeric(aff[,2])>0))
u <- length(which(as.numeric(aff[,7])<4 ))
uu <- length(which(as.numeric(aff[,7])<4 & as.numeric(aff[,2])>0))
pv <- round2(prop.test(c(ur,uu),c(r,u),correct = FALSE)$p.value,8)
```

Vi definerer nu meget religiøse, som folk med religiousness større end 3.
Er mindre religiøse, mere utro end religiøse?

`r r` er meget religiøse, ud af disse er  `r ur` utro.  

`r u` er mindre religiøse, ud af disse er  `r uu` utro.

Vor hypoteser bliver:

$$H_0:p_{religioese}\geq p_{mindre-religioese}$$
$$H_0:p_{religioese}< p_{mindre-religioese}$$

Vi finder har en signifikanssandsynlighed på `r round2(pv/2,6)`, dette er en meget lille signifikanssandsynlighed, så vi forkaster klart nulhypotesen.

Mindre Religiøse personer er altså mere utro end religiøse.

## Spørgsmål 2 andele

</details>  
<br>
<details> 
  <summary>Spørgsmål 2 andele vandskader.</summary>
Et forsikringsselskab ønsker at undersøge om andelen af anmeldelser af oversvømmede kældre er steget i `r as.numeric(substr(date(),21,24))` er steget i forhold til en lignende undersøgelse i `r as.numeric(substr(date(),21,24))-4`.
Man har i `r as.numeric(substr(date(),21,24))` undersøgt 309 forsikringstagere med kælder, af disse har 43 anmeldt vandskader.  

Tidligere i `r as.numeric(substr(date(),21,24))-4` har man konstateret at i en stikprøve på 350 forsikringstagere, havde 35 Beskadigede kældre.  

**1.** Er der forskel på andelen af anmeldte skader?  
**2.** Er forudsætningerne for testet opfyldt?  
**3.** Er antallet af anmeldte skader steget fra `r as.numeric(substr(date(),21,24))-4` til `r as.numeric(substr(date(),21,24))`?  
**4.** Er antallet af anmeldte skader steget fra `r as.numeric(substr(date(),21,24))-4` til `r as.numeric(substr(date(),21,24))`, hvis vi tester på 10% signifikansniveau?  

</details>  
<br>
<details> 
  <summary>Svar 2 andele vandskader.</summary>

**1.** Er der forskel på andelen af anmeldte skader?  
Vi opstiller hypoteserne:  
$$H_0:p_{`r as.numeric(substr(date(),21,24))`}=p_{`r as.numeric(substr(date(),21,24))-4`}$$
$$H_0:p_{`r as.numeric(substr(date(),21,24))`}\neq p_{`r as.numeric(substr(date(),21,24))-4`}$$

<img src="img/2andele1.png" alt="2andele1" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Da p værdien/signifikanssandsynligheden 0.1204 er større end 0.05 signifikansniveauet, kan vi ikke afvise nulhypotesen. Det vil sige andelen af anmeldte skader er ikke ændret fra 2014 til 2018. Bemærk vi tester to-sidet, da spørgsmålet er om andelen er **ændret**.  
			


**2.** Er forudsætningerne for testet opfyldt?  
<img src="img/2andele2.png" alt="2andele2" align="right" width="30%" height="30%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Da $n\cdot\hat{p}\cdot(1-\hat{p})$ klart er større end 9 for begge stikprøver, er disse tilstrækkeligt store til at vi kan forudsætningerne er opfyldt.  
  
  
**3.** Er antallet af anmeldte skader steget fra `r as.numeric(substr(date(),21,24))-4` til `r as.numeric(substr(date(),21,24))`?  
<img src="img/2andele3.png" alt="2andele3" align="right" width="40%" height="40%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Bemærk vi tester med en-sidet alternativ hypotese, da spørgsmålet er om andelen er **steget**. Da vi vælger at sætte `r as.numeric(substr(date(),21,24))` stikprøven som stikprøve 1 og `r as.numeric(substr(date(),21,24))-4` stikprøven som stikprøve 2, bliver testet ensidet opad. Vi skal jo undersøge om $p_{`r as.numeric(substr(date(),21,24))`}$ er større end $p_{`r as.numeric(substr(date(),21,24))-4`}$.  

Vi skal teste med ensidet alternativ hypotese opad. Hypoteserne i testet bliver derfor:  
$$H_0:p_{`r as.numeric(substr(date(),21,24))`}\leq p_{`r as.numeric(substr(date(),21,24))-4`}$$
$$H_0:p_{`r as.numeric(substr(date(),21,24))`}>p_{`r as.numeric(substr(date(),21,24))-4`}$$

Da p værdien/signifikanssandsynligheden 0.0602 er større end 0.05 signifikansniveauet, kan vi ikke afvise nulhypotesen.	Andelen af anmeldte skader er alså ikke steget. Dog er konklusionen niveaufølsom.  
			

**4.** Er antallet af anmeldte skader steget fra `r as.numeric(substr(date(),21,24))-4` til `r as.numeric(substr(date(),21,24))`, hvis vi tester på 10% signifikansniveau?  
<img src="img/2andele4.png" alt="2andele4" align="right" width="40%" height="40%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>  

Vi skal fortsat teste med ensidet alternativ hypotese opad dog med 10% signifikansniveau. Hypoteserne i testet bliver derfor:  
$$H_0:p_{`r as.numeric(substr(date(),21,24))`}\leq p_{`r as.numeric(substr(date(),21,24))-4`}$$
$$H_0:p_{`r as.numeric(substr(date(),21,24))`}>p_{`r as.numeric(substr(date(),21,24))-4`}$$
Da p værdien/signifikanssandsynligheden 0.0602 er mindre end 0.1 signifikansniveauet, afviser vi nulhypotesen. Andelen af anmeldte skader er altså steget fra `r as.numeric(substr(date(),21,24))-4` til `r as.numeric(substr(date(),21,24))`  
			
</details>  


</details>  
<br>
<details> 
  <summary>Spørgsmål 2016 8 Eksamen Statistik opgave 2 Finansøkonom.</summary>


A. 2016 8 Eksamen Statistik opgave 2
[toggle title=Spørgsmål]
Nykøbing Bank er et mindre pengeinstitut med en stærk position i sit lokalområde.
I Nykøbing Bank arbejder man med et rating-system af privatkunderne. Kunderne inddeles i risikogrupper efter deres risikoprofil på en skala fra 1 til 14. Et lavt antal point i rating-systemet betyder, at kunden har lav risiko for ikke at kunne overholde sine forpligtelser.
I bedømmelsen af dine svar bliver der lagt vægt på, at du argumenterer for dine valg af løsningsmetoder, undersøger om eventuelle forudsætninger er opfyldt samt fortolker dine resultater.

Opgave 2 (30 %)
Nykøbing Bank er bekymret for kundernes overtræk. I 2015 foretog banken en analyse, hvor man i en stikprøve på 75 kunder registrerede 26 kunder med overtræk.
Spørgsmål 2.1 (10 %)
Du bedes beregne et punktestimat og et 95 % konfidensinterval for andelen af bankens kunder, der havde overtræk i 2015.
Spørgsmål 2.2 (10 %)
Ved hjælp at en test på 5 % testniveau bedes du undersøge, om andelen af kunder med overtræk var større end 25 % i 2015.
Spørgsmål 2.3 (10 %)
Banken har en formodning om, at andelen af kunder med overtræk er faldet siden 2015. Anvend resultaterne i den vedlagte stikprøve fra maj 2016 til at teste på 5 % testniveau, om banken har ret i denne formodning.

Du finder hele opgaver i linket:
[2016 8 Eksamen Statistik Opgave](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldWRQVGRwZWlkdzQ)

[2016 8 Eksamen Statistik data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlN29HR09IRmJZSE0)
</details>  
<br>
<details> 
  <summary>Svar 2016 8 Eksamen Statistik opgave 2 Finansøkonom.</summary>

<div >
<iframe width="500" height="280"
src="https://www.youtube.com/embed/7rMQGhE2HIY"

frameborder="0"> 
></iframe><p><center>Løsning eksamensopgave</center></p>
<div class="clear"></div>
</div>

[2016 8 Eksamen Statistik opg 2 LØSNING](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlUThSYWllWG9pSG8)

</details>  
<br>
<details> 
  <summary>Spørgsmål 2016 8 Eksamen Statistik opgave 4 Finansøkonom.</summary>


Opgave 4 (10 %)
Det er mange år siden bankens markedschef har beskæftiget sig med statistik. Han beder dig derfor forklare nogle begreber.
Spørgsmål 4.1 (5 %)
Forklar forskellen på et punktestimat og et konfidensinterval. Forklar endvidere formålet med at beregne et konfidensinterval.
Spørgsmål 4.2 (5 %)
Hvilken betydning har testniveauet for konklusionen i en hypotesetest?
Hvilken betydning har stikprøvens størrelse for p-værdien, når der udarbejdes en hypotesetest?

Du finder hele opgaver i linket:
[2016 8 Eksamen Statistik Opgave](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldWRQVGRwZWlkdzQ)

[2016 8 Eksamen Statistik data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlN29HR09IRmJZSE0)

</details>  
<br>
<details> 
  <summary>Svar 2016 8 Eksamen Statistik opgave 4 Finansøkonom.</summary>

<div >
<iframe width="500" height="280"
src="https://www.youtube.com/embed/Vt2SLnolNak"

frameborder="0"> 
></iframe><p><center>Løsning eksamensopgave</center></p>
<div class="clear"></div>
</div>
[2016 8 Eksamen Statistik opg 4 LØSNING](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlaWVxc1poYTVxMTA)

</details>  
<br>
<details> 
  <summary>Spørgsmål 2017 3 Eksamen Statistik opgave 1 Finansøkonom.</summary>  


Opgave 1 (50%)  
Det første din chef vil have dig til at undersøge er den gennemsnitlige forsikringspræmie, og da det er målet at tilbyde prisbillige forsikringer til unge bilister, skal den gennemsnitlige forsikringspræmie være under kr. 6.000. Til det formål er der fortaget en stikprøveundersøgelse blandt Safe Cars kunder. Stikprøven er udtaget tilfældigt, og resultatet ses i datasættet i Excelarket.  
1.1 (5%)  
Undersøg om forsikringspræmierne for år 2016 er normalfordelte.  
1.2 (10%)
Test på 5% niveau, hvorvidt Safe Car lever op til målet om at den gennemsnitlige forsikringspræmie er lavere end kr. 6.000.  
Hvor sikre kan vi være på din konklusion?  
1.3 (10%)  
Beregn et 99% konfidensinterval for den gennemsnitlige forsikringspræmie for år 2016. Hvor anvendeligt er dette interval?  
1.4 (5%)  
Hvor stor skal stikprøven være, for at der maksimalt er kr. 100 mellem nedre og øvre grænse i 99% konfidensintervallet for den gennemsnitlige forsikringspræmie beregnet i 1.3?  
Foruden kravet om lave forsikringspræmier har Safe Car har en politik om, at variansen for præmierne ikke må blive for stor. Der er således en målsætning om, at variansen for forsikringspræmierne skal være kr. 250.000.  
1.5 (10%)  
Test på 5% niveau hvorvidt den sande varians for forsikringspræmierne er lig med kr. 250.000. - Hvor sikre kan vi være på din konklusion?  
Safe Car har også interne regler der siger, at andelen af kunder der har en forsikringspræmie over kr. 5800 maksimalt må udgøre en tredjedel.  
1.6 (10%)  
Beregn et 95% konfidensinterval for andelen af kunder der betaler mere end kr. 5800 i forsikringspræmie.  
Hvor anvendeligt er dette interval?  


Du finder hele opgaver i linket:
[2017 3 Eksamen Statistik Opgave](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlcTA2dDRiTEVRWUE)

[2017 3 Eksamen Statistik data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldEVIQXVIUXlvTHM)

</details>  
<br>
<details> 
  <summary>Svar 2017 3 Eksamen Statistik opgave 1 Finansøkonom.</summary>

<div >
<iframe width="500" height="280"
src="https://www.youtube.com/embed/NorhSH4G87U"

frameborder="0"> 
></iframe><p><center>Løsning eksamensopgave</center></p>
<div class="clear"></div>
</div>

[2017 3 Eksamen Statistik opg 1 LØSNING](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlMzBpNjhtMXdCTUk)

</details>  
<br>
<details> 
  <summary>Spørgsmål 2017 3 Eksamen Statistik opgave 3 Finansøkonom.</summary>


Opgave 3 (20%)
Hos Safe Car har man foruden fokus på billige forsikringspræmier også fokus på andelen af skader for forskellige aldersgrupper, og derfor har Safe Car for nylig lavet en analyse på baggrund af en tilfældigt udvalgt stikprøve på 175 personer blandt selskabets unge kunderne. Resultatet ses i dataarket under fane 2:

|Alder            |Lille skade      |Mellem skade                  |Stor skade      |Total
|:------------  |:------------       |:------------           |:------------   |:---------
18-19 år            | 15                  |20                       |35             |70
20-21 år                  |20             |20                       |20             |60
22-23 år                  |15             |15                       |15             |45
Total                 |50                 |55                       |70             |175


3.1 (10%)
Test på 5% niveau om andelen af personer som har lavet en stor skade er mindre end 65% for den yngste aldersgruppe.  
Safe Car er ligeledes interesseret i at finde ud af, om der er forskel mellem aldersgrupper  
3.2 (10%)  
Test på 5% om andelen af personer, der laver en stor skade, er større blandt de 18-19 årige end blandt de 22-23 årige.  

Du finder hele opgaver i linket:
[2017 3 Eksamen Statistik Opgave](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlcTA2dDRiTEVRWUE)

[2017 3 Eksamen Statistik data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldEVIQXVIUXlvTHM)

</details>  
<br>
<details> 
  <summary>Svar 2017 3 Eksamen Statistik opgave 3 Finansøkonom.</summary>

<div >
<iframe width="500" height="280"
src="https://www.youtube.com/embed/e5ooenttb1Q"

frameborder="0"> 
></iframe><p><center>Løsning eksamensopgave</center></p>
<div class="clear"></div>
</div>
[2017 3 Eksamen Statistik opg 3 LØSNING](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlZkVhZGpXYkJPZnc)

</details> 


## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=59" target="_blank">Selvtest 2 andele med videoløsning.</a></h2>  








# 2 Middelværdier



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->




## Konfidensinterval for 2 middelværdier

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226073803' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

### Pooled og unpooled t-test

Vi kan ofte være interesseret i at i at sammenligne middelværdier, til dette kan vi benytte en af flere tests. Hvis vi har 2 kvantitative stikprøver, kan vi undersøge om forskellen i middelværdierne er signifikant forskellig. Det er muligt at bruge en pooled t-test, hvis vi har ens standardafvigelser og dermed ens varianser for de 2 stikprøver. Man bruger en unpooled t-test, hvis varianserne ikke er ens. Vi kan teste om varianserne er ens, en sådan test for varianshomogenitet, findes i det meste software incl. freestat. Hvis man ikke har mulighed for at teste, kan man bruge tommelfingerreglen: Hvis den største af de 2 stikprøvers standardafvigelse, er mere end dobbelt så stor, som den lille stikprøves standardafvigelse, benyttes unpooled t-test. 

Vi ser igen på eksemplet med ejendomsmægleren der undersøgte kundernes afstand til filialerne. Den gennemsnitlige afstand til nærmeste filial var, 748 meter i stikprøven med 200 respondenter. Standardafvigelsen er 102 meter. 

Mægleren har data fra en tilsvarende undersøgelse hos en konkurrerende kæde, her er den gennemsnitlige afstand 702 meter og standardafvigelsen er 89 i en stikprøve af størrelse 40.

I Freestat kan man sætte de 2 stikprøver, ind analysen Pooled t-test varianshomogenitet i fanen Pooled. Vi får følgende output.

![](img/freestatmaeglerpooled.png)

Her har vi som ses af output fra Freestat, valgt mæglerens egen undersøgelse som 1. stikprøve, og konkurrentens som 2. stikprøve. Vi kan med 95% sikkerhed sige at forskellen mellem mæglerens og konkurrentens kunders gennemsnitlige afstand til filial ligger mellem 11,9 og 80.1 meter (markeret med rødt). Da 0 ikke er indeholdt i konfidensintervallet kan vi konstatere at denne forskel er signifikant, der er altså forskel på afstanden til nærmeste filial i de 2 kæder. Vi kan undersøge om vi også er 99% sikre på konklusionen ved at ændre signifikansniveauet til 1%, jo et bredere konfidensinterval, da præcisionen falder, når sikkerheden stiger.

Det er ikke så vigtigt hvilken stikprøve, der er 1. og 2. stikprøve, men det er væsentligt for tolkningen af konfidensintervallet. Bemærk konfidensintervallets øvre grænse, vil hvis man bytter rundt, blive den nedre grænse med fortegnsskift, og tilsvarende for den nedre grænse. Begge grænser i konfidensintervallet er positive, forskellen måles altid som 1. stikprøve minus 2. stikprøve, specielt i dette tilfælde altså kædens egen undersøgelse minus konkurrentens undersøgelse. Det er altid en MEGET god ide, at holde fuldstændig styr på hvilken stikprøve, der er 1. og 2., hvilket vi senere vil se i forbindelse med hypotestests med ensidet alternativhypotese.

Vi skal undersøge om varianserne er ens, tommelfingerreglen er overholdt, da standardafvigelsen for den store stikprøve $\hat{\sigma}_1=102$, ikke er mere end dobbelt så stor, som standardafvigelsen for den lille stikprøve $\hat{\sigma}_2=89$. Vi har dog en mere præcis metode, nederst til højre markeret med blåt testes varianshomogenitet automatisk. Vi har endnu ikke gennemgået hvorledes hypotesetests opstilles og aflæses, men vi kan godt forstå sidste del i konklusionen af hypotesetesten, "varianserne er ens".

Vi kan som nævnt, ændre signifinkansniveauet til 1% se om konfidensintervallet nu indeholder 0.

Vi kan med 99% sikkerhed sige, at forskellen mellem mæglerens og konkurrentens kunders gennemsnitlige afstand til filial ligger mellem 1,1 og 90.9 meter. Vi er altså relativt sikre på vor konklusion, om forskel i afstande til nærmeste filial for de 2 kæder.

![](img/freestatpooledmaegler2.png)

## Varianshomogenitet
### Forudsætninger
En forudsætning for at benytte pooled t-test, til at undersøge om 2 middelværdier kan antages at være identiske, er at der er varianshomogenitet. For at vi må undersøge om populations varianserne er ens, skal vi først undersøge om populationerne kan antages normalfordelte. Det nemmeste er at undersøge forudsætningen om normalfordelte populationer ved at se på normalfraktildiagrammerne.

I filen [huspriser](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlUklCZWNocEIyVnM), er indsamlet stikprøver af 22 huspriser fra 2016 og 20 huspriser fra 2007. Hvis vi vil undersøge om der er signifikant forskel i prisen vha. konfidensintervallet, skal vi tjekke at begge stikprøver stammer fra normalfordelinger. Vi kan til dette benytte normalfraktildiagrammer for de 2 stikprøver.


```{r qqplots, echo=FALSE, fig.height=6, fig.width=9, dev='svg'}
list.of.packages <- c("readxl")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library("readxl")
hus <- as.matrix(read_excel("/cloud/project/FILER/huspriser.xlsx",1))
hus07 <- subset(hus[,1],hus[,2]==2007)
hus16 <- subset(hus[,1],hus[,2]==2016)
par(mfrow=c(2,1))
qqnorm(hus07,pch=20, xlab="Teoretiske fraktiler",ylab="Stikprøve fraktiler", main = "Normalfraktildiagram 2007 huspriser"); qqline(hus07)
qqnorm(hus16,pch=20, xlab="Teoretiske fraktiler",ylab="Stikprøve fraktiler", main = "Normalfraktildiagram 2016 huspriser"); qqline(hus16)

# nedre <- round(t.test(hus16,hus07,var.equal =TRUE)$conf.int[1],2)
# ovre <- round(t.test(hus16,hus07,var.equal =TRUE)$conf.int[2],2)





```

Her vil det ofte være lidt af en skønssag at vurdere om stikprøven stammer fra en normalfordelt population, bemærk små afvigelser fra linjen vil ved mindre stikprøver, virke voldsommere end ved større stikprøver, da vi jo har "zoomet"" ind i normalfraktildiagrammet. I dette eksempel, kan vi godt konkludere at data stammer, fra en normalfordelt population. Afvigelser i enderne tillades i højere grad, end afvigelser omkring midten af diagrammet.

I Freestat genereres normalfraktildiagrammer direkte for en stikprøve, når data indsættes i en stikprøve.


## Sammenligning af 2 middelværdier ens varians Pooled t-test

Hvis vi har 2 stikprøver og ønsker at sammenligne middelværdierne kan vi benytte en pooled t-test, hvis de 2 populationer har samme standardafvigelse. 


Man kan undersøge om stikprøvernes varianser er homogene, dette gøres ved en test af om standardafvigelserne er ens:

$$H_0:\sigma_1=\sigma_2$$
$$H_1:\sigma_1 \neq \sigma_2$$

Eller ækvivalent om varianserne er ens:

$$H_0:\sigma^2_1=\sigma^2_2$$
$$H_1:\sigma^2_1 \neq \sigma^2_2$$

For at konkludere om nulhypotesen skal forkastes, bestemmes  signifikanssandsynligheden vha. et F-test. Man kan fx forestille sig en bank ønsker at undersøge om mænd og kvinder, har samme indestående på deres lønkonti. Her kan man, hvis varianserne er ens (de vil normalt ikke være kendte), benytte en pooled t-test. Vi går her ikke i detaljer, med formlerne til beregning af teststørrelsen, software regner dette ud for os.

<div class="Keats">
“I guess I think of lotteries as a tax on the mathematically challenged.” 
- Roger Jones
</div>

Man skal ligesom ved små stikprøver i test af en middelværdi, sikre sig normalitet i populationen. Dette kan på samme måde gøres visuelt i et normalfraktildiagram for de 2 stikprøver.

#### Eksempler
##### Statistik karakterer 

```{r karaktererstat, echo=FALSE}

kar <- read_excel("/cloud/project/FILER/statkarakterer.xlsx",1)
nk <- length(which(kar$Gender=="kvinde"))
nm <- length(which(kar$Gender=="mand"))
k <- as.vector(as.matrix(kar[which(kar$Gender=="kvinde"),1]))
m <- as.vector(as.matrix(kar[which(kar$Gender=="mand"),1]))
```

Vi ser igen på datasættet for [statistik karakterer](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRURnNjk0UnJSYzQ).
Vi kunne være interesseret i, at teste om kvinder får højere karakterer end mænd. Der er `r nk` kvinder i og `r nm` mænd i stikprøven. Da begge stikprøver er mindre end 30, skal vi undersøge om stikprøven kan antages at stamme fra en normalfordelt population. Dette efterprøves i 2 normalfraktildiagrammer. I Freestat kan man enkeltvis paste begge fordelinger ind i en kvantitativ stikprøve, og indsætte de 2 normalfraktildiagrammer, nedenfor er indsat Freestat normalfraktildiagrammet for kvinder.

![](img/freestatqqplotkarakterer.png)

Herunder er indsat Freestat normalfraktildiagrammet for mænd.

![](img/freestatqqplotkarakterermand.png)

Vi har nok på forhånd en formodning om at statistik karakterer generelt, følger en bimodal fordeling, enten får man en lav eller høj karakter. Man kan godt ane denne tendens, da vi kan se data ikke ligger helt pænt omkring den rette linje. Bemærk observationerne, illustreret ved punkter, ligger på rette linjer. Dette skyldes vi jo har hele karakterer. Vi konstaterer der synes at være problemer med normaliteten af populationerne, og dermed kvaliteten, præcisionen i analysen. Vi går imidlertid her videre videre med en pooled t-test hvis varianserne for mænd og kvinder er ens, ellers skal vi benytte en unpooled t-test.


$$H_0:\sigma^2_{kvinde}=\sigma^2_{mand}$$
$$H_1:\sigma^2_{kvinde} \neq \sigma^2_{mand}$$

Vi konstaterer at signifikanssandsynligheden er `r round(var.test(k,m)$p.value,4)`, hvilket direkte kan aflæses i nedenstående Freestat output. Vi kan altså ikke forkaste nulhypotesen og konstaterer at varianserne er ens, og det er derfor korrekt at anvende pooled t-test til at undersøge om kvinders karakterer er højere end mænds. Når vi tester to middelværdier undersøger vi om forskel mellem middelværdierne er forskellig fra 0. Vi får en t-teststørrelse jo større denne numerisk er jo større er forskellen mellem middelværdierne. En numerisk stor t-teststørrelse udtrykker altså stor forskel. Hypoteserne bliver:

$$H_0:\mu_{kvinder}\leq\mu_{mæ\ nd}$$
$$H_1:\mu_{kvinder}>\mu_{mæ\ nd}$$

Hvilket vi også kan skrive som

$$H_0:\mu_{kvinder}-\mu_{mæ\ nd}\leq 0$$
$$H_1:\mu_{kvinder}-\mu_{mæ\ nd}> 0$$

Vi får en test-størrelse på `r round(t.test(as.vector(as.matrix(k)),as.vector(as.matrix(m)),var.equal = TRUE)$statistic,4)`, denne medfører en p-værdi på 29.71%. Vi kan ikke forkaste nulhypotesen. 

Vi kan altså ikke konkludere at kvinder får en højere karakter end mænd.

Bemærk i Freestat, står der D for difference, dette skyldes man kan undersøge om en forskel mellem middelværdier kan være fx. 0.25, ved at sætte D, i det gule felt til 0.25.

![](img/freestatpooledkarakterer.png)

## Sammenligning af 2 middelværdier uens varians Unpooled t-test.

Skal vi undersøge 2 kvantitative stikprøver, der stammer fra populationer med uens varians, benytter vi unpooled t-test. Det er samme fremgangsmåde som ved pooled t-test, men unpooled testen er ikke så præcis som pooled. Derfor starter vi i pooled t-test og gennemfører kun unpooled t-test hvis varianserne ikke er ens.

```{r echo=FALSE,warning=FALSE,results='hide'}
# list.of.packages <- c("maps", "ggmap")
# new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
# if(length(new.packages)) install.packages(new.packages)
# library(maps)
# library(ggmap)
```





#### US crime 
<img src="img/usgun.png" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

Vi har i datasættet [US crime](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRDhUYUk4R0NwVFk), de beregnede rater pr. 100000 borgere fordelt på stat. for hhv. mord overfald og voldtægt. Yderemere er angivet graden af urbanisering, højere betyder staten har større arealer med bymæssig bebyggelse. Observationssættet er baseret på en stor 1973 undersøgelse af 100.000 arrestationer. Mordraterne er illustreret på kortet nedenfor.


```{r , echo=FALSE,message=FALSE,}
usarrest <- USArrests[-c(2,11),]
WriteXLS("usarrest", ExcelFileName = "usarrest.xls", 
         SheetNames = "usarrest",row.names = TRUE,AdjWidth = FALSE,
         BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
```


```{r USMAP, echo=FALSE,message=FALSE, fig.width=9*1.3, fig.height=5*1.3, dev="svg"}

# geostates <- row.names(USArrests)[-c(2,11)] #Remove Alaska and Hawaii
# geostates[which(row.names(USArrests)=="Washington")] <- "Washington State" #Change
# geoplace <- geocode(geostates)
statcrime <- c("Alabama","Arizona", "Arkansas", "California",
"Colorado", "Connecticut",  "Delaware", "Florida", "Georgia", "Idaho",
"Illinois"  ,     "Indiana"  ,      "Iowa",
"Kansas"    ,     "Kentucky"  ,     "Louisiana"  ,    "Maine"   ,       "Maryland"  ,
"Massachusetts","Michigan"   ,    "Minnesota"   ,   "Mississippi"   , "Missouri"   ,   
"Montana"    ,    "Nebraska"    ,   "Nevada"     ,    "New Hampshire"  ,"New Jersey"  ,  
 "New Mexico"  ,   "New York"     ,  "North Carolina", "North Dakota"  , "Ohio"         , 
 "Oklahoma"     ,  "Oregon"        , "Pennsylvania" ,  "Rhode Island" ,  "South Carolina",
 "South Dakota"  , "Tennessee" ,     "Texas"         , "Utah"        ,   "Vermont"       ,
 "Virginia"     ,  "Washington State" ,    "West Virginia" , "Wisconsin"  ,    "Wyoming" )
#longlat <- geocode(statcrime)
statcrime2 <- c(-86.9023,-111.0937,-91.83183,-119.4179,-105.7821,
-73.08775,-75.52767,-81.51575,-82.90008,-114.742,
-89.39853,-86.1349,-93.0977,-98.48425,-84.27002,
-91.96233,-69.44547,-76.64127,-71.38244,-85.60236,
-94.6859,-89.39853,-91.83183,-110.3626,-99.90181,
-116.4194,-71.5724,-74.40566,-105.8701,-74.00594,
-79.0193,-101.002,-82.90712,-97.09288,-120.5542,
-77.19452,-71.47743,-81.16372,-99.90181,-86.58045,
-99.90181,-111.0937,-72.57784,-78.65689,-120.7401,
-80.4549,-88.78787,-107.2903)

statcrime3 <- c(32.31823,34.04893,35.20105,36.77826,39.55005,
                41.60322,38.91083,27.66483,32.16562,44.0682,
                40.63312,40.26719,41.878,39.0119,37.83933,
                30.9843,45.25378,39.04575,42.40721,44.31484,
                46.72955,32.35467,37.96425,46.87968,41.49254,
                38.80261,43.19385,40.05832,34.51994,40.71278,
                35.75957,47.55149,40.41729,35.00775,43.80413,
                41.20332,41.58009,33.83608,43.96951,35.51749,
                31.9686,39.32098,44.5588,37.43157,47.75107,
                38.59763,43.78444,43.07597)

 geostates <- data.frame(statcrime,statcrime2,statcrime3)
   names(geostates) <- c("geostates","lon","lat")
states <- map_data("state")
arrests <- USArrests
names(arrests) <- tolower(names(arrests))
arrests$region <- tolower(rownames(USArrests))
choro <- merge(states, arrests, sort = FALSE, by = "region")
choro <- choro[order(choro$order), ]
  ggplot(choro, aes(long, lat), ann=FALSE) +
  geom_polygon(aes(group = group, fill = murder)) +
  coord_map("albers",  at0 = 45.5, lat1 = 29.5)+
    annotate("text",geostates[,2], geostates[,3], label=geostates[,1],size=2,colour = "white")+
    scale_fill_gradient("Mordrate", low = "grey", high = "black")+
    coord_cartesian(xlim = c(-123,-68))+
    theme(panel.background = element_rect(colour = 'grey', fill = 'grey'))+
    xlab("Længdegrad\nAntal mord pr. 100,000 indbyggere") +
    ylab("Breddegrad") +
    ggtitle("US MORDRATE\nfordelt på stater")
```



```{r echo=FALSE}
vm <- usarrest$Murder[which(usarrest$Assault>150)]
nvm <- usarrest$Murder[which(usarrest$Assault<=150)]
ust <- t.test(as.vector(as.matrix(vm)),as.vector(as.matrix(nvm)),var.equal = TRUE)
uust <- t.test(as.vector(as.matrix(vm)),as.vector(as.matrix(nvm)),var.equal = FALSE)

```


Lad os groft dele staterne i voldelige og ikke-voldelige stater, hvis der er 150 overfald/assaults eller derunder, betegner vi staten som ikke voldelig. Stater med mere end 150 overfald pr 100000 borgere betegnes som voldelige.

Er det gennemsnitlige antal mord pr. 100000 borgere lavere i ikke-voldelige stater?

For at besvare spørgsmålet er man nødt til at sortere data efter Assualt og tage Murder med i sorteringen. Herefter skal man dele Murder i de voldelige og ikke-voldelige grupper. Hvis det driller kan man se hvordan sorteringen skal blive længere nede på 
Vi får følgende hypotesetest:

$$H_0: \mu_{voldelige}-\mu_{ikke-voldelige}\leq 0 $$
$$H_1: \mu_{voldelige}-\mu_{ikke-voldelige}> 0 $$

Der er `r length(which(usarrest$Assault<=150))` ikke voldelige stater, og `r length(which(usarrest$Assault>150))` voldelige stater. Vi skal altså huske at undersøge om stikprøverne stammer fra normalfordelte populationer, normalfraktildiagrammerne er her udeladt.

Vi skal også undersøge om der er varianshomogenitet. Hvis vi tester varianshomogenitet:

$$H_0: \sigma_{voldelige}=\sigma_{ikke-voldelige}$$
$$H_1: \sigma_{voldelige}=\sigma_{ikke-voldelige}$$

Konstaterer vi at på 5% signifikansniveau, ville vi konkludere at der er forskel på varianserne da p-værdien er `r var.test(vm,nvm)$p.value`. Konklusionen er dog niveaufølsom, men vi benytter pooled t-test her.

Vor hypotesetest for middelværdierne bliver:

$$H_0: \mu_{voldelige}-\mu_{ikke-voldelige}\leq 0$$
$$H_1: \mu_{voldelige}-\mu_{ikke-voldelige}> 0$$

Vi finder stikprøvegennemsnittene. For mordrater i voldelige stater er stikprøvegennemsnittet `r round(ust$estimate[1],2) `, for ikke voldelige er stater er stikprøvegennemsnittet `r round(ust$estimate[2],2) `.


Nedenfor er Freestat output for testen, vi ser testet for varianshomogenitet i blå ramme ,betyder vi bør benytte unpooled t-test:

![](img/freestatuscrimepooled.png)
Teststørrelsen i pooled t-testen ovenfor bliver stor `r round(ust$statistic,4)`, der er altså meget stor forskel på mordraten. Vi får tilsvarende nedenfor en unpooled teststørrelse på `r round(uust$statistic,4)`. Begge teststørrelser er langt større end 2, hvilket giver os meget små p-værdier, så vi vil med sikkerhed forkaste nulhypotesen i begge analyser. I unpooled testen bliver p-værdien et meget lille tal, tæt på 0%, dette kan ses i nedenstående Freestat output.

Output fra Freestat når vi benytter unpooled t-test til analysen, ses herunder:

![](img/USunpooled.png)


## Parret t-test  

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228416754' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>  

I video eksemplet benyttes et datasæt med 2 aktier, dette kan du [hente her.](https://www.dropbox.com/s/052q3a8z60kydmm/2%20aktiekurser.xls?dl=1)

Hvis vi betragter en variabel før og efter en treatment, her kan treatment fx. være en behandling med et medicinsk produkt, det er vigtigt at vi betragter samme respondenter, før og efter treatment. I parret t-test vil der altid være tale om samme størrelse af datasættene før og efter treatment, treatment kan også være tid. Hvis man forestiller sig at en bank måler 40 kunders gennemsnitlige netbank besøgstid, før og efter en softwareopdatering, hvis der her er tale om de samme kunder, kan vi bruge parret t-test her.  


## Spørgsmål 2 middelværdier

 
<br>
<details> 
  <summary> Spørgsmål 2 middelværdier bankdata.</summary>

Vi ser igen på [bankdata](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM). 


**1.** Bestem ved hjælp af konfidensintervaller for forskellen om der forskel på kvinder og mænds gennemsnitlige uddannelseslængde?  
**2.** Bestem ved hjælp af konfidensintervaller for forskellen om der forskel på ledelsens og administationens gennemsnitlige uddannelse i populationen?   

```{r echo=FALSE}
library(readxl)
library("exams")
BANKDATA <- read_excel("/cloud/project/FILER/BANKDATA.xls")

BANKDATA <- as.matrix(BANKDATA)

mdat <- as.numeric(as.vector(subset(BANKDATA,(BANKDATA[,4]=="male"),select = "education")))
fdat <- as.numeric(as.vector(subset(BANKDATA,(BANKDATA[,4]=="female"),select = "education")))
```


```{r echo=FALSE}
adat <- as.numeric(as.vector(subset(BANKDATA,(BANKDATA[,2]=="admin"),select = "education")))
mandat <- as.numeric(as.vector(subset(BANKDATA,(BANKDATA[,2]=="manage"),select = "education")))
```

</details> 
<br>
<details> 
  <summary> Svar 2 middelværdier bankdata.</summary>

**1.** Bemærk der er uens varianser, vi skal således benyttet Unpooled t-test til at bestemme konfidensintervaller.  
Der er `r round(length(fdat),2)` kvinder, deres gennemsnitlige uddanelseslængde er `r round(mean(fdat),2)`, Der er `r round(length(mdat),2)` mænd, deres gennemsnitlige uddanelseslængde er `r round(mean(mdat),2)`  
Vi kan med 95% sikkerhed sige at forskellen på mænds og kvinders gennemsnitlige uddannelse i populationen, ligger mellem `r round(t.test(mdat,fdat,var.equal =F)$conf.int[1],2)` år og `r round(t.test(mdat,fdat,var.equal =F)$conf.int[2],2)` år.  
Vi kan med 99% sikkerhed sige at forskellen på mænds og kvinders gennemsnitlige uddannelse i populationen, ligger mellem `r round(t.test(mdat,fdat,var.equal =F,conf.level = 0.99)$conf.int[1],2)` år og `r round(t.test(mdat,fdat,var.equal =F,conf.level = 0.99)$conf.int[2],2)` år. Vi er altså ret sikre på, at der er forskel på uddannelseslængden for mænd og kvinder, da 0 ikke engang er indeholdt i 99% konfidensintervallet.  

Havde vi i stedet benyttet pooled t-test havde vi nået samme konklusion, der er ikke meget forskel på grænserne:  
Vi kan med 95% sikkerhed sige at forskellen på mænds og kvinders gennemsnitlige uddannelse i populationen, ligger mellem `r round(t.test(mdat,fdat,var.equal =TRUE)$conf.int[1],2)` år og `r round(t.test(mdat,fdat,var.equal =TRUE)$conf.int[2],2)` år.  
Vi kan med 99% sikkerhed sige at forskellen på mænds og kvinders gennemsnitlige uddannelse i populationen, ligger mellem `r round(t.test(mdat,fdat,var.equal =TRUE,conf.level = 0.99)$conf.int[1],2)` år og `r round(t.test(mdat,fdat,var.equal =TRUE,conf.level = 0.99)$conf.int[2],2)` år. Vi er altså ret sikre på, at der er forskel på uddannelseslængden for mænd og kvinder, da 0 ikke engang er indeholdt i 99% konfidensintervallet.  

**2.** Bemærk der er uens varianser, vi skal således benyttet Unpooled t-test til at bestemme konfidensintervaller. Der er `r round(length(adat),2)` personer i administative stillinger, deres gennemsnitlige uddanelseslængde er `r round(mean(adat),2)`, Der er `r round(length(mandat),2)` i ledelsen, deres gennemsnitlige uddanelseslængde er `r round2(mean(mandat),2)`  
Vi kan med 95% sikkerhed sige at forskellen på ledelsens og administrationens gennemsnitlige uddannelse i populationen, ligger mellem `r round(t.test(mandat,adat,var.equal =F,conf.level = 0.95)$conf.int[1],2)` år og `r round2(t.test(mandat,adat,var.equal =F,conf.level = 0.95)$conf.int[2],2)` år.  

Vi kan med 99% sikkerhed sige at forskellen på ledelsens og administrationens gennemsnitlige uddannelse i populationen, ligger mellem `r round2(t.test(mandat,adat,var.equal =F,conf.level = 0.99)$conf.int[1],2)` år og `r round2(t.test(mandat,adat,var.equal =F,conf.level = 0.99)$conf.int[2],2)` år. Vi er altså ret sikre på at der er forskel på uddannelseslængden for ledere og administrativt personale, da 0 ikke engang er indeholdt i 99% konfidensintervallet.
</details> 
<br>
<details> 
  <summary> Spørgsmål 2016 8 Eksamen statistik Fin opg 3.</summary>

Opgave 3 (30 %)
En række klagesager i Nykøbing Bank har fået en del kunder til at forlade banken. Det er vigtigt for Nykøbing Bank at fastholde sine kunder i lokalområdet i mange år. Banken ønsker derfor en nærmere analyse af kundeancienniteten.  

Spørgsmål 3.1 (5 %)  
Undersøg om kundeancienniteten i banken er normalfordelt. 
  
Spørgsmål 3.2 (10 %)  
Test på 5 % testniveau om den gennemsnitlige kundeanciennitet er under 20 år.  
I undersøgelsen fra 2015 var kundeancienniteten på 20 år med en standardafvigelse på 10 år.  
  
Spørgsmål 3.3 (5 %)  
Test på 5 % testniveau om standardafvigelserne er ens i de 2 undersøgelser.  
  
Spørgsmål 3.4 (10 %)  
Test på 5 % testniveau om den gennemsnitlige anciennitet er faldet fra 2015 til 2016.  
  
<br>
Du finder hele opgaver i linket:  

[2016 8 Eksamen Statistik Opgave](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldWRQVGRwZWlkdzQ)  

[2016 8 Eksamen Statistik Data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlN29HR09IRmJZSE0)  

</details> 
<br>
<details> 
  <summary>Svar 2016 8 Eksamen statistik Fin opg 3.</summary>

<div >
<iframe width="500" height="280"
src="https://www.youtube.com/embed/keMbL_L-35U"

frameborder="0"> 
></iframe><p><center>Løsning eksamensopgave</center></p>
<div class="clear"></div>
</div>
[2016 8 Eksamen Statistik LØSNING](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlV1g0a3BLLTBzN1k)

</details> 

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=60" target="_blank">Selvtest Realkredit 2 middelværdier med videoløsning</a></h2>



# Korrelation



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->




<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226072242' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

Korrelationskoefficienten viser hvordan 2 variable varierer sammen, korrelationskoefficienten er et tal mellem -1 og 1. Dagstemperaturen og dagssalget af is på Seven Eleven, har positiv samvarians, vi siger de er positivt korrelerede. Høj temperatur (varme) betyder højt salg af is, lav temperatur (kulde) betyder lavt salg af is. Korrelationskoefficienten vil derfor være et positivt tal.

Dagstemperaturen og dagssalget af varm kakao på Seven Eleven, har negativ samvarians, vi siger de er negativt korrelerede. Høj temperatur (varme) betyder lavt salg af kakao, lav temperatur (kulde) betyder højt salg af kakao. korrelationskoefficienten vil derfor være et negativt tal.

Er korrelationskoefficienten 0 eller tæt på 0 er 2 variable ikke korrelerede, fx. nedbørsmængden i Bergen og Intel kursen.

Det er svært præcis at definere grænser for hvornår noget er korreleret stærkt og svagt eller slet ikke, herunder er dog et skema der angiver mulige tolkninger af korrelationskoefficienter.

|Korrelationskoefficient                  | Tolkning                       
|:-------------                 |:------------                    
-1 til -0.8                     | Stærk negativ korrelation
-0.8 til -0.6                  | Klar negativ korrelation
-0.6 til -0.3                  | Negativ korrelation
-0.3 til -0.15                  | Svag negativ korrelation
-0.15 til -0.1                  | Meget svag negativ korrelation
-0.1 til 0.1                  | Ingen korrelation
0.1 til 0.15                 | Meget svag positiv korrelation
0.15 til 0.3                  | Svag positiv korrelation
0.3 til 0.6                  | Positiv korrelation
0.6 til 0.8                  | Klar positiv korrelation
0.8 til 1                     | Stærk positiv korrelation

Ud fra korrelationskoefficienten alene, er det ikke umiddelbart muligt at tale om hvilken af de 2 variable der har effekt på den anden variabel. Korrelationskoefficienten fortæller alene, om der er en samvariation mellem 2 variable.

Vi kan betegne korrelationskoefficienten med r eller det græske bogstav $\rho$, man kan teste om korrelationskoefficenten er signifikant forskellig fra 0.

$$H_0:\rho=0\ dvs. \ ingen \ korrelation$$
$$H_A:\rho\neq0\ dvs.  \ korrelation$$
Vi ser nu på datasættet [HELBRED.xlsx](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlMTM1UUNMdzdoUm8) med helbredsoplysninger for 318 respondanter, hvor vi sammenligner variablene Spise frugt, Spise grøntsager,	Dyrke sport,	Højde og	Vægt. Nedenfor ses output fra Freestat

![](img/korr1.png)

Vi ser på tabelen korrelationsmatrice. Bemærk de 5 variable giver korrelationskoefficienter for de 10 mulige parvise kombinationer. Man behøver kun at se på koefficienterne under diagonalen med 1 taller, den øverste del er samme koefficienter. Der er 1 taller i diagonalen da fx. Spise frugt er perfekt positivt korreleret med sig selv.

Korrelationskoefficienterne er farvekodet jo rødere koefficient, des mere negativt korrelerede er 2 variable. Grønne koefficienter betyder positiv korrelation mellem 2 variable. Hvide eller svagt farvede betyder ingen eller ringe korrelation.

Ikke overraskende er der grøn positiv korrelationskoefficient på 0.38 mellem spise frugt og spise grøntsager. Det betyder respondenter der spiser megen frugt, har større tilbøjelighed til at spise mange grøntsager og omvendt. Ligeledes betyder dette at spiser man få grøntsager spiser man ligeledes lidt frugt.

Af den røde negative korrelationskoefficient på -0.1884 for grøntsager og vægt ses, at høj vægt betyder man spiser få grøntsager, lav vægt betyder flere grøntsager. Denne sammenhæng er ikke så stærk som for frugt og grøntsager.


Bemærk korrelationen beskriver en samvariation mellem 2 variable, men ikke hvad forklaringen er på samvariationen, hvis der overhovedet er en fornuftig forklaring på korrelationen. Vi siger at hvis der er en årsagssammenhæng mellem 2 variable, at der er kausalitet. Der kan godt være korrelation uden at der er kausalitet. 

Statistikere opdagede i 1920'erne positiv korrelation mellem antallet af lungekræfttilfælde og cigaretrygning. Der gik dog flere årtier inden man konstaterede, at der var kausalitet mellem rygning og lungekræft. 

### Spuriøse korrelationer  
Konstaterer man variable er korrelerede, uden en der er en fornuftig årsagssammenhæng, siger vi, der er tale om en spuriøs korrelation. 

Danske forskere opdagede, at der var positiv korrelation mellem antallet af børnefødsler og antallet af storkepar. Det var dog ikke storken der kom med børnene. Folk i landområder, får flere børn end folk i byområder af socioøkonomiske årsager. I byområder er der få storke. Når variablene forekomsten af børnefødsler og antallet af storkepar forklares af en mellemkommende variabel, urbaniseringsgrad, siger vi sammenhængen mellem storke og børnefødsler er spuriøs.

Der findes flere interessante sider, der udelukkende viser spuriøse sammenhænge mellem forskellige variable. <a href="http://www.tylervigen.com/spurious-correlations" target="_blank">spurious correlations</a> er en hjemmeside med mange sjove variable der er korrelerede, hvor det er svært at forestille sig en kausal sammenhæng.


<br>
<details> 
  <summary>Spørgsmål spuriøs korrelation.</summary>
[Hent datasættet spuriøs korrelation her](https://www.dropbox.com/s/1jerrptayat4xi7/spuri%C3%B8s%20korrelation.xlsx?dl=1), prøv i Freestat at beregne korrelationerne mellem skilsmisse og mælkeforbrug i første fane.

</details> 
<br>
<details> 
  <summary>Svar spuriøs korrelation.</summary>
<img src="img/corr1.png" alt="corr1.png" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>


Der er en stærk positiv korrelation mellem skilsmisse og mælkeforbrug. Korrelationskoefficienten er på 0.9706, men sammenhængen er spuriøs.  

</details> 
<br>
<details> 
  <summary>Spørgsmål spuriøs korrelation.</summary>
  
[Hent datasættet spuriøs korrelation her](https://www.dropbox.com/s/1jerrptayat4xi7/spuri%C3%B8s%20korrelation.xlsx?dl=1), prøv i Freestat at beregne korrelationerne mellem drukning og mord i anden fane.

</details> 
<br>
<details> 
  <summary>Svar spuriøs korrelation.</summary>
<img src="img/corr2.png" alt="corr2.png" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

Der er en stærk positiv korrelation mellem drukning og mord. Korrelationskoefficienten er på 0.8506, men sammenhængen er spuriøs.

</details> 
<br>
<details> 
  <summary>Spørgsmål spuriøs korrelation.</summary>
  
[Hent datasættet spuriøs korrelation her](https://www.dropbox.com/s/1jerrptayat4xi7/spuri%C3%B8s%20korrelation.xlsx?dl=1), prøv i Freestat at beregne korrelationerne mellem ost og bier i tredie fane.

</details> 
<br>
<details> 
  <summary>Svar spuriøs korrelation.</summary>

<img src="img/corr3.png" alt="corr3.png" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

Der er en positiv korrelation mellem ost og bier. Korrelationskoefficienten er på 0.4474, men sammenhængen er spuriøs.

</details> 
<br>
<details> 
  <summary>Spørgsmål korrelation.</summary>
  
[Hent datasættet Ford her](https://www.dropbox.com/s/21hf56ppe409pis/Ford.xlsx?dl=1), der viser salgspriser, kørte km etc. Beregn korrelationskoefficienterne mellem variablene År, Pris DKK,	Alder (år) og Kilometer. 
1. Er disse som vi ville forvente, er korrelationerne kausale?
2. Hvorfor er korrelationskoefficienten mellem År og Pris positiv når korrelationskoefficienten mellem Alder (år) og pris er negativ?
3. Hvorfor er korrelationskoefficienten mellem År og Alder (år) og pris perfekt negativt korrelleret?

</details> 
<br>
<details> 
  <summary>Svar korrelation.</summary>

<img src="img/ford.png" alt="ford.png" align="right" width="100%" height="100%"style="border:0px solid #eeeeee; padding:5px; margin:6px;"/>

1. Ja korrelationerne er kausale:  
År og Pris DKK er positivt korrelerede jo højere produktionsår jo nyere bil desto højere pris.   
År og Alder (år) er negativt korrelerede, jo højere produktionsår des lavere alder i år.  
År og Kilometer er negativt korrelerede jo højere produktionsår jo færre Kilometer har bilen kørt.  
Pris DKK og Alder (år) er negativt korrelerede jo højere pris des lavere Alder i år.  
Pris DKK og Kilometer er negativt korrelerede jo højere pris jo færre Kilometer.  
Alder (år) og Kilometer er positivt korrelerede jo ældre bil des flere Kilometer er der kørt.  

2. Hvorfor er korrelationskoefficienten mellem År og Pris positiv når korrelationskoefficienten mellem Alder (år) og pris er negativ?  
År er produktionsåret og Alder er antal år højt produktionsår giver lav alder.  

3. Hvorfor er korrelationskoefficienten mellem År og Alder (år) og pris perfekt negativt korrelleret?
Fordi Alder beregnes direkte ud fra 2014 - produktionsår, derfor er Alder år altid givet ud fra produktionsåret.  

</details> 

<!-- Ønsker man eksempelvis at undersøge om højde er korreleret med vægt kan man opstille hypoteserne: -->

<!-- $$H_0:\rho_{højde/vægt}=0\ dvs. \ ingen \ korrelation\ mellem \ højde\ og \ vægt$$ -->
<!-- $$H_A:\rho_{højde/vægt}\neq0\ dvs.  \ korrelation\ mellem \ højde\ og \ vægt$$ -->

<!-- Korrelationskoefficienten 0.4974, findes i første tabel 5. række 4. søjle. -->
<!-- Vi finder p-værdien 0.0000, for testet i anden tabel tabel 5. række 4. søjle, da p-værdien, er meget lav og klart mindre end 5% signifikansniveauet, forkaster vi nulhypotesen. Der er altså korrelation mellem højde og vægt. -->

<!-- Havde vi testet om korrelationen var positiv, ville hypoteserne i stedet have været: -->

<!-- $$H_0:\rho_{højde/vægt}\leq0\ dvs. \ korrelation\ mellem \ højde\ og \ vægt\ er\ ikke \ positiv$$ -->
<!-- $$H_0:\rho_{højde/vægt}>0\ dvs. \ korrelation\ mellem \ højde\ og \ vægt\ er \ positiv$$ -->
<!-- Vi må da se på 2. tabel med p-værdier for et-sidet alternativ hypotese opad i figuren nedenfor, igen p-værdien er meget lille 0.0000, der er altså positiv korrelation mellem højde og vægt. -->
<!-- ![korr2](img/korr2.png) -->




# Lineær regressionsanalyse  



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "36813, 39445,38854,38855,36811,36812"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->




<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228379418' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


```{r OMX-data,include=FALSE}
library(ggplot2)
# companies <- c("TRYG.CO","COLO-B.CO","DANSKE.CO","FLS.CO","GEN.CO","MAERSK-A.CO")
# col <- seq(6,length(companies)*6,by=6)
# ndb <- 200
# DKkurs <- data.frame(yahooSeries(companies, from = NULL, to = Sys.timeDate(), nDaysBack = ndb))[,col]
# DKdf <- round(100*((DKkurs[2:nrow(DKkurs),]-DKkurs[1:nrow(DKkurs)-1,])/DKkurs[1:nrow(DKkurs)-1,]),2)
# names(DKdf) <- c("TRYG","COLO","DDB","FLS","GEN","MAERSK")
# WriteXLS("DKdf", ExcelFileName = paste0("DK aktiekurser ",Sys.Date(),".xls"), SheetNames = "Kurser",col.names = TRUE,row.names = TRUE,AdjWidth = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
# done <- drop_upload(paste0("DK aktiekurser ",Sys.Date(),".xls"))
# drop_get(paste0("DK aktiekurser ",Sys.Date(),".xls"), overwrite = TRUE)
```


Hvis en variabel Y, påvirkes lineært af en anden X, kan vi bestemme en lineær funktion til at forudsige værdien af Y for værdier af X. Nedenfor er et mini-eksempel vi kun benytter for at vise hvad det er vi beregner. Vi går ikke i detaljer med de matematiske beviser og formler bag teknikken.

## Joe and The Juice
En kvik juicer har observeret hvordan vejret er, og hvor mange Go Away Doc drinks, der er solgt. 



|Temperatur | Drinks|
|:-----      |:----- |
|2          |1      |
|4          |5      |
|8          |6      |







Det virker ikke logisk at salget på Joe and the Juice påvirker temperaturen, derimod giver det god mening at temperaturen påvirker salget af drinks. Vi angiver salget af drinks på y-aksen og temperaturen på x-aksen.<img src="img/joeandthejuice.png" align="right" width="40%" height="40%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

Variablen vi ønsker at forudsige, her salget af drinks, kalder vi:

- Y
- Responsvariablen
- Den forklarede variabel
- Den afhængige variabel
- Den endogene variabel

En variabel vi bruger til at forudsige, her temperaturen, kaldes:

- X
- Prædiktoren
- Den forklarende variabel
- Den uafhængige variabel
- Den eksogene variabel

Baseret på observationerne kan vi forsøge at forudsige salget af drinks, til dette formål opstiller vi en lineær model.
Normalt når vi har en lineær funktion har vi i matematik lært at denne har forskriften $$y=ax+b$$
Når vi har at gøre med lineær regression bruger vi typisk betegnelsen $\beta_1$ eller mere sigende $\beta_{temperatur}$ eller $\beta_{temp}$ om hældningskoefficienten $a$. Vi bruger ofte betegnelsen $\beta_0$ eller $\alpha$ om skæringen med y-aksen b også kaldet interceptet.



Det betyder vores gamle matematik formel for linjen $$y=ax+b$$ Bliver til vores model af virkeligheden: $$\hat{Y}=\hat{\beta}_{temp} \cdot X_{temp}+\hat{\beta}_0$$ For at vi kan bruge modellen til at sige noget om salget af drinks, skal vi baseret på vore observationer estimere hældningskoefficienten $\beta_{temp}$ og skæringen $\beta_0$. Vi kender ikke de sande værdier parametrene $\beta_{temp}$ og $\beta_0$, men ud fra vore faktiske observationer kan vi give vores bedste gæt parameterestimaterne $\hat{\beta}_{temp}$ og $\hat{\beta}_0$. Software beregner parameterestimaterne til linjen, der bedst beskriver sammenhængen mellem den uafhængige variabel temperatur og responsvariablen drinks. Vi kalder denne linje regressionslinjen. Da den beregnede værdi af antallet af drinks er baseret på estimater, vælger vi at skrive $\hat{Y}$ i stedet for $Y$






Nedenstående forklaring på metoden til beregning af modellens forklaringskraft, kan være svær at forstå. Det er ikke nødvendigt for at fortolke modellerne, men kan give indsigt i mekanikken bag modellen.

Når vi beregner estimaterne for regressionslinjen, bruger vi en metode, der kaldes mindste kvadraters metode (på engelsk ordinary least squares OLS) til at beregne vore estimater.

Vi får software til at beregne de 2 estimater 
$$\hat{\beta}_{temp}=0.75 ~~ \hat{\beta}_0=0.5$$
Disse parameterestimater kan vi nu indsætte i modellen:

$$\hat{Y}=\hat{\beta}_{temp} \cdot X_{temp}+\hat{\beta}_0$$
$$\hat{Y}=0.75 \cdot X_{temp}+0.5$$


Når vi kender en temperatur fx. 6 grader, kan vi indsætte denne værdi i regressionslinjen, i stedet for $X_{temp}$ og forudsige/estimere hvad salget af drinks vil være.
$$\hat{Y}=0.75 \cdot X_{temp}+0.5 \Leftrightarrow$$
$$\hat{Y}=0.75 \cdot 6+0.5\Leftrightarrow$$
$$\hat{Y}=5$$

Vi kan i figuren se at de sorte prikker er faktiske observationer, og linjen er modellen af virkeligheden. Vi har beregnet modellens forudsigelse af drinkssalget ved de 3 temperaturer 2, 4 og 8 grader, modellens forudsigelser er illustreret ved sorte trekanter. Vi kalder forskellen mellem faktiske og observerede værdier for residualer, definitionen for residualer er altså faktisk minus observeret værdi. Man benytter ofte det græske bogstav epsilon $\epsilon$ til at betegne residualerne. For at have et mål for hvor stor forskellen mellem modellen og de faktiske observationer er samlet set, bruger vi summen af de kvadrerede residualer SSR.
Residualer af observerede salg af drinks beregnes som: $$SSR=(1-2)^2+(5-3.5)^2+(6-6.5)^2=1+2.25+0.25=3.5$$ Vi kalder værdien for summen af kvadrerede residualer på engelsk SSR sums of squared residuals, de 3 kvadrerede residualer er illustreret som de 3 grå kvadrater i figuren nedenfor.


```{r joereg1,echo=FALSE,fig.width=9, fig.height=9,dev="svg"}
Drinks <- c(1,5,6)
Temperatur <- c(2,4,8)
joe <- data.frame(Drinks,Temperatur)
ggplot(joe, aes(x=Temperatur, y=Drinks)) +
  geom_point(shape=16,size=3)+
  geom_smooth(method=lm, se=FALSE, color="black",lwd=0.5)+
  #geom_hline(yintercept=4)+
  annotate("text", label = "(8,6)", x = 8.2, y = 6, size = 3, colour = "black")+
  ggtitle("Go away doc drinks\nsalg pr. periode")+
  annotate("rect", xmin = 2, xmax =3 , ymin = 1, ymax = 2,  alpha = .2)+
  annotate("rect", xmin = 4, xmax =5.5 , ymin = 3.5, ymax = 5,  alpha = .2)+
  annotate("rect", xmin = 7.5, xmax =8 , ymin = 6, ymax = 6.5,  alpha = .2)+
  geom_point(x=2,y=2,shape=17,size=3)+
  geom_point(x=4,y=3.5,shape=17,size=3)+
  geom_point(x=8,y=6.5,shape=17,size=3)+
  annotate("text", label = "(2,2)\nForudsagt drinkssalg 2", x = 2.1, y = 2, size = 3,hjust = 0)+
  annotate("text", label = "(4,3.5)\nForudsagt drinkssalg 3.5", x = 4.1, y = 3.5, size = 3,hjust = 0)+
  annotate("text", label = "(2,1)\nFaktisk drinkssalg 1", x = 2.1, y = 1, size = 3,hjust = 0)+
  annotate("text", label = "(4,5)\nFaktisk drinkssalg 5", x = 4.1, y = 5, size = 3,hjust = 0)+
  annotate("text", label = "(8,6.5)", x = 8.1, y = 6.5, size = 3,hjust = 0)+
  geom_segment(x=2,xend=2,y=1,yend=2,lty=2)+
  annotate("text", label = "Residualen=1-2=-1", x = 1.9, y = 1,angle = 90,hjust = 0, size = 3, colour = "black")+
  geom_segment(x=2,xend=2,y=1,yend=2,lty=2)+
  geom_segment(x=8,xend=8,y=6.5,yend=6,lty=2)+
  annotate("text", label = "Residualen=1-2=-1", x = 1.9, y = 1,angle = 90,hjust = 0, size = 3, colour = "black")+
  geom_segment(x=4,xend=4,y=3.5,yend=5,lty=2)+
  annotate("text", label = "Residualen=5-3.5=1.5", x = 3.9, y = 3.5,angle = 90,hjust = 0, size = 3, colour = "black")+
  geom_point(x=2,y=6.2,shape=17,size=3)+
  annotate("text", label = "Forudsagt salg af drinks ifølge modellen",x=2,y=6.2,size=3,hjust=-0.065)+
  geom_point(x=2,y=6.4,shape=16,size=3)+
  annotate("text", label = "Faktisk salg af drinks",x=2,y=6.4,size=3,hjust=-0.12)+
  geom_segment(x=1.9,xend=2.08,y=6,yend=6,lty=2)+
  annotate("text", label = "Residualen = faktisk salg - forudsagt salg",x=2,y=6,size=3,hjust=-0.06)+
  annotate("text", label = "Summen af arealerne SSR = 1 + 2.25 + 0.25 = 3.5",x=2,y=5.8,size=3,hjust=-0.06)+
  annotate("text", label = "Regressionslinjens ligning er:\ny = 0.75x + 0.5",x=6,y=5,size=4,hjust=-0.2)+
  annotate("text", label = "Arealet er\n1*1=1",x=2.1,y=1.6,size=3,hjust=0)+
  annotate("text", label = "Arealet er\n1.5*1.5=2.25",x=4.1,y=4.5,size=3,hjust=-0.2)+
  annotate("text", label = "Arealet er\n0.5*0.5=0.25",x=7.4,y=6.25,size=3,hjust=0)
```

Hvis der ikke er en lineær sammenhæng mellem temperatur og drinkssalg, og regressionslinjen derfor ikke kan bruges til at forklare salget, så kan vi i stedet benytte det observerede gennemsnitlige salg af drinks. Vi beregner det gennemsnitlige salg af drinks i stikprøven som $\frac{1+5+6}{3}=\frac{12}{3}=4$. Vi beregner nu de summen af de kvadrerede afvigelser fra det gennemsnitlige observerede salg af drinks som:
$$SST=(1-4)^2+(5-4)^2+(6-4)^2=9+1+4=14$$ 

Vi kalder værdien for summen af kvadrerede afvigelser total på engelsk SST sums of squared total, de 3 kvadrerede afvigelser er illustreret som de 3 grå kvadrater i figuren nedenfor.

<div class="Keats">
<b>Ekstrapolation</b> <img src="img/engine.png" align="right" width="40%" height="50%"style="border:0.0px solid #eeeeee; padding:2px; margin:3px;"/>
To statistikere flyver fra København til New York. En time inde i flyvningen meddeler piloten, man har mistet en motor, der er dog ikke grund til bekymring, der er stadig 3 tilbage, rejsetiden vil dog blive 11 i stedet for 9 timer.

Lidt efter meddeler piloten, at man har mistet yderligere en motor, der er dog stadig 2 tilbage, men rejsetiden vil nu være 15 timer.

Noget senere vender piloten tilbage 3. motor har også sat ud, nu vil det tage 22 timer at nå frem.

Hvorpå den ene statistiker udbryder "Fandens! hvis den sidste motor sætter ud, vil vi være i luften i evigheder"
</div>

Vi kan vise hvor godt responsvariablen forklares ud fra den forklarende variabel i modellen, vha. forholdet mellem SSR og SST. Er SSR og SST næsten ens, vinder vi ikke meget ved at beskrive responsvariablen Y ud fra den forklarende variabel X. SST vil aldrig være mindre end SSR, da en linje med tilpasset hældningskoefficient altid vil beskrive  observationerne mindst ligeså godt som en vandret linje. Vi beskriver modellens forklaringskraft ud fra R-kvadreret som er defineret som 

$$1-\frac{SSR}{SST}=1-\frac{3.5}{14}=1-0.25=0.75$$

Vi kan udtrykke dette som at 75% af variationen i responsvariablen - Drinks solgt kan forklares ved variationen i den forklarende variabel - Temperatur. Denne forklaringskraft afhænger dog af om der er nok observationer, og at disse viser at hældningen på den rette linje er signifikant forskellig fra 0. Er hældningen på linjen 0, betyder det, at man sælger samme antal drinks ligegyldigt hvordan vejret er. Vi bør have flere observationer end de kun 3 vi benytter i dette minieksempel. 


```{r joereg2,echo=FALSE,fig.width=9, fig.height=9 ,dev="svg"}
Drinks <- c(1,5,6)
Temperatur <- c(2,4,8)
joe <- data.frame(Drinks,Temperatur)
ggplot(joe, aes(x=Temperatur, y=Drinks)) +
  geom_point(shape=16,size=3)+
  #geom_smooth(method=lm, se=FALSE, color="black",lwd=0.5)+
  geom_hline(yintercept=4)+
  annotate("text", label = "(8,6)", x = 8.2, y = 6, size = 3, colour = "black")+
  ggtitle("Go away doc drinks\nsalg pr. periode")+
  annotate("rect", xmin = 2, xmax =5 , ymin = 1, ymax = 4,  alpha = .2)+
  annotate("rect", xmin = 4, xmax =5 , ymin = 4, ymax = 5,  alpha = .2)+
  annotate("rect", xmin = 6, xmax =8 , ymin = 6, ymax = 4,  alpha = .2)+
  geom_point(x=2,y=4,shape=17,size=3)+
  geom_point(x=4,y=4,shape=17,size=3)+
  geom_point(x=8,y=4,shape=17,size=3)+
  annotate("text", label = "(2,4)", x = 2.1, y = 4, size = 3,hjust = 0)+
  annotate("text", label = "(4,4)", x = 4.1, y = 4, size = 3,hjust = 0)+
  annotate("text", label = "(2,1)\nFaktisk drinkssalg 1", x = 2.1, y = 1, size = 3,hjust = 0)+
  annotate("text", label = "(4,5)\nFaktisk drinkssalg 5", x = 4.1, y = 5, size = 3,hjust = 0)+
  annotate("text", label = "(8,4)", x = 8.1, y = 4, size = 3,hjust = 0)+
  geom_segment(x=2,xend=2,y=1,yend=4,lty=2)+
  annotate("text", label = "Afvigelse=1-4=-3", x = 1.9, y = 2,angle = 90,hjust = 0, size = 3, colour = "black")+
  geom_segment(x=2,xend=2,y=1,yend=4,lty=2)+
  geom_segment(x=4,xend=4,y=4,yend=5,lty=2)+
  annotate("text", label = "Afvigelse=5-4=1", x = 3.9, y = 4.2,angle = 90,hjust = 0, size = 3, colour = "black")+
  geom_segment(x=8,xend=8,y=4,yend=6,lty=2)+
  annotate("text", label = "Afvigelse=6-4=-2", x = 8.1, y = 4.6,angle = 90,hjust = 0, size = 3, colour = "black")+
  
  geom_point(x=2,y=6.2,shape=17,size=3)+
  annotate("text", label = "Gennemsnitligt salg af drinks i stikprøven",x=2,y=6.2,size=3,hjust=-0.065)+
  geom_point(x=2,y=6.4,shape=16,size=3)+
  annotate("text", label = "Faktisk salg af drinks",x=2,y=6.4,size=3,hjust=-0.12)+
  geom_segment(x=1.9,xend=2.08,y=6,yend=6,lty=2)+
  annotate("text", label = "Afvigelsen = faktisk salg - gennemsnitligt salg",x=2,y=6,size=3,hjust=-0.06)+
  annotate("text", label = "Summen af arealerne SST = 9 + 1 + 4 = 14",x=2,y=5.8,size=3,hjust=-0.06)+
  annotate("text", label = "R-kvadreret = 1 - SSR / SST = 1 - 3.5 / 14 = 0.75",x=2,y=5.6,size=3,hjust=-0.06)+
  #annotate("text", label = "Regressionslinjens ligning er:\ny = 0.5 + 0.75x",x=6,y=5,size=4,hjust=-0.2)+
  annotate("text", label = "Arealet er\n3*3=9",x=3.1,y=2.6,size=3,hjust=0)+
  annotate("text", label = "Arealet er\n1*1=1",x=4.1,y=4.5,size=3,hjust=-0.2)+
  annotate("text", label = "Arealet er\n2*2=4",x=6.8,y=5,size=3,hjust=0)
```


Her har vi kun en forklarende variabel temperatur, vi kalder derfor specielt analysen for simpel lineær regression. Vi vil senere se på analyse vha. lineær regression med flere forklarende variable, denne analysetype kalder vi for multipel lineær regression.

## Freestat output lineær regression Joe and The Juice
Vi kan få software til at beregne output for os, i Freestat kan fanen mreg, benyttes til lineær regression. Vi skal altid taste værdier for responsvariablen Y i **I-søjlen** husk overskift. Vi sætter en eller flere forklarende variable i de efterfølgende søjler. 

![](img/freestatmregjoe.png)

I cellen **C11** ses SSR som vi tidligere regnede ud til at være 3.5.  
I cellen **C12** ses SST som vi tidligere regnede ud til at være 14.  
I cellen **B3** ses R-kvadreret som vi tidligere regnede ud til at være 0.75.  
I cellen **B15** ses estimatet for parameteren $\beta_0$ altså $\hat{\beta}_0$.  
I cellen **B16** ses estimatet for parameteren $\beta_{temp}$ altså $\hat{\beta}_{temp}$.  
I cellerne **I3-I5** har vi de faktiske værdier.  
I cellerne **G3-G5** har vi de forventede eller forudsagte værdier.  
I cellerne **H3-H5** har vi residualerne, dette er faktisk minus forudsagt.  

Vi nævnte tidligere at modellen her egentlig er fjollet lille, dette resulterer i at den ikke kan bruges til noget, da den ene forklarende variabel ikke er signifikant. 

Vi opstiller et t-test, for at afgøre om teperaturen har en effekt:  

$$H_0:\beta_{temp}=0 \ Den\ forklarende\ variabel\ er\ ikke\ signifikant$$$$H_1:\beta_{temp}\neq 0 \ Den\ forklarende\ variabel\ er\ signifikant$$ 

Nulhypotesen betyder at vi ikke kan afvise at hældningen på regressionslinjen er 0, hvilket betyder at den vil være vandret. Hvis regressionslinjen er vandret har temperaturen ingen effekt på salget, salget vil jo være konstant ifølge modellen.  

Alternativhypotesen siger derimod at den ene forklarende variabel er signifikant forskellig fra 0. Det vil altså sige at temperaturen har effekt på drinkssalg.  

I cellen **D16** ses t-teststørrelsen for testet af $\beta_{temp}$, er teststørrelsen cirka mindre end -2 eller større end 2, får vi en p-værdi der er mindre end 0.05.  
I cellen **E16** ses p-værdien for testet, her er p-værdien større end 0.05, hvilket betyder, vi kan ikke forkaste nulhypotesen. Vi kan altså ikke afvise at $\beta_{temp}=0$, hvilket vil sige temperaturen påvirker ikke salget af drinks signifikant. Havde vi haft en større stikprøvestørrelse, er det muligt, vi havde kunnet konkludere at hældningen $\beta_{temp}$, var signifikant forskellig fra 0.  



## Forudsætninger lineær regression.

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228381611' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

Der er 4 forudsætninger, der skal være opfyldt for at kvaliteten af vor lineære regressionsmodel er god. Linearitet, varianshomogenitet, uafhængighed residualer og normalitet residualer. Vi kan undersøge om de 4 forudsætninger er opfyldt, ved at se på 3 forskellige plots et linjetilpasningsplot, et residualplot og et normalfraktildiagram.  Et linjetilpasningsplot er et xy-punktdiagram hvor regressionslinjen er indtegnet. De 3 plots tegnes automatisk, når man genererer en lineær regressionsmodel i Freestat.

### Linearitet
For at benytte lineær regression, er den vigtigste forudsætning, at der er en lineær sammenhæng mellem den forklarende variabel X og responsvariablen Y. Er der ikke en lineær sammenhæng, kan vi ikke beskrive sammenhængen ved en lineær regressionsmodel. Herunder er nogle eksempler på linjetilpasningsplots, hvor der er problemer med forudsætningen om lineraritet.

I de fire røde linjetilpasningsplots, er der problemer med linearitet. Responsvariablen i plot 1 og 2, kunne bedre beskrives ved en parabel. Modellerne over- og undervurderer konsekvent værdien af y. Hvis forudsætningen om linearitet, ikke er opfyldt er det alvorligt, vi ser af figurerne at modellen ikke vil beskrive responsvariablen korrekt. Responsvariablen i plot 3 og 4 kunne synes at følge en eksponentiel eller polynomisk udvikling. Bemærk man kan ikke umiddelbart ud fra r-kvadereret og p-værdien for F- og t-testet, konstatere at der er problemer med linearitetsantagelsen. Vi kan imidlertid let se der er problemer med lineariteten i linjetilpasningsplots.

```{r pol1,echo=FALSE,fig.width=9, fig.height=18 ,dev="svg"}
par(mfrow=c(4,1))
x <- sort(rnorm(125,200,100))
y <- 0.01*(x-250)^2+400+rnorm(125,0,30)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 1, 125 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25, col = "black", font = 4))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")


x <- sort(rnorm(125,200,100))
y <- 0.01*(x-250)^2+400+rnorm(125,0,30)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 2, 125 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25, col = "black", font = 4))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")


x <- rnorm(125,100,10)
y <- 1.1^x+rnorm(125,0,2000)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot, 125 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25, col = "black", font = 4))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")

x <- sort(rnorm(125,100,10))
y <- 1.1^x+rnorm(125,0,4000)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 4, 125 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25,  col = "black", font = 1))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")



```




I de 4 linjetilpasningsplots nedenfor er problemet, at der tilsyneladende ikke er en lineær sammenhæng mellem den forklarende og responsvariablen. Vi kan her se ud fra R-kvadreret, at modellens forklaringskraft er meget lav for de 4 linjetilpasningsplots. Her giver det således ikke mening at beskrive responsvariablen ud fra den forklarende variabel.  

```{r scatter2,echo=FALSE,fig.width=9, fig.height=18 ,dev="svg"}
par(mfrow=c(4,1))
x <- sort(rnorm(500,100,10))
y <- rnorm(500,4000,4000)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 5, 500 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25,
                  col = "black", font = 4))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")


x <- sort(rnorm(125,100,10))
y <- rnorm(125,4000,4000)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 6, 125 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25,
                  col = "black", font = 4))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")



x <- sort(rnorm(125,100,10))
y <- rnorm(125,4000,4000)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 7, 125 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25, col = "black", font = 4))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")

x <- sort(rnorm(125,100,10))
y <- rnorm(125,4000,4000)
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 8, 125 observationer\nForudsætningen om linearitet er ikke opfyldt", cex = 1.25, col = "black", font = 4))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")
```

I de 4 linjetilpasningsplots 9 til 12, nedenfor er forudsætningen om linearitet opfyldt, bemærk p-værdierne alle er mindre end 5% samt R kvadreret er relativt høj.  

```{r scatter1,echo=FALSE,fig.width=9, fig.height=18 ,dev="svg"}
par(mfrow=c(4,1))
x <- rnorm(125,100,10)
xa <- runif(125,1.1,1.3)
y <- xa*x+100
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "lawngreen")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 9, 125 observationer\nForudsætningen om linearitet er opfyldt", cex = 1.25,  col = "black", font = 1))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")



x <- rnorm(125,100,10)
xb <- rnorm(125,0,4)
y <- -.5*x+xb
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "lawngreen")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 10, 125 observationer\nForudsætningen om linearitet er opfyldt", cex = 1.25,  col = "black", font = 1))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")

x <- rnorm(125,100,10)
xb <- rnorm(125,0,4)
y <- .8*x+xb
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "lawngreen")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 11, 125 observationer\nForudsætningen om linearitet er opfyldt", cex = 1.25,  col = "black", font = 1))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")


x <- rnorm(125,100,10)
xb <- rnorm(125,0,4)
y <- -.8*x+xb
plot(x,y ,xlab="x forklarende variabel",ylab="y responsvariablen",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "lawngreen")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,2)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Linjetilpasningsplot 12, 125 observationer\nForudsætningen om linearitet er opfyldt", cex = 1.25,  col = "black", font = 1))
legend("topright",
       cex = .95,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")
```



### Varianshomogenitet
Varianshomogenitet betyder responsvariablen Y skal have samme afvigelse fra regressionslinjen ligegyldigt hvilken værdi den uafhængige variabel X har. I eksemplet med Joe and the Juice betyder det, for alle temperaturer skal det faktiske salg af drinks, afvige nogenlunde med samme størrelse. Hvis det fx. er 20 grader og afvigelsen i forhold til det af modellen forudsagte er 100 drinks mod en afvigelse på kun 5 drinks når det er 0 grader, er der ikke varianshomogenitet. Det er nemmest at undersøge om der er varianshomogenitet, ved at se på residualplottet. Hvis der fx. er en trompetform, som i residualplots 1, 2, 3 og 4 nedenfor, er antagelsen om varianshomogenitet ikke opfyldt. I residualplot 1 vil modellen være meget præcis, når X antager værdier mellem 60 og 90 og gradvis mere upræcis herefter. Der er er varianshomogenitet i resiualplots 5, 6, 7 og 8, det kan vi se da de lodrette afstande er nogenlunde de samme for alle værdier af den uafhængige variabel X, hvilket betyder variationen i afvigelserne er ens for alle værdier af den uafhængige variabel.  
  
Er der varianshomogenitet, siger man med et fint specialudtryk, at der er homoskedasticitet, hvilket betyder der er ens varians for de forudsagte værdier og dermed ingen trompetform, forudsætningen er altså opfyldt. Hvis der er trompetform, siger vi med et fint ord, at der er heteroskedasticitet, så er der altså ikke varianshomogenitet, forudsætningen er således ikke opfyldt.




### Uafhængighed residualer

Uafhængighed af residualer betyder at hverken værdien af X eller andre residualer påvirker en residual, målefejlen er altså tilfældig. I resiualplots 1, 2, og 3 er der uafhængighed mellem residualerne, lave residualer medfører fx ikke nødvendigvis lave eller høje residualer. Der er som før beskrevet ikke varianshomogenitet , men der er ikke afhængighed i residualerne. 
I resiualplots 4, 5 og 6, er der ikke uafhængige residualer, lave residualer medfører lave residualer og høje residualer medfører høje residualer. Der må ikke være systematik imellem residualerne, punkterne i residualplottet skal ligge tilfældigt som i residualplot 7 og 8, her er både antagelsen om varianshomogenitet og uafhængige residualer opfyldt.

```{r residualplots,echo=FALSE,fig.width=9, fig.height=36 ,dev="svg"}
par(mfrow=c(8,1))
x <- sort(rnorm(500,100,10))
y <- rnorm(500,0,seq(0,49.9,.1))
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 1, 500 observationer\nForudsætningen om varianshomogenitet er ikke opfyldt.\nForudsætningen om uafhængighed er opfyldt", cex = 1.25, font = 4))


x <- sort(rnorm(500,100,10))
y <- rnorm(500,0,seq(10,59.9,.1))
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 2, 500 observationer\nForudsætningen om varianshomogenitet er ikke opfyldt.\nForudsætningen om uafhængighed er opfyldt", cex = 1.25,
                  col = "black", font = 4),ylab="Residualer")

x <- sort(rnorm(500,100,10))
y <- rnorm(500,0,seq(10,59.9,.1))
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 3, 500 observationer\nForudsætningen om varianshomogenitet er ikke opfyldt.\nForudsætningen om uafhængighed er opfyldt", cex = 1.25,
                  col = "black", font = 4))




x <- sort(rnorm(500,100,10))
y <- rnorm(500,seq(-251,250,1),seq(10,59.9,.1))
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 4, 500 observationer\nForudsætningen om varianshomogenitet er ikke opfyldt.\nForudsætningen om uafhængighed er ikke opfyldt", cex = 1.25,
                  col = "black", font = 4),ylab="Residualer")


x <- sort(rnorm(500,100,10))
y <- rnorm(500,seq(-251,250,1),100)
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 5, 500 observationer\nForudsætningen om varianshomogenitet er opfyldt.\nForudsætningen om uafhængighed er ikke opfyldt", cex = 1.25,
                  col = "black", font = 4),ylab="Residualer")


x <- sort(rnorm(500,100,10))
y <- rnorm(500,c(rev(seq(-249,0,1)),seq(-249,0,1)),50)
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 6, 500 observationer\nForudsætningen om varianshomogenitet er opfyldt.\nForudsætningen om uafhængighed er ikke opfyldt", cex = 1.25,
                  col = "black", font = 4),ylab="Residualer")



x <- sort(rnorm(500,100,10))
y <- rnorm(500,0,10)
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "lawngreen")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 7, 500 observationer\nForudsætningen om varianshomogenitet er opfyldt.\nForudsætningen om uafhængighed er opfyldt", cex = 1.25,
                  col = "black", font = 4),ylab="Residualer")

x <- sort(rnorm(500,100,10))
y <- rnorm(500,0,10)
plot(x,y ,xlab="Forudsagt værdi af Y",ylab="Residualer",pch=19)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "lawngreen")
grid(col = "white",lty =1)
points(x,y,pch=19)
title(main = list("Residualplot 8, 500 observationer\nForudsætningen om varianshomogenitet er opfyldt.\nForudsætningen om uafhængighed er opfyldt", cex = 1.25,
                  col = "black", font = 4),ylab="Residualer")



```

### Normalitet residualer
Vi kan undersøge normaliteten af residualerne ved at plotte disse i et normalfraktildiagram. Her skal punkterne ligge tæt omkring den rette linje. Af nedenstående plots er kun residualerne i 1. plot normalfordelte.

```{r normalfraktildiagrammer,echo=FALSE,warning=FALSE,fig.width=9, fig.height=9 ,dev="svg"}
par(mfrow=c(2,2))
rn <- rnorm(100)
qq <- qqnorm(rn, ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "lawngreen")
grid(col = "white",lty =1)
points(qq$x,qq$y,ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
title(main = list("Normalfraktildiagram 1, 100 observationer\nResidualerne er normalfordelte", cex = 1.25,
                  col = "black", font = 4))
qqline(rn)

x <- sort(rnorm(100,10,5))
y <- x^2
qq <- qqnorm(lm(y ~ x)$residuals,ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(qq$x,qq$y,ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
title(main = list("Normalfraktildiagram 2 100 observationer\nResidualerne er ikke normalfordelte", cex = 1.25,
                  col = "black", font = 4))
qqline(lm(y ~ x)$residuals)


x <- sort(rnorm(100,20,2))
y <- x^0.5
qq <- qqnorm(lm(y ~ x)$residuals, ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(qq$x,qq$y,ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
title(main = list("Normalfraktildiagram 3, 100 observationer\nResidualerne er ikke normalfordelte", cex = 1.25,
                  col = "black", font = 4))
qqline(lm(y ~ x)$residuals)

x <- sort(rnorm(100,20,2))
y <- log(x)
qq <- qqnorm(lm(y ~ x)$residuals, ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "orangered")
grid(col = "white",lty =1)
points(qq$x,qq$y,ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
title(main = list("Normalfraktildiagram 4, 100 observationer\nResidualerne er ikke normalfordelte", cex = 1.25,
                  col = "black", font = 4))
qqline(lm(y ~ x)$residuals)
```
  
    
    

|Forudsætning   |Plot  |Udseende af plot
|:-------------|:-------------|:-------------
|Linearitet af observationer| Linjetilpasningsplot  |Observationerne følger en linjeform       |
|Uafhængighed af residualerne|Residualplot|Der er ikke systematik i residualplottet|
|Varianshomogenitet/homoskedasticitet|Residualplot|Der er ikke trompetform i residualplottet|
|Normalitet af residualerne|Normalfraktildiagram for residualerne|Punkterne ligger pænt om den rette linje|



## Simpel lineær regression Rømø

### Video simpel lineær regression PI og KI
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226071259' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>

### Video simpel lineær regression PI og KI
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/225987363' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>



Hvis vi ønsker at undersøge om lejeprisen på sommerhuse afhænger af kvm. prisen, kan vi benytte lineær regressionsanalyse til at afgøre om lejeprisen kan forudsiges af kvm. prisen. 

For at vi kan beskrive responsvariablen vha. lineær regression, skal der være en lineær sammenhæng, dette kan vi undersøge ved at plotte de 2 variable i et XY punktdiagram. I linket [sommerhuse](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlOWNjUzlQd0s4TVE), findes data som lejepriser og størrelse, for 57 sommerhuse beliggende på Rømø. Vi kan undersøge, om om der er en lineær sammenhæng mellem disse i et punktdiagram. Det er naturligt at antage at lejeprisen afhænger af størrelsen og ikke omvendt, dvs. responsvariablen Y er lejepris og den uafhængige variabel X er størrelsen i kvm. Vi kan forvente en positiv sammenhæng mellem de 2 variable, dvs. jo større sommerhus jo større lejepris. 


```{r sommerhusescatterplot,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg"}
options(scipen=999)
lejepris <- c(3950,	4875,	8775,	5650,	4700,	4900,	4475,	5375,	5650,	5900,	7925,	6850,	4900,	7925,	5650,	4550,	5525,	4225,	5575,	8375,	8475,	7975,	5400,	9100,	5900,	4975,	5600,	5575,	5275,	8375,	7225,	8300,	5650,	12000,	4600,	13275,	5125,	4550,	5175,	5225,	4575,	4700,	4600,	4775,	5400,	4650,	5400,	5125,	4775,	8475,	4575,	7725,	2825,	3825,	4700,	5425,	5225)
kvm <- c(68,	71,	100,	77,	64,	74,	60,	80,	85,	78,	93,	100,	75,	115,	75,	60,	93,	60,	75,	112,	130,	105,	89,	92,	100,	65,	82,	81,	80,	97,	122,	130,	80,	160,	62,	180,	90,	64,	78,	110,	65,	76,	110,	96,	120,	70,	65,	65,	70,	95,	70,	80,	24,	42,	70,	70,	90)
Beliggenhed <- c("Juvre","Toftum","Tvismark","Juvre","Havneby","Kongsmark","Kongsmark","Toftum","Toftum","Havneby","Kongsmark","Toftum","Havneby","Tvismark","Tvismark","Havneby","Juvre","Tvismark","Toftum","Havneby","Kongsmark","Toftum","Tvismark","Tvismark","Toftum","Kongsmark","Tvismark","Kongsmark","Juvre","Havneby","Havneby","Juvre","Tvismark","Kongsmark","Tvismark","Toftum","Toftum","Tvismark","Toftum","Tvismark","Kongsmark","Tvismark","Kongsmark","Kongsmark","Kongsmark","Kongsmark","Toftum","Tvismark","Juvre","Toftum","Havneby","Juvre","Toftum","Havneby","Havneby","Juvre","Kongsmark")

Antalpers <- c(4,6,8,8,6,7,4,8,6,7,6,6,6,6,6,5,6,4,6,6,8,8,6,6,8,6,6,6,6,6,7,7,6,10,5,8,6,6,6,8,6,6,5,5,6,6,5,4,5,8,6,6,2,4,4,6,4)

Opfoert <- c(1965,1984,1994,1975,1980,1980,1980,1980,1980,1985,1994,1965,1980,1984,1987,1984,1978,1978,1975,1993,1995,1990,1984,1981,1975,1986,1985,1986,1986,1970,1974,1995,1989,1989,1986,1990,1985,1972,1985,1960,1977,1979,1755,1979,1987,1974,1986,1978,1985,1992,1972,1994,1986,1960,1989,1988,1967)

Moderniseretsenest <- c(1990,1990,1994,1994,1985,1994,1988,1985,1991,1985,1994,1986,1996,1992,1987,1993,1985,1987,1991,1993,1995,1990,1984,1991,1993,1995,1991,1986,1991,1994,1997,1995,1989,1989,1986,1990,1985,1990,1985,1996,1997,1988,1987,1983,1987,1993,1986,1990,1991,1992,1982,1994,1986,1988,1989,1988,1997)

Antalsoverum <- c(2,3,4,3,3,3,2,3,3,3,3,3,3,3,3,3,3,2,3,3,4,4,4,3,3,3,3,3,3,3,4,4,3,5,3,4,3,3,3,4,3,3,3,2,4,3,3,2,3,3,3,3,1,2,3,3,2)

Strandafstand <- c(700,700,250,1200,700,1400,350,700,500,125,300,100,900,300,1400,800,300,1300,800,700,1200,850,600,50,800,1500,1200,600,300,125,1100,500,1400,1500,1500,400,800,1500,1000,200,400,1500,500,1200,1200,700,800,900,1100,450,1000,900,550,800,800,750,1000)

Indkoebafstand <- c(1500,2300,250,1500,900,800,1800,2300,500,300,1500,1000,1900,2200,1300,800,400,500,1700,1400,1200,2000,400,700,1000,600,400,1800,1200,2000,1400,900,150,1500,700,1400,500,700,1000,600,150,700,300,700,400,1300,800,850,1500,350,1300,700,50,500,1800,600,800)

Vaskemaskine <- c("Nej","Nej","Ja","Ja","Nej","Ja","Nej","Nej","Nej","Nej","Ja","Nej","Ja","Ja","Nej","Nej","Nej","Nej","Ja","Ja","Ja","Ja","Ja","Ja","Ja","Nej","Ja","Nej","Ja","Ja","Ja","Ja","Ja","Ja","Nej","Ja","Nej","Nej","Ja","Ja","Nej","Nej","Ja","Ja","Nej","Nej","Nej","Nej","Ja","Ja","Nej","Ja","Nej","Nej","Nej","Nej","Ja")

Sauna <- c("Nej","Nej","Ja","Nej","Nej","Nej","Nej","Ja","Ja","Nej","Ja","Nej","Ja","Nej","Ja","Nej","Nej","Nej","Ja","Ja","Ja","Ja","Nej","Nej","Ja","Nej","Ja","Ja","Nej","Ja","Ja","Ja","Ja","Ja","Nej","Ja","Nej","Nej","Ja","Nej","Nej","Nej","Nej","Nej","Nej","Nej","Nej","Nej","Nej","Ja","Nej","Ja","Nej","Nej","Nej","Ja","Ja")

Vaskemaskinedummy <- ifelse(Vaskemaskine=="Nej",0,1)
Saunadummy <- ifelse(Sauna=="Nej",0,1)

x <- kvm
y <- lejepris
lmdata <- lm(y~x)
plot(x,y ,pch=19,ylab="",xlab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Sommerhuse Rømø", cex = 1.3,
                  col = "grey50", font = 3),ylab = "Lejepris",xlab = "Kvm")
legend("topleft",
       cex = 0.8,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")

```

Ud fra figuren, er antagelsen om en lineær sammenhæng rimelig.

Når man producerer en simpel lineær regression i Freestat fanen linreg, får man automatisk linjetilpasningsplot, residualplot og normalfraktildiagram. Freestat giver os ligeledes følgende beregninger:

![](img/simlinreg.png)


##### Brugbarhed, signifikanssandsynlighed og R-kvadreret
Modellen er signifikant ud fra p-værdien i cellen **E12** eller **E16**, dvs. størrelsen har klart en effekt på lejeprisen. Vi tester begge steder hypotesen
$$H_0:\beta_{Kvm}=0\ variablen\ kvm\ har \ ingen\ effekt$$$$H_1:\beta_{Kvm}\neq 0\ variablen\ kvm\ har\ effekt$$
Størrelsen har en effekt, da p-værdien er mindre end 0.0001 og dermed er klart under signifikansniveauet på 5%. Vi forkaster nulhypotesen, og konstaterer den forklarende variabel Kvm. har en effekt på responsvariablen Lejepris pr. uge. 

Estimatet for skæringen med y-aksen `r a` er ikke signifikant, p-værdien i celle **E15** 15.61% er jo større end 5% signifikansniveauet, 
$$H_0:\beta_{0}=0\ Lejeprisen\ for\ et\ 0\ kvm\ hus\ er\ 0\ DKK$$$$H_1:\beta_{0}\neq 0\ Lejeprisen\ for\ et\ 0\ kvm\ hus\ er\ forskellig\ fra\ 0\ DKK$$

Skæringen kunne derfor være fx. 0. Normalt interesserer denne test os ikke, vi udelader derfor test af skæringen fra fremtidige analyser. For at sikre den optimale tilpasning af regressionslinjen (og dermed minimere residualerne), bibeholder vi altid skæringen i modellen. 


Ud fra R-kvadreret i cellen **B3** konstateres at 69% af variationen i responsvariablen Lejepris pr uge, kan forklares ud fra variationen i den forklarende variabel Kvm. Herudover skal 31% af variationen i lejepris, forklares ud fra andre faktorer, der ikke er beskrevet i modellen.

##### Model
Vi kan aflæse parameterestimaterne for $\beta_0$ og $\beta_{kvm}$ i cellerne **B15** og **B16**, vi kan herefter opstille modellen:
$$\hat{Y}=\hat{\beta}_0+\hat{\beta}_{Kvm}X$$$$\hat{Y}=`r a`+`r b`X$$

##### Tolkning af koefficienter
Ifølge modellen vil lejeprisen pr. uge for et hus på 0 Kvm. være `r a`. Her er det vigtigt at bemærke at vi ikke har observeret huse i nærheden af denne størrelse, der er derfor tale om ekstrapolation. Det er behæftet med usikkerhed at benytte modellen til forudsigelser udenfor intervallet understøttet af data. Vi bemærkede før at skæringen ikke er signifikant forskellig fra 0.

Ifølge modellen vil lejeprisen pr. uge stige med `r b`, for hver kvadratmeter større sommerhuset er. 

Vi kan beregne hvad et 100 Kvm. sommerhus ifølge modellen koster:

$$`r a`+`r b`*100=`r a+b*100`$$

Bemærk her forudsiges en lejepris for en sommerhusstørrelse, der er understøttet af data, vi har jo observationer for sommerhuse der er mindre og større end 100 Kvm. Når vi forudsiger lejeprisen er der tale om interpolation.

Forudsiger vi en lejepris for et 10 eller 200 Kvm. sommerhus er der tale om ekstrapolation, dette er behæftet med usikkerhed.


#### Prædiktionsinterval

For den simple lineære regression, kan vi forudsige, i hvilket interval responsvariablen lejepris pr. uge vil ligge med 95% sandsynlighed, for en bestemt værdi af den uafhængige variabel Kvm. I celle **D4**, kan vi indtaste en vilkårlig x-værdi og bestemme et prædiktionsinterval også kaldet et forudsigelsesinterval. I Freestat output er indsat 100, hvilket svarer til at lejeprisen pr. uge vil med 95% sikkerhed ligge mellem **D6** 4649 DKK og **D8** 9034 DKK. for et 100 Kvm. sommerhus. Der er tale om et meget bredt interval hvilket skyldes, at vi udtaler os om et enkelt sommerhus.

#### Konfidensinterval

For den simple lineære regression, kan vi forudsige, i hvilket interval den gennemsnitlige lejepris pr. uge vil ligge med 95% sandsynlighed for en bestemt størrelse sommerhus.I celle **E4**, kan vi indtaste en vilkårlig x-værdi og bestemme et konfidensinterval. I Freestat output er indsat 100, hvilket svarer til at den gennemsnitlige lejepris pr. uge vil med 95% sikkerhed ligge mellem **E6** 6514 DKK og **E8** 7169 DKK. for et 100 Kvm. sommerhus. Bemærk konfidensintervallet er smallere end prædiktionsintervallet, da vi udtaler os om gennemsnittet og ikke et enkelt sommerhus.

#### Forudsætninger

Vi undersøger ligeledes om forudsætningerne om varianshomogenitet ved residualplottet, plottet ser fornuftigt ud, de største residualer er for sommerhuse med et areal omkring på 90 til 120 kvm, men vi vil her konstatere at der ikke er problemer med forudsætningen om varianshomogenitet.

Der er ikke nogen tydelig systematik i residualplottet, hvorfor vi konstaterer forudsætningen om uafhængighed af residualerne er opfyldt.

```{r residualplot,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg"}
x <- kvm
yr <- lmdata$residuals
plot(x,yr ,pch=19,ylab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,yr,pch=19)
title(main = list("Residualplot\nSommerhuse Rømø ", cex = 1.3,
                  col = "grey50", font = 3),ylab="Residualer")
```

Der er i normalfraktildiagrammet store afvigelser i enderne, dette er ikke så kritisk som omkring medianen. Forudsætningen om normalitet af residualerne synes ikke opfyldt, hvilket bemærkes da dette har effekt på kvaliteten af modellen.

```{r qq,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg"}
x <- sort(rnorm(100,20,2))
y <- x^0.5
qq <- qqnorm(lmdata$residuals, ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(qq$x,qq$y,ylab="Stikprøve fraktiler", main="",  xlab="teoretiske fraktiler",pch=16)
title(main = list("Normalfraktildiagram\nResidualer Sommerhuse Rømø ", cex = 1.3,
                  col = "grey50", font = 3))
qqline(lmdata$residuals)
```

  
<br>
<details> 
  <summary> Spørgsmål sommerhuse Rømø.</summary>


Vi ser fortsat på datasættet med  [sommerhuse](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlOWNjUzlQd0s4TVE) på Rømø
Kan det seneste moderniseringsår forklare lejeprisen pr. uge?

</details>  
<br>
<details> 
  <summary> Svar sommerhuse Rømø.</summary>

```{r svar1,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg"}
x <- Moderniseretsenest
y <- lejepris
lmdata <- lm(y~x)
plot(x,y ,pch=19,ylab="",xlab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Sommerhuse Rømø", cex = 1.3,
                  col = "grey50", font = 3),ylab = "Lejepris",xlab = "Moderniseringsår seneste")
legend("topleft",
       cex = 0.8,
       title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2),
       paste("R kvadreret",r2),
       paste("P-værdi",pv),
       horiz=TRUE,
       bg="grey96")
```

Vi får en p-værdi på `r pv` altså mindre end signifikansniveauet 5%. Dette betyder vi kan forkaste nulhypotesen i testet:
$$H_0:\beta_{Moderniseret}=0\ Moderniseret\ har\ ingen\ effekt$$$$H_1:\beta_{Moderniseret}\neq 0\ Moderniseret\ har\ effekt$$

Vi kan altså afvise at hældningen $\beta_{Moderniseret}$ er nul, hvilket betyder moderniseringår seneste har signifikant effekt. Hvis moderniseringsåret er et år senere vokser lejeprisen med `r b` DKK., hvilket giver god mening. Her giver skæringen absolut ikke mening, skæringen svarer jo til at den forklarende variabel årstal er lig med nul, hvilket jo ville betyde at ugelejen for et sommerhus moderniseret det år Jesus blev født ville være `r a` DKK. Man får altså over kvart million om ugen, for at bo i det gamle skrammelhus ifølge modellen. Her er naturligvis tale em ekstrem ekstrapolation der ikke giver mening.


Modellens forklaringskraft R-kvadreret er kun `r r2`, hvilket er meget lavt, det betyder der er mange andre faktorer, der forklarer lejeprisen. Vi ved jo fra forrige analyse, at også størrelsen på sommerhuset forklarer en del af lejeprisen. I næste afsnit se hvordan vi med multipel regressionsanalyse kan kombinere flere forklarende variable. 
</details>  
<br>
<details> 
  <summary> Spørgsmål sommerhuse Rømø.</summary>
Kan afstand til strand forklare lejeprisen pr. uge?
</details>  
<br>
<details> 
  <summary> Svar sommerhuse Rømø.</summary>
```{r svar2,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg"}
x <- Strandafstand
y <- lejepris
lmdata <- lm(y~x)
plot(x,y ,pch=19,ylab="",xlab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- round(summary(lm(y ~ x))$coefficients[8],4)
title(main = list("Sommerhuse Rømø", cex = 1.3,
                  col = "grey50", font = 3),ylab = "Lejepris",xlab = "Strandafstand")
legend("topleft", cex = 0.8, title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2), paste("R kvadreret",r2), paste("P-værdi",pv), horiz=TRUE, bg="grey96")
```

Vi får en p-værdi på `r pv` altså større end signifikansniveauet. Dette betyder vi kan ikke forkaste nulhypotesen i testet:
$$H_0:\beta_{Strandafstand}=0\ Strandafstand\ har\ ingen\ effekt$$$$H_1:\beta_{Strandafstand}\neq 0\ Strandafstand\ har\ effekt$$
Vi kan altså ikke afvise at hældningen $\beta_{Strandafstand}$ er nul, hvilket betyder moderniseringår seneste ikke har signifikant effekt. Det betyder vi kan ikke bruge modellen. Bemærk det er muligt  variablen ville være signifikant, hvis den indgår i en multipel lineær regression, den er næsten signifikant i den simple lineære model. Når vi kontrollerer for andre forklarende variable i en multipel model, kan dette medføre den bliver signifikant. Bemærk hældningskoeficienten `r b` i modellen er negativ hvilket vi ville forvente jo større afstand til strand jo lavere lejepris.
</details>  

## Multipel lineær regression

<div class="Keatswide">

<b>Lineære modeller i virkeligheden</b> <img src="img/target.jpg" align="right" width="50%" height="50%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
En vred far kommer i 2012 ind i en Target Butik lidt udenfor Minneapolis og forlanger at tale med bestyreren. Faderen er meget fortørnet over butikken sender datteren kupon-tilbud på graviditets produkter som bleer, graviditetstøj og vugger. 

"Hun går kun i High-school, forsøger i at opmuntre hende til noget!!!"

Bestyreren beklager og ringer et par dage senere for at undskylde igen. Faderen er nu noget brødebetynget i telefonen. Der har været aktiviteter i hjemmet, han ikke var bekendt med, faderen skal være morfar til august.  

Hvordan kunne Target vide datteren var gravid før faderen?  

Target kender sine kunder godt, man registrerer kundernes indkøb med unik ID. Man giver blandt andet graviditetspakker, og kan således identificere, karakteristiske produkter gravide kunder køber. Targets statistiker Andrew Pole fandt bl.a. at i starten af andet trimester køber gravide en stor mængde parfumefri lotion. I de første 20 uger indkøbes store mængder vitamintilskud som zink, magnesium og calcium. Pole kunne nu ved hjælp af liniære modeller meget præcist forudsige om vilkårlige kunder var gravide, og hvor langt de var henne. Target kunne således målrette markedsføringsindsatsen og ved hjælp af kundepleje, sikre sig høj loyalitet, inden de store indkøbsbeslutninger til den lille baby . Target endte i en shitstorm og beklagede. I dag sørger man for ikke at vise kunderne, hvor meget man ved om dem, og sender kupontilbud på både plæneklippere og bleer.
</div>
<br>
<br>

Datasættet der er brugt i videoerne herunder kan hentes [her](https://www.dropbox.com/s/eidlkch361ia57v/Sommerhuse.xlsx?dl=1)  
  
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226060430' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>




### Dummy variable

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226042549' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
  
### Forudsætning multikollinaritet
  
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/268567497' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


### Multipel lineær regression forudsagt værdi

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/226060763' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


<!-- ### Multipel lineær regression Rømø -->

<!-- Vi ser fortsat på datasættet [sommerhuse](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlOWNjUzlQd0s4TVE). -->
<!-- Hvis vi ønsker at undersøge om lejeprisen på sommerhuse kan forklares af flere variable samtidigt kan vi opstillen en multipel lineær regressionsmodel. -->

<br>
<br>


## Spørgsmål lineær regression
<!-- 
Marts 2017 
[2017 3 2. RE Statistik Fin Opgave](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlWjF0WThURjNPbUU)
[2016 8 Eksamen Statistik data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldEVIQXVIUXlvTHM) --> 




<br>
<details> 
  <summary> Spørgsmål korrelation USA afkast.</summary>


I datasættet USA afkast er der månedsafkast i procent for udvalgte aktier fra Dow Jones indekset samt månedsafkastet af selve indekset i procent. [hent datasættet her](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldVZtS2tzV0RqVjQ). 

1. Er afkastet for Kellogs aktien og Microsoft aktien (MFST) korrelerede?
2. Hvilke 2 aktier er mest korrelerede? Vi ser bort fra selve porteføljen?
3. Hvorfor er korrelationerne overvejende positive?
4. Hvorfor er alle aktier mere korrelerede med porteføljen?
5. Hvilken aktie tror du er mest defensiv (dvs. mindst konjunkturfølsom)?
</details>  
<br>
<details> 
  <summary> Svar korrelation USA afkast.</summary>

1. Korrelationskoefficienten mellem Kellogs aktien og Microsoft aktien (MFST) er kun -0.001, får en p-værdi på 98.82 procent, aktierne er altså ikke korrelerede?  
2. JP Morgan JPM og BOA Bank of America er mest korrelerede. Korrelationskoefficienten er 0.6944, ved test for om aktierne er positivt korrelerede får vi en p-værdi på 0.0000. JPM og BOA er altså klart positivt korrelerede. Dette giver god mening da begge selskaber tilhører den finansielle sektor.  
3. Korrelationerne overvejende positive, da alle aktier overordnet påvirkes af konjunkturer samt risikovilligheden.  
4. Alle aktier er mere korrelerede med porteføljen, da porteføljen er opbygget af netop disse aktier.
5. Den mest defensive aktie er Kellogs (fødevarer), denne aktie påvirkes ikke af konjunkturer i samme grad som de øvrige aktier, folk skal have mad uanset hvordan markedstemningen er.  

Vi kan indsætte aktieafkastene i Freestat i corrm arket, vi får følgende output:  
![](img/korropg.png)



</details>  
<br>
<details> 
  <summary>Spørgsmål 2016 8 Statistik Fin opg. 1.</summary>

  
Opgave 1 (30 %)
Nykøbing Bank ønsker opstille en model der kan forklare, hvilken risikogruppe en given kunde vil tilhøre. Banken antager, at variablen risikogruppe er kvantitativ.  
Som udgangspunkt forventer Nykøbing Bank, at følgende variable kan bruges til at forklare kundernes placering i risikogruppe:  
Alder målt som kundens alder i år  
Bruttoindkomst pr. år målt i kr.  
Kundeanciennitet målt som antal år kunden har været kunde i banken Om kunden har haft overtræk (0 = ikke overtræk og 1 = overtræk)  
Om kunden bor i ejerbolig (0 = ikke ejerbolig og 1 = ejerbolig)  
Banken har i maj 2016 ved tilfældig udvælgelse udtrukket en stikprøve på 28 kunder og undersøgt placering i rating-systemet samt de ovenfor nævnte variable.  
Resultatet af denne dataindsamling findes i den udleverede Excel-fil.  
  
Spørgsmål 1.1 (25 %)  
Opstil en model der kan forklare kunders placering i rating-systemet. Alle forklarende variable skal være signifikante på 5 % niveau.  
Fortolk dine resultater og vurdér i hvilken grad modellen er brugbar for Nykøbing Bank.  
Spørgsmål 1.2 (5 %)  
Beregn ved hjælp af din signifikante model fra spørgsmål 1.1 hvilken rating nedenstående kunde vil opnå:  
Alder 34 år  
Bruttoindkomst 580.000 kr. Har været kunde i banken i 3 år Har ikke haft overtræk
Bor i ejerbolig.  
  
Du finder hele opgaven i linket:  
  
[2016 8 Eksamen Statistik Opgave](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMldWRQVGRwZWlkdzQ)  

[2016 8 Eksamen Statistik Data](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlN29HR09IRmJZSE0)  
  

</details>  
<br>
<details> 
  <summary>Svar 2016 8 Statistik Fin opg. 1.</summary>



[Videogennemgang af løsningsforslag](https://youtu.be/_WO_M3653vs)


[2016 8 Statistik Fin opg 1 LØSNING](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlcHplOUpQeU51MTA)

</details>  
<br>
<details> 
  <summary>Spørgsmål Tyske aktier.</summary>
  

```{r, echo=FALSE, warning=FALSE}
list.of.packages <- c("quantmod")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library("quantmod")
```

```{r OMX-data, ,echo=FALSE, include=FALSE,warning=FALSE}
filnavn <- c("Tyskland Afkast pr. md. i procent")
DEcompanies <- c("DBK.DE","BAYN.DE","^GDAXI")
test <- getSymbols(DEcompanies,from = "2000-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE,periodicity = "monthly")
DEkurs <- as.data.frame(cbind(DBK.DE[,6]  , BAYN.DE[,6] ,GDAXI[,6]   ))
afkast <- round(100*((DEkurs[2:nrow(DEkurs),]-DEkurs[1:nrow(DEkurs)-1,])/DEkurs[1:nrow(DEkurs)-1,]),4)
afkast[is.na(afkast)] <- 0 #Replace NA with 0
names(afkast) <- c("Deutsche Bank","Bayer AG","DAX indeks")
WriteXLS("afkast", ExcelFileName = paste0(filnavn,".xls"),col.names = TRUE,row.names = TRUE,AdjWidth = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
# done <- drop_upload(paste0(filnavn,".xls"))

# dblink <- drop_share(paste0(filnavn,".xls"), requested_visibility = "public")

# dblink <- drop_share(paste0(filnavn,".xls"),short_url = FALSE)$url
# dblink <- "https://www.dropbox.com/s/zd0pw8sp3k5q6eo/Tyskland%20Afkast%20pr.%20md.%20i%20procent.xls?dl=0"
# dblink <- paste0(substr(dblink,0,nchar(dblink)-1),1)
afkast[nrow(afkast)-100:nrow(afkast),]

```

<a href="Tyskland Afkast pr. md. i procent.xls" download> Hent datasættet Tyskland Afkast pr. md. i procent her.</a>, i dette datasæt er måneds afkast i procent siden år 2000 for Deutsche Bank, BAYER AG (Tysk kemigigant) samt hele DAX det tyske aktieindeks.

CAPM er en  model til at prisfastsætte finansielle aktiver, vi gennemgår ikke modellen her. Vi kan ved hjælp af simpel lineær regression bestemme hvor volatil/følsom aktien er i forhold til resten af markedet her DAX det tyske aktie indeks. Den risikofri rente er for tiden meget lav her sættes den her til konstant 0, så kan modellen opstilles som:

$$Y_{aktie}=\beta\cdot X_{DAX}+\beta_0$$

Er størrelsen af $\beta_{marked}$ mindre en 1, er aktien ikke særlig konjunkturfølsom, vi siger aktien er defensiv . Er $\beta_{marked}$ større end en, siger vi aktien er cyklisk. 

Hvad bliver beta-værdierne for hhv. Deutsche Bank og BAYER AG i forhold til DAX, når vi betragter måneds afkast siden år 2000?

For at beregne beta-værdierne, skal vi opstille 2 simple lineære regressionsmodeller med DAX indekset som forklarende variabel X.

Hvad bliver beta-værdierne for hhv. Deutsche Bank og BAYER AG i forhold til DAX, når vi betragter de seneste 40 måneders afkast?

</details>  
<br>
<details> 
  <summary> Svar Tyske aktier.</summary>
<br>  

Løsningsforslag ses herunder:

##### Deutsche Bank måneds afkast siden år 2000
```{r svar3,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg",warning=FALSE}
x <- afkast[,3]
y <- afkast[,1]
lmdata <- lm(y~x)
plot(x,y ,pch=19,ylab="",xlab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- summary(lm(y ~ x))$coefficients[8]
title(main = list("Deutsche Bank i forhold til DAX", cex = 1.3,
                  col = "grey50", font = 3),ylab = "Deutsche Bank afkast pct. måned",xlab = "DAX afkast pct. måned")
legend("topleft", cex = 0.8, title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2), paste("R kvadreret",r2), paste("P-værdi",pv), horiz=TRUE, bg="grey96")
```

Vi får en p-værdi på `r pv` altså mindre end signifikansniveauet. Dette betyder vi forkaster nulhypotesen i testet:
$$H_0:\beta=0\ DAX\ har\ ingen \ effekt$$$$H_1:\beta\neq 0\ DAX\ har\ effekt$$
Vi kan altså afvise at hældningen $\beta$ er nul, hvilket betyder DAX afkastet har signifikant effekt. Dette er ikke overraskende, da DAX indeholder Deutsche Bank. Bemærk hældningskoeficienten $\beta=`r b`$ i modellen er positiv hvilket hvilket er forventeligt, jo bedre tyske aktier performer, des bedre performer Deutsche Bank. Er Beta større end 1, hvilket betyder aktien er cyklisk, dette ville vi typisk forvente for en bankaktie. Når DAX stiger med 1 procent point, stiger Deutsche Bank med `r b` procentpoint. Beta-værdien er behæftet med nogen usikkerhed den afhænger af tidshorisonten, perioden og længden vi beregner afkastet på. I eksemplet her er der tale om månedsafkast siden `r rownames(afkast)[1]` til `r rownames(afkast)[nrow(afkast)]`. Konjunkturer har stor betydning for resultatet, vi beregner afkast fra `r rownames(afkast)[1]`, finanskrisen vil således påvirke vores resultat.

##### BAYER AG måneds afkast i procent siden år 2000
```{r svar4,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg",warning=FALSE}
x <- afkast[,3]
y <- afkast[,2]
lmdata <- lm(y~x)
plot(x,y ,pch=19,ylab="",xlab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- summary(lm(y ~ x))$coefficients[8]
title(main = list("Bayer AG i forhold til DAX", cex = 1.3,
                  col = "grey50", font = 3),ylab = "Bayer AG afkast pct. måned",xlab = "DAX afkast pct. måned")
legend("topleft", cex = 0.8, title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2), paste("R kvadreret",r2), paste("P-værdi",pv), horiz=TRUE, bg="grey96")
```

Vi får en p-værdi på `r pv` altså mindre end signifikansniveauet. Dette betyder vi forkaster nulhypotesen i testet:  
$$H_0:\beta=0\ DAX\ har\ ingen \ effekt$$$$H_1:\beta\neq 0\ DAX\ har\ effekt$$  

Vi kan altså afvise at hældningen $\beta$ er nul, hvilket betyder DAX afkastet har signifikant effekt. Vi vil forvente at $\beta$ er mindre end 1 for en kemiaktie, hvilket betyder aktien er defensiv,  Når DAX stiger med 1 procent point, stiger Bayer AG med `r b` procentpoint. Beta-værdien afhænger af tidshorisonten, perioden og længden vi beregner afkastet på. I eksemplet her er der tale om månedsafkast siden `r rownames(afkast)[1]` til `r rownames(afkast)[nrow(afkast)]`.  

##### Deutsche Bank måneds afkast i procent de sidste 40 måneder  
```{r svar5,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg",warning=FALSE}

x <- afkast[(nrow(afkast)-39):nrow(afkast),3]
y <- afkast[(nrow(afkast)-39):nrow(afkast),1]
lmdata <- lm(y~x)
plot(x,y ,pch=19,ylab="",xlab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- summary(lm(y ~ x))$coefficients[8]
title(main = list("Deutsche Bank i forhold til DAX", cex = 1.3,
                  col = "grey50", font = 3),ylab = "Deutsche Bank afkast pct. måned",xlab = "DAX afkast pct. måned")
legend("topleft", cex = 0.8, title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2), paste("R kvadreret",r2), paste("P-værdi",pv), horiz=TRUE, bg="grey96")
```

Vi får en p-værdi på `r pv` altså mindre end signifikansniveauet. Dette betyder vi forkaster nulhypotesen i testet:  
$$H_0:\beta=0\ DAX\ har\ ingen \ effekt$$$$H_1:\beta\neq 0\ DAX\ har\ effekt$$

Vi kan altså afvise at hældningen $\beta$ er nul, hvilket betyder DAX afkastet har signifikant effekt. Dette er ikke overraskende, da DAX indeholder Deutsche Bank, jo bedre/værre tyske aktier performer, des bedre/værre performer Deutsche Bank. Bemærk hældningskoeficienten $\beta=`r b`$ i modellen. Vi vil forvente at en bank aktie er cyklisk eller konjunkturfølsom dvs. $\beta$ er større end 1. Når DAX stiger med 1 procent point, stiger Deutsche Bank med `r b` procentpoint. Beta-værdien er behæftet med nogen usikkerhed den afhænger af tidshorisonten, perioden og længden vi beregner afkastet på. I eksemplet her er der tale om 40 måneders afkast fra `r rownames(afkast)[(nrow(afkast)-39)]` til `r rownames(afkast)[nrow(afkast)]`.  

##### BAYER AG måneds afkast i procent de sidste 40 måneder  
```{r svar6,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg",warning=FALSE}
x <- afkast[(nrow(afkast)-39):nrow(afkast),3]
y <- afkast[(nrow(afkast)-39):nrow(afkast),2]
lmdata <- lm(y~x)
plot(x,y ,pch=19,ylab="",xlab="")
rect(par("usr")[1], par("usr")[3], par("usr")[2], par("usr")[4], col = "grey95")
grid(col = "white",lty =1)
points(x,y,pch=19)
abline(lm(y ~ x))
a <- round(lm(y ~ x)$coef[1],2)
b <- round(lm(y ~ x)$coef[2],2)
r2 <- round(summary(lm(y ~ x))$r.squared,4)
pv <- summary(lm(y ~ x))$coefficients[8]
title(main = list("Bayer AG i forhold til DAX", cex = 1.3,
                  col = "grey50", font = 3),ylab = "Bayer AG afkast pct. måned",xlab = "DAX afkast pct. måned")
legend("topleft", cex = 0.8, title=paste("Regressionslinjen",a,"+",b,"x R kvadreret",r2), paste("R kvadreret",r2), paste("P-værdi",pv), horiz=TRUE, bg="grey96")
```

Vi får en p-værdi på `r pv` altså mindre end signifikansniveauet. Dette betyder vi forkaster nulhypotesen i testet:  
$$H_0:\beta=0\ DAX\ har\ ingen \ effekt$$$$H_1:\beta\neq 0\ DAX\ har\ effekt$$  

Vi kan altså afvise at hældningen $\beta$ er nul, hvilket betyder DAX afkastet har signifikant effekt. Vi vil forvente at en kemi aktie er defensiv dvs. $\beta$ er mindre end 1. Når DAX stiger med 1 procent point, stiger Bayer AG med `r b` procentpoint. Beta-værdien afhænger af tidshorisonten, perioden og længden vi beregner afkastet på. I eksemplet her er der tale om 40 måneders afkast fra `r rownames(afkast)[(nrow(afkast)-39)]` til `r rownames(afkast)[nrow(afkast)]`.  
</details>  

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=65" target="_blank">Selvtest korrelation med videoløsning</a></h2>

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=66" target="_blank">Selvtest simpel lineær regression med videoløsning</a></h2>

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=54" target="_blank">Selvtest bank lineær regression med videoløsning</a></h2>


# Binomialfordelingen





<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812,39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->






Et Bernoulli forsøg er et forsøg med kun 2 mulige udfald succes og fiasko. Det kan fx. være at få krone i et kast (forsøget) med en krone. Vi siger at sandsynligheden for succes er p (altså 0.5 hvis mønten er fair), sandsynligheden for fiasko kan beregnes som 1-p=1-0.5=0.5.

<div class="Keats">
<img src="img/cointoss.jpg" align="right" width="40%" height="40%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/> En statistik studerende havde voldsomme tømmermænd og skulle op til afsluttende eksamen. Dette var en sand/falsk test, så han besluttede at slå plat og krone om spørgsmålene. Den tilsynsførende ved eksamen, så den studerende slå plat og krone skrive et svar, slå plat og krone og skrive et svar konstant i 2 timer. Da eksamen var ved at være forbi, var kun den studerende med mønten tilbage.

Den tilsynsførende spørger ham nysgerrigt. "Nu har du siddet i 2 timer og slået plat og krone for svarene uden at åbne bogen, hvordan kan det dog tage dig så lang tid?"

Den studerende svarer febrisk, mens han stadig slår plat og krone "Shhh! jeg er ved at tjekke svarene"

</div>
Binomialfordelingen er en diskret (heltallig) fordeling, der beskriver sandsynligheden for x succeser, ved n identiske Bernoulli forsøg. Sandsynlighedsfordelingen for krone ved ti kast, med en fair mønt, er således 10 uafhængige forsøg med samme sandsynlighedsparameter p = 0.5 antalsparameteren n er 10, hvilket er det samlede antal enkelt forsøg.
For at en stokastisk variabel X er binomialfordelt, skal følgende 3 forudsætninger være opfyldt:

1. Den stokastiske variabel betegner antallet af succeser i n forsøg, som hver især kan antage to værdier kaldet succes og fiasko.

2. De n forsøg er uafhængige, har man fx. 4 succeser er successandsynligheden ikke ændret i næste forsøg.

3. Sandsynlighedsparameteren er konstant p for samtlige forsøg, dvs. successandsynligheden ændrer sig ikke.

Vi siger den stokastiske variabel er binomialfordelt, med antalsparameter n og sandsynlighedsparameter p, notationen for dette er:
$$X\sim b(n,p)$$

Vi kan for $X\sim b(n,p)$ beregne punktsandsynligheder ved formlen:

$$P(X=x)=\binom{n}{x} p^{x} (1-p)^{n-x}$$

Hvor $\binom{n}{x}$ er binomialkoefficienten denne kan udregnes som:

$$\binom{n}{x}=\frac{n!}{x!(n-x)!}=\frac{n \cdot (n-1)\cdot...\cdot 1 }{x\cdot...\cdot1((n-x)\cdot...\cdot1}$$

Punktsandsynligheden for i 4 kast at få netop fx. 1 krone. kan udregnes som antal mulige udfald hvor man netop har 1 krone gange sandsynligheden for netop at få en krone.

De mulige udfald hvor antallet af succeser dvs. krone er en, bliver:

1. {krone, plat, plat, plat}
2. {plat, krone, plat, plat}
3. {plat, plat, krone, plat}
4. {plat, plat, plat, krone}

Vi kan netop udregne dette antal mulige udfald ved binomialkoefficienten som:
$$\binom{4}{1}=\frac{4\cdot3\cdot2\cdot1}{1\cdot3\cdot2\cdot1}=\frac{24}{6}=4$$

Sandsynligheden for kun et udfald med en krone udregnes til:
$$p^{x} (1-p)^{n-x}=0.5^{1} (1-0.5)^{4-1}=0.5\cdot0.125=0.0625$$

Vi får beregner altså punktsandsynligheden til:

$$P(X=1)=4*0.0625=0.25$$

Nedenfor er sandsynlighedsfordelingen for binomialfordelingen med antalsparameter 4 og sandsynlighedsparameter 0.5 illustreret, bemærk punktsandsynligheden for 1 krone er netop 0.25:

```{r Binomialfordelingen450,echo=FALSE, fig.width=9, fig.height=3, dev='svg'}
pr <- 0.5
n <- 4
x7 <- 0:n
y7 <- dbinom(x7,n,pr)
b7 <- data.frame(x7,y7)
    p <- ggplot(b7, aes(x=x7, y= y7, label=y7))+
     geom_bar(stat="identity", width=0.5)+
      coord_cartesian(ylim = c(0, .4))+
      xlab("Antal krone ved 4 kast")+
  ylab("Sandsynlighed")+
      labs(title = "Binomialfordelingen n=4, p=0.1")+
    geom_text(aes(label=y7),hjust=0.5, vjust=-.5,size=3)
    plot(p)
```

Her ses binomialfordelingen med antalsparamerter n=8 og sandsynlighedsparameter p=0.5.

```{r Binomialfordelingen850,echo=FALSE, fig.width=9, fig.height=3, dev='svg'}
pr <- 0.5
n <- 8
x7 <- 0:n
y7 <- dbinom(x7,n,pr)
b7 <- data.frame(x7,y7)
    p <- ggplot(b7, aes(x=x7, y= y7, label=y7))+
     geom_bar(stat="identity", width=0.5)+
      coord_cartesian(ylim = c(0, .3))+
      xlab("Antal krone ved 8 kast")+
  ylab("Sandsynlighed")+
      labs(title = "Binomialfordelingen n=8, p=0.5")+
    geom_text(aes(label=round(y7,4)),hjust=0.5, vjust=-.5,size=3)
    print(p)
```

Her ses binomialfordelingen med antalsparamerter n=8 og sandsynlighedsparameter p=0.9. Bemærk fordelingen bliver venstreskæv hvis p er større end 0.5 hvor den er symmetrisk.

```{r Binomialfordelingen890,echo=FALSE, fig.width=9, fig.height=3, dev='svg'}
pr <- 0.9
n <- 8
x7 <- 0:n
y7 <- dbinom(x7,n,pr)
b7 <- data.frame(x7,y7)
    p <- ggplot(b7, aes(x=x7, y= y7, label=y7))+
     geom_bar(stat="identity", width=0.5)+
      coord_cartesian(ylim = c(0, .5))+
      xlab("Antal krone ved 8 kast")+
  ylab("Sandsynlighed")+
      labs(title = "Binomialfordelingen n=8, p=0.9")+
    geom_text(aes(label=round(y7,4)),hjust=0.5, vjust=-.5,size=3)
    print(p)
```

Her ses binomialfordelingen med antalsparamerter n=8 og sandsynlighedsparameter p=0.1 denne er højreskæv.

```{r Binomialfordelingen810,echo=FALSE, fig.width=9, fig.height=3, dev='svg'}
pr <- 0.1
n <- 8
x7 <- 0:n
y7 <- dbinom(x7,n,pr)
b7 <- data.frame(x7,y7)
    p <- ggplot(b7, aes(x=x7, y= y7, label=y7))+
     geom_bar(stat="identity", width=0.5)+
      coord_cartesian(ylim = c(0, .5))+
      xlab("Antal krone ved 8 kast")+
  ylab("Sandsynlighed")+
      labs(title = "Binomialfordelingen n=8, p=0.1")+
    geom_text(aes(label=round(y7,digits = 4)),hjust=0.5, vjust=-.5,size=3)
    print(p)
```

Figuren nedenfor vises 3 binomialfordelinger, samtlige med sandsynlighedsparameter p=0.5 og antalsparameter n hhv. 10, 20 og 50.



```{r Binom3stk,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
X1<-0:50
X2<-0:50
X3<-0:50
Y1<-dbinom(X1,10,0.5)
Y2<-dbinom(X1,20,0.5)
Y3<-dbinom(X1,50,0.5)
X <- c(X1,X2,X3)
Y <- c(Y1,Y2,Y3)
Forsøg <- c(rep("10 forsøg",51),rep("20 forsøg",51),rep("50 forsøg",51))
dat <- data.frame(X,Y,Forsøg)
myplot <- ggplot(data=dat, aes(x=dat$X,y=dat$Y,fill=Forsøg)) +
  labs(title = "3 Binomialfordelinger n=10,20,30 p=0.5")+
  geom_bar(stat="identity",position="dodge", width=0.9)+
  scale_fill_manual(values=c("black", "gray70", "gray40"))+
xlab("Antal successer ved hhv. 10, 20 og 30 forsøg")+
  ylab("Sandsynlighed")
plot(myplot)
```


Figuren nedenfor viser 3 binomialfordelinger med sandsynlighedsparametre p hhv. 0.1, 0.5 og 0.9 samtlige har antalsparameter n 50. Bemærk at sandsynlighedsparametrene påvirker skævheden. En sandsynlighedsparameter, mindre end 0.5 giver højreskævhed, netop  0.5 giver symmetri og større end 0.5 venstreskævhed.



```{r Binom3ford2,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
X1<-0:50
Y1<-dbinom(X1,50,0.1)
Y2<-dbinom(X1,50,0.5)
Y3<-dbinom(X1,50,0.9)
X <- c(X1,X1,X1)
Y <- c(Y1,Y2,Y3)
Sandsynlighed <- c(rep("10%",51),rep("50%",51),rep("90%",51))
dat <- data.frame(X,Y,Sandsynlighed)
myplot <- ggplot(data=dat, aes(X,Y,fill=Sandsynlighed)) +
  geom_bar(stat="identity",position="dodge", width=0.9)+
  scale_fill_manual(values=c("black", "gray70", "gray40"))+
  labs(title = "3 Binomialfordelinger n=50 p=0.1,0.5,0.9")+
xlab("Antal successer ved 50 eksperimenter")+
  ylab("Sandsynlighed")
plot(myplot)
```


Vi kan for for en binomialfordelt stokastisk variabel $X\sim bin(n,p)$ beregne:

Middelværdien
$$E(X)=n\cdot p$$
Standardafvigelsen til
$$SD(X)=\sqrt[]{n\cdot p \cdot (1-p)}$$


## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=61" target="_blank">Selvtest binomialfordelingen med videoløsning</a></h2>

# Den hypergeometriske fordeling


<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->



<img src="img/mm.jpg" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
Den hypergeometriske fordeling beskriver sandsynligheden for antal successer k i en stikprøve af størrelse n, fra en endelig population af størrelse N. Stikprøven udtages i modsætning til binomialfordelingen, uden tilbagelægning, det betyder sandsynligheden for succes ikke er konstant som for binomialfordelingen.

Vi har følgende størrelser når vi ser på den hypergeometiske fordeling:

|Den hypergeometriske fordeling  | Population |   Stikprøve | Ikke trukket ud |
|:------------------------ |:--------------|:--------------|:--------------|
|Succes     |m|k|m-k|
|Fiasko     |N-m|n-k|N + k - n - m|
|Ialt     |N|n|N-n|

Antag en endelig population, består af en pose med gule og røde M&M's N=100, der udtages en stikprøve på n=20 M&M. Succes er gule M&M's, der er m=30 gule M&M's i populationen altså posen. Vi siger den stokastiske variabel X, er fordelt efter den hypergeometriske fordeling med parametrene N=100, m=30, n=20 notationen er:
$$X \sim h(N=100,m=30,n=20)$$
Man kan da beregne sandsynligheden for netop k gule M&M's i stikprøven vha. den hypergeometriske fordeling. Vi kan for at få et overblik skrive værdierne ind i skemaet.

|Den hypergeometriske fordeling  | Population |   Stikprøve | Ikke trukket ud |
|:------------------------ |:--------------|:--------------|:--------------|
|Succes     |m=30|k|m-k=30-k|
|Fiasko     |N-m=100-30=70|n-k=20-k|N + k - n - m=100+k-20-30|
|Ialt     |N=100|n=20|N-n=100-20|

Hver gang vi tager en M&M, ændres sandsynligheden for at næste M&M er gul. Er den trukne M&M rød stiger sandsynligheden for gul i næste trækning, er den gul falder sandsynligheden for gul i næste trækning. Vi lægger ikke de trukne M&M's tilbage i posen, derfor siger vi "uden tilbagelægning".

Vi kan udregne punktsandsynligheden for k succeser ud fra den hypergeometriske fordeling, den generelle formel er:

$$P(X=k)=\frac{\binom{m}{k}\cdot \binom{N-m}{n-k}}{\binom{N}{n}}$$

Hvor binomialkoefficienten udregnes som:
$$\binom{m}{k}=\frac{m!}{k!\cdot (m-k)!}=\frac{m \cdot (m-1)\cdot...\cdot 1}{k \cdot (k-1)\cdot...\cdot 1\cdot (m-k) \cdot (m-k-1)\cdot(m-k-2)\cdot...\cdot 1}$$
Hvis vi i vort eksempel ønsker at beregne sandsynligheden for at trække k=4 gule M&M's får vi:
$$ P(X=4)=\frac{\binom{30}{4}\cdot \binom{100-30}{20-4}}{\binom{100}{4}}=`r round((choose(30,4) * choose(70,16))/choose(100,20),4)`$$

Hvor fx. binomialkoefficienten

$$\binom{30}{4}=\frac{30!}{4!\cdot (30-4)!}=\frac{30 \cdot 29\cdot...\cdot 1}{4 \cdot 3\cdot 2\cdot 1\cdot 26 \cdot 25\cdot24\cdot...\cdot 1}=27405$$

Sandsynlighedsfordelingen bliver som nedenfor:

```{r hyp1,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
x7 <- 0:20
y7 <- round(dhyper(0:20, 30, 70, 20),4)
b7 <- data.frame(x7,y7)
    p <- ggplot(b7, aes(x=x7, y= y7, label=y7))+
     geom_bar(stat="identity", width=0.5)+
      coord_cartesian(ylim = c(0, .225))+
      xlab("Antal gule M&M's i stikprøven")+
  ylab("Sandsynlighed")+
      labs(title = "Den hypergeometriske fordeling\nN=100, n=20, m=30")+
    geom_text(aes(label=y7),hjust=0.5, vjust=-.5,size=3)
    plot(p)
```
<img src="img/gul.jpg" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
Middelværdien for den hypergeometriske fordeling bestemmes udfra formlen:

$$\mu=E(X)=\frac{n\cdot m}{N}$$

I eksemplet med M&M's bliver middelværdien således:

$$\mu=E(X)=\frac{n\cdot m}{N}=\frac{20\cdot 30}{100}=6$$

Variansen udregnes udfra formlen:

$$\mu=E(X)=\frac{n\cdot m\cdot (N-m)}{N^2}\cdot \frac{N-n}{N-1}$$

I eksemplet med M&M's bliver variansen:

$$\\sigma^2=Var(X)=\frac{n\cdot m\cdot (N-m)}{N^2}\cdot \frac{N-n}{N-1}=\frac{20\cdot 30\cdot (100-30)}{100^2}\cdot \frac{100-20}{100-1}=`r ((20*30)*(100-30))/100^2* (100-20)/(100-1)`$$

Standardafvigelsen er jo blot kvadratroden af variansen:

$$\\sigma=sd(X)=`r (((20*30)*(100-30))/100^2* (100-20)/(100-1))^0.5`$$

Nedenfor ses output fra Freestat.

![](img/hypergeo.png)


<br>
<details>
  <summary>Spørgsmål cigaretter og våben</summary>
<img src="img/guncigarettes.jpg" align="right" width="20%" height="20%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
En bank giver mulighed for at investere i 100 investeringsforeninger, ud af disse investerer 10 bla. i våben- og tobaksindustrien. Banken kører forskellige afkast simuleringer på vilkårlige porteføljer, der netop indeholder 15 investeringsforeninger.

1. Hvad er sandsynligheden for en tilfældigt udvalgt portefølje ikke har investeringer i våben og tobaksindustrien?
2. Hvad er sandsynligheden for at porteføljen højst indeholder 2 investeringsforeninger, der har investeringer i våben og tobaksindustrien?
3. Hvad er sandsynligheden for at porteføljen mindst indeholder 2 investeringsforeninger, der har investeringer i våben og tobaksindustrien?
4. Hvad er sandsynligheden for at porteføljen indeholder præcis 15 investeringsforeninger, der har investeringer i våben og tobaksindustrien?

</details>
<br>
<details>
  <summary>Svar cigaretter og våben</summary>


```{r hyp2,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
x7 <- 0:15
y7 <- round(dhyper(0:15, 10, 90, 15),4)
b7 <- data.frame(x7,y7)
    p <- ggplot(b7, aes(x=x7, y= y7, label=y7))+
     geom_bar(stat="identity", width=0.5)+
      coord_cartesian(ylim = c(0, max(y7)*1.05))+
      xlab("Antal porteføljer uden tobaks- og våbenproducenter")+
  ylab("Sandsynlighed")+
      labs(title = "Den hypergeometriske fordeling\nN=100, n=15, m=10")+
    geom_text(aes(label=y7),hjust=0.5, vjust=-.5,size=3)
    plot(p)
```

|Den hypergeometriske fordeling  | Population |   Stikprøve | Ikke trukket ud |
|:------------------------ |:--------------|:--------------|:--------------|
|Succes     |m=10|k|m-k=30-k|
|Fiasko     |N-m=100-10=90|n-k=20-k|N + k - n - m=100+k-15-10|
|Ialt     |N=100|n=15|N-n=100-15=85|

1. $$ P(X=0)=\frac{\binom{10}{0}\cdot \binom{100-10}{15-0}}{\binom{100}{15}}=`r round((choose(10,0) * choose(90,15))/choose(100,15),4)`$$
Det betyder sandsynligheden for at porteføljen indeholder netop 0 investeringsforeninger er 18.08%.
Output fra Freestat bliver:
![rmd](img/hypergeo2.png)

2. $$ P(X\leq 2)=P(X=0)+P(X=1)+P(X=2)=0.1808+0.3568+0.2919=0.8295$$
Det betyder sandsynligheden for at porteføljen indeholder højst 2 investeringsforeninger er 82.95%.
Output fra Freestat bliver:
![rmd](img/hypergeo3.png)

3. $$ P(X\geq 2)=1-P(X<2)=1-P(X=0)+P(X=1)=1-0.1808-0.3568=0.4624$$
Det betyder sandsynligheden for at porteføljen indeholder netop 0 investeringsforeninger er 46.24%.
Output fra Freestat bliver:
![rmd](img/hypergeo3.png)

4. $$ P(X=0)=0$$
Det kan ikke lade sig gøre at porteføljen indeholder 15 investeringsforeninger, der har investeringer i våben og tobaksindustrien. Der er kun 10 af sådanne investeringsforeninger, derfor bliver sandsynligheden for hændelsen 0%.
Output fra Freestat bliver:
![rmd](img/hypergeo4.png)


</details>



## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=63" target="_blank">Selvtest den hypergeometriske fordeling med videoløsninger</a></h2>

# Poisson fordelingen


<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->


Poisson fordelingen er en diskret sandsynlighedsfordeling der angiver sandsynligheden for at et antal begivenheder, indtræffer indenfor i tid eller rum. Fx.
<img src="img/car.png" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
1. Antal cykelpunkteringer indenfor 1000 km.
2. Antal mål i EM-finalen.
3. Antal dødsfald i trafikken på et år.
4. Antal kunder i en bankfilial i timen.
5. Antal skadesanmeldelser i løbet af ugen.

Poisson fordelingen har kun en parameter middelværdien $\lambda$ (det græske bogstav lambda), det forventede antal hændelser pr. enhed. Notationen for en stokastisk variabel der er poissonfordelt er:

$$X\sim Pois(\lambda)$$

Når vi kender $\lambda$ kan vi beregne punktsandsynligheden for at den stokastiske variabel X er netop x som:

$$P(X=x)=\frac{e^{-\lambda}\cdot \lambda^x}{x!}$$
<img src="img/Puncture.jpg" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

Uafhængighed mellem antal hændelser der intræffer i 2 på hinanden følgende intervaller er en forudsætning. Har der fx. være 1 punktering på de første 1000 km. påvirker dette ikke det forventede antal punkteringer på de næste 1000 km. Vi kalder også $\lambda$ for intensiteten, intensiteten er konstant for intervaller af samme længde og proportional. Er $\lambda$=3 for hver 1000 kilometer, bliver $\lambda$=6 for 2000 kilometer.

Hvis det forventede antal punkteringer $\lambda=3$, kan vi beregne sandsynligheden for fx. 4 punkteringer som:

$$P(X=4)=\frac{e^{-\lambda}\cdot \lambda^x}{x!}=\frac{e^{-3}\cdot 3^4}{4!}=\frac{4.032753}{4\cdot 3\cdot 2\cdot 1}=0.1680$$

Sandsynligheden for netop 4 punkteringer er derfor 17%.
Ønsker vi at bestemme sandsynligheden for højst 4 punkteringer dvs. $P(X\leq 4)$.
$$P(X\leq 4)=P(X=0)+P(X=1)+P(X=2)+P(X=3)+P(X=4)=$$$$0.0498+0.1494+0.2240+0.2240+0.1680=0.8152$$

Sandsynligheden for flere end 4 punkteringer dvs. $P(X>4)$ kan udregnes som:

$$P(X>4)=1-P(X\leq 4)=1-0.8152=0.1848$$

Variansen for poissonfordelingen er $\lambda$, heraf følger at standardafvigelsen som kvadratroden af $\lambda$ dvs. $\lambda^{0.5}$

Vi får følgende sandsynlighedfordeling.

```{r hyp3,echo=FALSE, fig.width=9, fig.height=5, dev='svg'}
x7 <- 0:15
y7 <- round(dpois(x7,3),2)
b7 <- data.frame(x7,y7)
    p <- ggplot(b7, aes(x=x7, y= y7, label=y7))+
     geom_bar(stat="identity", width=0.5)+
      coord_cartesian(ylim = c(0, .225))+
      xlab("Antal punkteringer")+
  ylab("Sandsynlighed")+
      labs(title = "Poisson fordelingen\nlambda 3")+
    geom_text(aes(label=y7),hjust=0.5, vjust=-.5,size=3)
    plot(p)
```

Nedenfor ses output fra Freestat:
![](img/poisson.png)




<br>
<details>
  <summary>Spørgsmål bankkunder</summary>

<img src="img/bankkunder.jpg" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px;margin:6px;"/>
Antag at antal kunder der ankommer i en bank i minuttet er poissonfordelt med intensitet 2.
1. Hvad er sandsynligheden for der netop ankommer 1 kunde i minuttet?
2. Hvad er sandsynligheden for der netop ankommer 10 kunder på 10 minutter?
3. Hvad er sandsynligheden for der mindst ankommer 1 kunde i minuttet?

</details>
<br>
<details>
  <summary>Svar bankkunder</summary>

1. Vi skal finde sandsynligheden for der netop ankommer 1 kunde i minuttet. Her er tale om en poisson fordeling med parameter $\lambda$=2, vi ønsker at bestemme sandsynligheden for at x=1.
$$P(X=1)=\frac{e^{-\lambda}\cdot \lambda^x}{x!}=\frac{e^{-2}\cdot 2^1}{1!}=0.2707$$
![](img/poisson2.png)

2. Vi skal finde sandsynligheden for der netop ankommer 10 kunder på 10 minutter. Her er tale om en poisson fordeling med parameter $\lambda$=20. Vi skal jo betragte 10 minutters intervallet, derfor ganger vi intensiteten for 1 minut $\lambda$=2 med 10. Vi ønsker at bestemme sandsynligheden for at x=10.
$$P(X=10)=\frac{e^{-\lambda}\cdot \lambda^x}{x!}=\frac{e^{-20}\cdot 20^{10}}{10!}=0.0058$$
![](img/poisson3.png)

3. Vi kan bestemme sandsynligheden for der mindst ankommer 1 kunde i minuttet ved:
$$P(X\geq 1)=1-P(X=0)=1-0.1353=0.8647$$
![](img/poisson2.png)



</details>


## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=62" target="_blank">Selvtest poissonfordelingen med videoløsning</a></h2>



# Stikprøveteori



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->



<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/259842430' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>


Der findes forskellige metoder, til at udtage en stikprøve fra en population. Vort ønske er at stikprøven er repæsentativ for den population, vi ønsker at udtale os om. At stikprøven er repæsentativ, betyder at stikprøven afspejler populationen korrekt, det er svært at sikre repræsentativitet. Man kunne forestille sig en stikprøve var repræsentativ mht. køn og alder i populationen, men ikke mht. det andre parametre som fx indkomst og geografi.

<img src="img/samplingmethods.png" align="left" width="100%" height="100%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>


Nogle af de vigtigste stikprøve udvælgelsesmetoder er illustreret i figuren og nævnt herunder.


## Bekvemmelighedsudvælgelse
Bekvemmelighedsudvælgelse er som navnet antyder, den letteste stikprøveudvælgelsesmetode, men det kan også være en meget upræcis metode. Hvis man fx. udvælger forbipasserende på strøget, er stikprøven nem at indsamle, men ikke nødvendigvis repræsentativ.
<img src="img/sampling.jpg" align="right" width="59%" height="59%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
1. Er populationen fx. danskere, får man her en overrepræsentation af københavnere.

2. Var populationen en landmands produktion af agurker, kunne bekvemmelighedsudvælgelse fx. betyde at landmanden udtager en stikprøve fra de nærmeste planter. Stikprøven vil måske ikke være repræsentativ for populationen mht. vanding, gødning, sol og varme etc.

3. Hvis Elektronikfabrikanten Foxconn, der producerer forbrugerelektronik, kvalitetssikrer på baggrund af bekvemmelighedsudvælgelse, kunne man forestille sig man udtager stikprøven fra nærmeste samlebånd. Stikprøven vil måske ikke være repræsentativ for populationen mht. til kvaliteten, der er måske forskellig kvalitet i forskellige fabrikshaller, forskellige lokationer, under forskellige produktionsledere, produktionsanlæg, medarbejdere etc.

## Snowballing
Snowball udvælgelse betyder at deltagerne i ens undersøgelse selv rekrutterer yderligere deltagere. Ofte vil der være gode chancer for, at folk, der er relevante for undersøgelsen, kender andre, der også er. Disse nye deltagere kender måske flere mennesker, der kan deltage osv. Denne udvælgelses metode er nem men ikke nødvendigvis repræsentativ for populationen.

1. Ønsker man at undersøge unges kendskab til forsikring, kunne man få de oprindeligt udvalgte deltagere til at videresende spørgeskemaet til andre unge de kender.

## Simpel tilfældig udvælgelse
Ved simpel tilfældig udvælgelse har hver respondent eller element i populationen (fx. unge, agurker, danskere, elektronisk komponenter) samme sandsynlighed for at blive udtrukket. Man sørger altså for, at alle i populationen, har samme chance for at komme med i stikprøven, dette er svært at administrere uden registre eller samme tilgang til alle respondenter eller elermenter i stikprøven. Man kan også være begrænset fx. fysiske, administrative eller geografiske begrænsninger. Simpel tilfældig udvælgelse er samme princip som udtrækningen af lottotallene, hvor alle tal er lige sandsynlige.

1. Er populationen på 1 mio., skal sandsynligheden for udtrækning således være $\frac{1}{1.000.000}=0.000001$ for hvert element i populationen.

## Systematisk udvælgelse

Man kan udvælge respondenter systematisk, hvis man har en ordning af populationen, ordningen kan fx. være ud fra løbenummer, tid, alfabet etc.

1. Ønsker man at belyse deltagerne i en konferences holdning, kunne man interviewe hver 10. deltager når du forlader konferencen.

## Stratificeret udvælgelse

At stratificere betyder man opdeler populationen i ens grupper eller segmenter, dette kaldes stata. Der er måske grupper i populationen, med samme karakteristika, det kan være specielle holdninger, etnicitet, indkomst, socialklasse, køn eller andre kriterier, der kan have betydning for folks holdning. Stratificeret udvælgelse vil ofte give mere præcise resultater, end simpel tilfældig udvælgelse.

1. Skal man undersøge befolkningens holdning til udflytningen af statslige arbejdspladser, vil der måske være forskel på holdningen alt efter om man bor i by eller på land, er mand eller kvinde. Befolkningenen kunne inddeles efter køn, by- og landbefolkning, så man får 4 strata med nogenlunde ens holdninger.

2. Det kan være landmanden, der dyrker agurker, opdeler populationen i 3 strata i forhold til kvaliteten af drivhusene.

### Proportional allokering
Proportional allokering, betyder man sikrer hvert strata har en andel i stikprøven, der svarer til andelen i populationen.

1. Udgør  andelen af kvinder i landbefolkningen 20% af befolkningen, skal stikprøveandelen således være 20%. Har man adspurgt 1000 respondenter, skal 200 af disse således være kvinder, der bor på landet.

2. Har Landmanden 30% af sin produktion i kvalitet 1 drivhuse, skal 30% af stikprøvens agurker stamme fra disse drivhuse.

### Optimal allokering

Optimal allokering betyder man udtager flere respondenter, fra strata med højere varians, for at korrigere for den højere usikkerhed i disse strata. Optimal allokering, er en stikprøve udvælgelsesmetode, der kan give mere præcise resultater end proportional allokering. En forudsætning er at man kender populationsvariansen, det gør man jo normalt ikke, derfor bliver metoden mindre præcis, hvis vi skal estimere variansen ud fra variansen i stikprøvens strata.

Man kunne forestille sig at kvinder i landbefolkningen, var et mere homogent stratum end mænd i landbefolkningen, variansen blandt kvinder i landbefolkningen er altså mindre end for mænd. Benytter optimal allokering, indsamles så en forholdsmæssigt større stikprøve blandt mænd på landet, end ved den proportionale allokering.

<div class="Keats">
<img src="img/readersdigest.jpg" align="right" width="40%" height="40%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
I 1936 gennemførte Readers Digest en meget stor og dyr undersøgelse, man spurgte 2,4 mio. vælgere for at finde ud af, hvem de ville stemme på ved præsidentvalget. Stikprøven viste at 57% stemme på Landon og 43% på Roosevelt. Resultatet af valget blev at Roosevelt vandt med 62% mod 38% til Landon. Problemet ved det voldsomme fejlskøn lå primært i stikprøveindsamlingen. Vælgerne var udvalgt ud fra telefonlister, abonnementer og medlemslister til klubber. I 1936 var telefon en luksus, som fx. de 9 mio arbejdsløse, ikke havde råd til. Man kalder denne type problem ved udvælgelsen, hvor grupper fra populationen ikke repræsenteres korrekt, for coverage error, dette resulterer i stikprøve bias eller udvælgelses bias. George Gallup forudsagde korrekt Roosevelt ville vinde, udfra en mindre stikprøve med kun 50.000 respondenter.
</div>

### Poststratifikation

Poststratifikation eller efter stratificering, betyder man efter man har indsamlet stikprøven, vægter strata med forskellige vægte, dette giver ikke så gode resultater som hvis man har planlagt stratificeringen på forhånd.


## Klyngeudvælgelse eller cluster udvælgelse
Klyngeudvælgelse betyder man opdeler populationen i klynger. Klynger fx. forskellige afdelinger i en virksomhed eller geografiske områder i befolkning fx boligområder. Så udtager man til stikprøven samtlige respondenter fra et antal tilfældigt udvalgte klynger.

1. Man kunne forestille sig at man opdelte landet efter veje, og herefter spurgte samtlige respondenter på tilfældigt udvalgte veje.

2. Det kunne være at landmanden undersøgte samtlige agurker på udvalgte vækstborde, klyngerne ville så være vækstbordene.

3. Foxconn kunne opdele populationen i klynger efter hvilket samlebånd, de blev produceret på, og så tilfældigt udvælge et antal klynger, hvor man undersøger samtlige elektronikprodukter.


<br>
<details>
  <summary>Spørgsmål nonfood dagligvarer</summary>

En virksomhed, der producerer nonfood dagligvarer, har salgskanaler i hele verden. Man omsætter følgende mængder af luftfriskere i distributionsnettet. Forretningerne kan indeles i kategori lille, mellem og stor efter omsætning.
Man kender populationens størrelser for de enkelte strata, samt følgende oplysninger nedenfor:

|Omsætning   |Populations størrelse  |Stikprøvestørrelse |Omsætning (1000 kr) i gns.|Standard afvigelse
|:-------------      |:------------   |:------------   |:---------     |:---------
Lille                     | 10.000                  |250    |25   |5
Mellem                  | 15.000               |300   |32                       |6
Stor                    |30.000              |450            |39          |7
Total                   |55.000             |1000           |       |

1. Beregn det gennemsnitlige salg af luftfriskere pr. forretning samt et 95% konfidensinterval
for det gennemsnitlige salg af luftfriskere pr forretning.
2. Hvordan burde stikprøven have være udtaget for hvis man benytter proportional allokering?
3. Hvordan burde stikprøven have være udtaget for hvis man benytter optimal allokering, hvis vi forudsætter stikprøve standardafvigelsen svarer til populationsstandardafvigelsen?
4. Vi forestiller os nu virksomheden, havde benyttet optimal allokering til at bestemme stikprøvestørrelserne i de 3 strata. Hvis man havde fået samme gennemsnitlig omsætning i 1000 kr. og samme stikprøve standardafvigelse, hvad ville konfidensintervallet da have været?

Man sælger også hårvoks i samme distributionsnet, her ønsker man på forhånd at bestemme den optimale indsamling af en stikprøve, man kender ikke standard afvigelsen fra de 3 strata, men vurderer ud fra tidligere analyser at standardafvigelsen kan antages at være 10, 15 og 12 for hhv. lille, mellem og stor. Man ønsker at indsamle en samlet stikprøve på 5000 fra de 3 strata.

4. Hvor mange stikprøver er det optimalt at indsamle fra hver af de 3 strata?

</details>
<br>
<details>
  <summary>Svar nonfood dagligvarer</summary>


Herunder er en videoløsning til opgaven:
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/259842259' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
</details>



# Sandsynligheder



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->





<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/228228340' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

Vi vil her se på sandsynligheder. Hvis vi forestiller os, man har på en cafe har spurgt 800 besøgende, om de drikker the, kaffe eller begge dele, og har fået følgende svar.

|Kaffe              |The                     |Både kaffe og the
|:-------------     |:------------           |:------------
600                 | 400                    | 200

Vi kan opstille resultaterne i et Venn-diagram som vist på figuren.<img src="img/sandsynligheder1.png" align="right" width="35%" height="35%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/> Vi kan udføre et stokastisk eksperiment og tilfældigt udtage en person og undersøge, hvor stor sandsynligheden er for at vedkommende drikker kaffe.

Vi skriver P for probability dvs. sandsynlighed. Sandsynligheden for en person drikker kaffe kan opskrives som:

$$\small P(Kaffe)=\frac{Antal\ kaffe-drikkere}{Antal\ adspurgte}=\frac{600}{800}=0.75=75\%$$

På samme måde kan man finde sandsynligheden for at en person drikker the:

$$\small P(The)=\frac{Antal\ the-drikkere}{Antal\ adspurgte}=\frac{400}{800}=0.5=50\%$$

### Forenings- og fælleshændelser

Sandsynligheden for at en person drikker the eller kaffe, er en foreningshændelse (vi bruger symbolet $\cup$), det skriver vi som:
$$P(The\cup Kaffe)=\frac{Antal\ the- eller\ kaffedrikkere}{Antal\ adspurgte}=\frac{800}{800}=1$$
Alle der kommer på denne cafe, drikker altså enten the eller kaffe.

Sandsynligheden for at en person drikker the og kaffe, er en fælleshændelse (vi bruger symnolet$\cap$), det skriver vi som:
$$P(The\cap Kaffe)=\frac{Antal\ the- og\  kaffedrikkere}{Antal\ adspurgte}=\frac{200}{800}=0.25$$

Har man svært ved at huske betydningen af de 2 symboler. Så tænk på at foreningshændelsen  $\cup$ (det ligner er jo en kop), kan rumme mere end fælleshændelsen $\cap$ (der er ikke meget plads på toppen).


## Betingede sandsynligheder

Vi kan også se på en mindre gruppe af de adspurgte, hvis fx. man kun vil se på kaffedrikkerne kunne man ønske at undersøge, hvor stor en andel af kaffedrikkerne der både drikker the og kaffe. Vi siger at vi betinger med en hændelse, hvis vi ser på en sådan delmængde af de adspurgte. Betingede sandsynligheder kan formuleres på flere måder fx:

Givet at man drikker kaffe hvad er da sandsynligheden for at man ligeledes drikker the?
Hvis man drikker kaffe hvad er da sandsynligheden for at man ligeledes drikker the?
Hvad er da sandsynligheden for, at man drikker the, når man drikker kaffe?
Hvad er andelen af kaffedrikkere, der drikker the?

Vi siger vi betinger med hændelsen A, man drikker kaffe, og ser således kun på gruppen af kaffedrikkere. Hvad er så sandsynligheden for at man også drikker the hændelsen B?
Vi skal altså bestemme sandsynligheden for B givet A, med symboler skriver vi det som $\small P(B\mid A)$. Vi kan udregne dette som
$$\small P(B\mid A)=\frac{P(B\cap A)}{P(A)}$$

Det betyder vi kan udregne hvad er andelen af kaffedrikkere, der drikker the, ved formlen:
$$\small P(B\mid A)=P(kaffe\ og\ the\mid  kaffe)=\frac{P(kaffe\ og\ the\cap kaffe)}{P(kaffe)}$$
$$\small \frac{\frac{200}{800}}{\frac{600}{800}}=\frac{200}{600}=\frac{1}{3}\approx 33\%$$



### Race og dødsdom eksempel

<img src="img/death-row-inmates-drug-cocktail.jpg" align="right" width="40%" height="40%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>

I et kendt studie fra 1991 af Radelet and Pierce, om Florida, har man indsamlet data i retssager hvor der var mulighed for dødsstraf. Man har blandt andet indsamlet data om den tiltaltes etnicitet,  offerets etnicitet samt udfaldet af retssagen dvs. om den tiltalte blev idømt dødstraf eller ikke. Studiets formål var at afgøre om der ved domstolene er en bias, således at amerikanere af afrikansk afstamning oftere idømmmes dødsstraf end hvide.

Race tiltalt                  | Dødsdom             |Ikke dødsdom     |Total
|:-------------               |:------------        |:------------   |:---------
Hvid                          |53                   |430            |483
Afrikansk amerikaner          |15                   |176            |191
Total                         |68                   |606            |674

Sandsynligheden for at blive dødsdømt, når man er tiltalt kan udregnes til:
$$\small P(dø\ dsdom)=\frac{dø\ dsdø\ mte}{alle\ tiltalte}=\frac{68}{674}=0.1009$$

Sandsynligheden for at blive dødsdømt, når man er hvid og tiltalt er en betinget sandsynlighed, denne kan udregnes til:
$$\small P(dø\ dsdom\mid hvid)=\frac{P(dø\ dsdom \cap hvid)}{P(hvide\ tiltalte)}=\frac{53}{483}=0.1097$$

Sandsynligheden for at blive dødsdømt, hvis man er afrikansk-amerikaner og tiltalt er en betinget sandsynlighed, denne kan udregnes til:
$$\small P(dø\ dsdom\mid sort)=\frac{P(dø\ dsdom\cap sort)}{P(sorte\ tiltalte)}=\frac{15}{191}=0.0785$$

Dette tyder ikke på at der er racemæssig forskel på andelen af dødsdømte.

## Uafhængighed

Vi kan sige at 2 hændelser A og B er uafhængige hvis sandsynligheden for at den ene hændelse indtræffer ikke påvirkes af om den anden hændelse indtræffer eller ej.

Sandsynligheden for at slå krone med en mønt og slå en sekser med en terning, er 2 hændelser der er uafhængige.

Trækker man et es fra et spil kort, vil sandsynligheden for igen at trække et es være påvirket af det første træk. Disse hændelser er ikke uafhængige.


Vi kan udtrykke uafhængige hændelser vha. betingede sandsynligheder.

$$\small P(A\mid B)=P(A)$$
Her står sandsynligheden for A er den samme ligegyldigt om hændelsen B indtræffer eller ej.
$$\small P(B\mid A)=P(B)$$
Her står sandsynligheden for B er den samme ligegyldigt om hændelsen A indtræffer eller ej.

Vi kan omskrive begge ligninger til nedenstående resultat.
$$\small P(A\mid B)=P(A)\Leftrightarrow \frac{P(A\cap B)}{P(B)}=P(A)\Leftrightarrow P(A\cap B)=P(A)\cdot P(B)$$
Så hændelserne A og B er uafhængige hvis fælleshændelsen $\small P(A\cap B)$ er lig med produktet af hændelserne $\small P(A) \cdot P(B)$

Er hændelserne drikke kaffe og the uafhængige?
Vi finder sandsynligheden for fælleshændelsen:
$$\small P(Kaffe \cap The)=\frac{200}{800}=0.25$$
Er sandsynligheden for fælleshændelsen lig med produktet af sandsynlighederne?
$$\small P(Kaffe)\cdot P(The)=\frac{600}{800}\cdot \frac{400}{800}=\frac{3}{4}\cdot \frac{1}{2}=\frac{3}{8}=0.375$$
Hændelserne er altså ikke uafhængige for 0.25 er ikke 0.375.

Vi ser på om hændelserne hvid tiltalt og dødsdom er afhængige.
Vi finder sandsynligheden for fælleshændelsen:
$$\small P(Dø\ dsdom \cap Hvid)=\frac{53}{674}=0.08$$
Er sandsynligheden for fælleshændelsen lig med produktet af sandsynlighederne?
$$\small P(Dø\ dsdom)\cdot P(Hvid)=\frac{68}{674}\cdot \frac{483}{674}=0.10 \cdot 0.72=0.072$$
Sandsynlighederne 0.08 og 0.072 er tæt på hinanden, udtaler vi os om en population ville vi nok ikke kunne afvise at hændelserne er uafhængige. Vi vil i afsnittede om Chi i anden tests se på hvorledes man tester uafhængighed.


<details>
  <summary>Spørgsmål dødsdom</summary>
Vi inddeler nu skemaet ovenfor, med en variabel, der angiver offerets race.


Race offer    |Race tiltalt       | Dødsdom             |Ikke dødsdom   |Total
|:-------------   |:-------------   |:------------   |:------------  |:---------
Hvid                      |Hvid                          |53                        |414            |467
Hvid                      |Afrikansk amerikaner          |11                        |37             |48
Afrikansk amerikaner      |Hvid                          |0                         |16             |16
Afrikansk amerikaner      |Afrikansk amerikaner          |4                         |139            |143
Total                     |                              |68                        |606            |674

**1.** Hvad er sandsynligheden for at blive dødsdømt, hvis man er hvid tiltalt for at have dræbt en hvid?
**2.** Hvad er sandsynligheden for at blive dødsdømt, givet man er sort tiltalt for at have dræbt en hvid?
**3.** Hvad er sandsynligheden for at blive dødsdømt, givet man er hvid tiltalt for at have dræbt en sort?
**4.** Hvad er sandsynligheden for at blive dødsdømt, når man er sort tiltalt for at have dræbt en sort?
**5.** Hvad er sandsynligheden for at blive dødsdømt og ikke blive dødsdømt, når man er hvid?
**6.** Hvad er sandsynligheden for at blive dødsdømt eller ikke blive dødsdømt, når man er hvid?
</details>
<br>
<details>
  <summary>Svar dødsdom</summary>

<img src="img/usdeath2.jpg" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>
**1.** Sandsynligheden for at blive dødsdømt, hvis man er hvid tiltalt for at have dræbt en hvid kan udregnes til:
$$\small P(Dø\ dsdø\ mt \mid hvid\ tiltalt\ og\ hvidt\ offer)=\frac{53}{467}=0.1135$$
**2.** Sandsynligheden for at blive dødsdømt, givet man er sort tiltalt for at have dræbt en hvid kan udregnes til:
$$\small P(Dø\ dsdø\ mt \mid sort\ tiltalt\ og\ hvidt\ offer)=\frac{11}{48}=0.2292$$
**3.** Sandsynligheden for at blive dødsdømt, givet man er hvid tiltalt for at have dræbt en sort kan udregnes til:
$$\small P(Dø\ dsdø\ mt \mid hvid\ tiltalt\ og\ sort\ offer)=\frac{0}{16}=0$$
**4.** Sandsynligheden for at blive dødsdømt, når man er sort tiltalt for at have dræbt en sort kan udregnes til
$$\small P(Dø\ dsdø\ mt \mid sort\ tiltalt\ og\ sort\ offer)=\frac{4}{143}=0.0280$$

Vi ser nu at der synes at være større sandsynlighed for dødsdom for sorte end for hvide, denne effekt kommer først frem når vi kontrollerer for offer race. Man kalder dette for Simpsons paradoks.

**5.** Sandsynligheden for at blive dødsdømt og ikke blive dødsdømt når man er hvid, er 0, der er ingen hvide der både bliver dødsdømte og ikke dødsdømte. Fællesmængden mellem de 2 hændelser er tom.

**6.** Sandsynligheden for at blive dødsdømt eller ikke blive dødsdømt når man er hvid er 1, alle hvide tiltalte bliver enten dødsdømte eller ikke dødsdømte. Foreningsmængden for de 2 hændelser er alle de mulige udfald. Man kan kun blive dødsdømt eller ikke dødsdømt.



</details>
<br>
<details>
  <summary>Spørgsmål utroskab og skolegang</summary>

Herunder er angivet tro og utro personer delt på Uddannelsesniveau. Data stammer fra en kendt amerikansk undersøgelse om utroskab fra 1969. Man har interviewet 601 respondenter om religiøsitet, antal affærer uddannelsesniveau etc.

Uddannelseniveauet er stigende, hvor Grundskole er lavest og Phd højest. KVU betyder kortere videregående uddannelse.



```{r ,echo=FALSE,warning=FALSE }
utros <- data.frame(rbind(c(5,31,119,95,62,79,60,451),c(2,13,35,20,27,33,20,150),c(7,44,154,115,89,112,80,601)),row.names=c("Antal utro","Antal tro","Total"))
names(utros) <- c("Basis","Gymnasie","KVU1","KVU2","KVU3","Master","Phd.","Total")
kable(utros)%>%
  kable_styling( full_width = T) %>%
  row_spec(0, angle = 0)%>%
  add_header_above(c(" ", "Uddannelsesniveau" = 8)) %>%
 column_spec(9, bold = T,color = "white",background = "Black") %>%
  row_spec(3, bold = T, color = "white", background = "Black")

```


**1.** Hvad er sandsynligheden for at man er utro?

**2.** Hvad er sandsynligheden for man er tro?

**3.** Hvad er sandsynligheden for at man er utro eller tro?

**4.** Hvad er sandsynligheden for at man er utro og tro?

**5.** Hvad er sandsynligheden for at man er utro, givet man har en Phd?

**6.** Hvad er sandsynligheden for at man har en Phd?

**7.** Hvad er sandsynligheden for at man har en Phd eller Kandidatgrad og er tro?

**8.** Hvad er sandsynligheden for at man har en Phd, når man er tro?

**9.** Hvad er sandsynligheden for at man har en Phd eller Kandidatgrad, når man er tro?

**10.** Hvad er sandsynligheden for at man har en Phd og Kandidatgrad, givet man er tro?

**11.** Når man er utro, hvad er da sandsynligheden for, at man har en Kandidatgrad?

**12.** Når man er tro, hvad er da sandsynligheden for, at man har en Phd?












</details>
<br>
<!-- <details>  -->
<!--   <summary>Svar utroskab og skolegang</summary> -->

<!-- </details>  -->
<br>
<br>




# Chi i anden tests



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->





## Goodness of fit test
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/231079869' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>
```{r,echo=FALSE, include=FALSE}

# library("easypackages")
library(rdrop2)
# list.of.packages <- c("googlesheets","dplyr","threejs","plotly","leaflet")
# new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
# if(length(new.packages)) install.packages(new.packages)
#library("googlesheets","dplyr","threejs","plotly","leaflet")
# packages("googlesheets","dplyr","threejs","plotly","leaflet","DT","DiagrammeR","metricsgraphics","dygraphs","networkD3","d3heatmap",prompt=FALSE)
# libraries("googlesheets","dplyr","threejs","plotly","leaflet","DT","DiagrammeR","metricsgraphics","dygraphs","networkD3","d3heatmap","rdrop2","exams")
```


Goodnees of fit testen er en udvidelse af z-testet for en andel. <img src="img/bolig.jpg" align="right" width="40%" height="40%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/> Med test af andele kan man fx. undersøge om andelen af mænd er 60% og kvinder 40% i en population, vi tester altså fordelingen for en kvalitativ variabel med 2 mulige udfald. Med et goodness of fit test kan vi teste kvalitative variable med 2 eller flere mulige udfald, man kan fx. undersøge om fordelingen af boligform i en stikprøve kan antages at svare til fordelingen på regionsplan: 50% ejer, 20% andel og 30% leje.

Vi tester vha. Chi i anden fordelingen. Teststørrelsen vi finder, udtrykker forskellen mellem det vi observerer i stikprøven og det vi tester under nulhypotesen.

```{r chi1 ,echo=FALSE, include=FALSE,warning=F}
obs <- c(60,40,50)
exp <- sum(obs)*c(.5,.2,.3)
chibi <- (obs-exp)^2/exp
chi <- round(sum(chibi),4)
chidf <- length(obs)-1
chicrit <- round(qchisq(0.95,chidf),4)
chipv <- round(1-pchisq(chi,chidf),4)
```

Antag man simpelt tilfældigt har udtaget en stikprøve på 150 boliger, der indeholder 60 ejer- 40 andels- og 50 lejeboliger.

Hvis vi vil undersøge undersøge om fordelingen af boligform i stikprøven, kan antages at følge regionsfordelingen som er 50% ejer, 20% andel og 30% leje, opstiller vi følgende hypoteser:

$$H_0:p_{ejer}=0.5\ p_{andel}=0.2\ p_{leje}=0.3$$$$H_1:Fordelingen\ af\ boliger\ fø\ lger\ ikke\ samme\ fordeling\ som\ i\ regionen$$

Teststørrelsen findes som:

$$\chi^2=\sum^k_{j=1}\frac{(O-E)^2}{E}$$

Hvor O er observerede værdier og E er forventede værdier det stammer fra expected på engelsk, k angiver antallet af mulige udfald for den kvalitative variabel.

For at beregne teststørrelsen bestemmer vi E, antallet af ejer, leje og andel vi ville forvente i en stikprøve på netop 150 boliger, der perfekt repræsenterede regionen.

ejer: $0.5\cdot150=75$
andel: $0.2\cdot150=30$
leje: $0.3\cdot150=45$

Vi kan nu udregne teststørrelsen som:

$$\chi^2=\frac{(60-75)^2}{75}+\frac{(40-30)^2}{30}+\frac{(50-45)^2}{45}=3+3\frac{1}{3}+\frac{5}{9}=`r chi`$$

Vi sammenligner med chi i anden fordelingen med k-1=3-1=2 frihedsgrader $\chi^2_2$, den kritiske værdi bliver `r chicrit` hvilket giver p-værdien `r chipv`, illustreret ved den gule hale i figuren nedenfor. Da teststørrelsen 6.89 er større end den kritiske værdi 5.99, får vi en p-værdi, der er mindre end 5% signifikansniveauet. Vi tester her på 5% signifikansniveau, dvs. 100%-5%=95% konfidensniveau. Vi vælger 5% signifikansniveau, når vi ikke har signifikans- eller konfidensniveauet, givet i opgaven. Vi forkaster nulhypotesen og konkluderer, fordelingen af boligtyper i populationen, er ikke identiske med fordelingen i regionen.

```{r 68,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(0,15,length.out=200)
y <- dchisq(x,chidf)
z <- seq(0,chicrit,length.out=200)
z2 <- seq(chicrit,15,length.out=200)
z3 <- seq(chi,15,length.out=200)
plot(x,y,type="l",main = "Chi i anden fordelingen\n2 frihedsgrader",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(0,z,chicrit),c(0,dchisq(z,chidf),0),col="green",border="NA")
polygon(c(chicrit,z2,25),c(0,dchisq(z2,chidf),0),col="red",border="NA")
polygon(c(chi,z3,25),c(0,dchisq(z3,chidf),0),col="yellow",border="NA")
#text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår chi-scoren er\ni dette interval",cex = .7)
# text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=2,y=.05,"Grønt areal\n95%",cex = .7)
text(x=chi,y=dnorm(0)*1.02,label="chi-teststørrelsen 6.89",cex = .7)
text(x=chicrit*.9,y=0.11,label="kritisk værdi 5.99",cex = .7)
segments( chicrit,  0,   chicrit, 0.1,lty=3,lwd=1,col ="black")
segments( chi, 0, chi, dnorm(0),lty=3,lwd=1,col ="black")
#arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
arrows( chi*1.2, 0.05,chi*1.1, 0.01,length=0.05,angle = 15)
text(x=chi*1.3,y=0.06,label="p-værdi 3.19%",cex = .7)
axis(side = 1, at=c(round(chicrit,2),round(chi,2)),cex.axis=0.7,las=2)
grid()
```

I Freestat tastes input i de hvide felter, hvilket resulterer i følgende resultat:

![](img/gofbolig.png)


## Forudsætning
En forudsætning for at goodness of fit testet er tilstrækkeligt præcist, er at de forventede værdier E er tilstrækkeligt store. Der er mange forskellige tolkninger, af størrelsen af E cellerne. Nogle nævner celleværdier skal være større end 3 andre 5, det bør under alle omstændigheder nævnes om forudsætningen synes opfyldt. Hvis de forventede værdier er meget små, kan man sammenlægge kategorier, der vil så være et tradeoff med detaljegraden af analysen. Hvis man sammenlægger bør man gøre dette, så det analytisk giver mening.

I eksemplet med boligtyper, havde vi forventede værdier E på hhv. 75, 30 og 45, her var forudsætningen altså opfyldt.

<br>
<details>
  <summary>Spørgsmål datasæt karakterer</summary>
Undervisningsministeriet <img src="img/12-Ball-Real.pngc200.png" align="right" width="15%" height="15%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>har et ønske om at karaktererne på landsplan bør normaliseres omkring 7, hvor der er følgende procentvise vægt på hver karakter

|Karakter  | Ønsket fordeling |
|:--------|:-------------|
|02   |10%|
|4    |25%|
|7        |30%|
|10        |25%|
|12       |10%|


Der er intet krav til andelen af studerende der består, således drejer fordelingen sig udelukkende om bestået-karakterer.

```{r statkarakterer ,echo=FALSE, include=FALSE,warning=F}
grade <- c(00,7,10,02,10,00,7,-3,12,00,00,4,4,00,02,10,12,10,10,4,7,02,10,00,00,00,00,4,12,02,12,10,00,10,10,00,00,02,02,02,7,10,00,10,02,7,4,02,00,00,12,4,10,-3)
gender <- c("mand","kvinde","kvinde","kvinde","kvinde","mand","mand","kvinde","mand","mand","kvinde","mand","mand","kvinde","kvinde","kvinde","kvinde","kvinde","mand","kvinde","kvinde","mand","kvinde","mand","mand","kvinde","mand","mand","mand","mand","kvinde","kvinde","kvinde","mand","kvinde","kvinde","kvinde","kvinde","mand","kvinde","mand","mand","mand","kvinde","mand","kvinde","kvinde","kvinde","mand","kvinde","mand","kvinde","mand","mand")
class <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)
length(which(grade==-3))
length(which(grade==00))
k02 <- length(which(grade==02))
k4 <- length(which(grade==4))
k7 <- length(which(grade==7))
k10 <- length(which(grade==10))
k12 <- length(which(grade==12))
sumkar <- sum(k02,k4,k7,k10,k12)
f02 <- round(k02/sumkar,4)
f4 <- round(k4/sumkar,4)
f7 <- round(k7/sumkar,4)
f10 <- round(k10/sumkar,4)
f12 <- round(k12/sumkar,4)
filnavn <- "Statistik karakterer Finansøkonom" #Sæt filnavn her
arknavn <- "Karakterer køn klasse" #Max 31 karakterer
statdf <- data.frame(grade,gender,class)
names(statdf) <- c("Karakterer","Køn","Klasse")

obs <- c(k02,k4,k7,k10,k12)
exp <- sum(obs)*c(.1,.25,.3,.25,.1)
chibi <- (obs-exp)^2/exp
chi <- round(sum(chibi),4)
chidf <- length(obs)-1
chicrit <- round(qchisq(0.95,chidf),4)
chipv <- round(1-pchisq(chi,chidf),4)
```
[Hent datasættet statkarakterer](https://www.dropbox.com/s/mnsmu56cdkl8yyv/Statkarakterer.xlsx?dl=1) for stikprøven for statistikstuderende , betragt kun de beståede studerende, kan populationen antages at følge de generelle retningslinjer?


</details>
<br>
<details>
  <summary>Svar datasæt karakterer</summary>

Vi starter med at se på de beståede `r sumkar` studerende, optæl fx. vha. =countif eller =tælhvis i excel for at bestemme antallet af studerende med de respektive karakterer.

|Karakter  | Ønsket fordeling |   Observeret antal |  Observeret Frekvens |
|:------------------------ |:--------------|:------------|:-----------|
|02   |10%| `r length(which(grade==02))` |`r f02`|
|4    |25%| `r length(which(grade==4))` |`r f4`|
|7        |30%| `r length(which(grade==7))` |`r f7`|
|10        |25%| `r length(which(grade==10))` |`r f10`|
|12       |10%| `r length(which(grade==12))` |`r f12`|

Vi kan nu bestemme den forventede karakterfordeling hvis karaktererne følger den ønskede fordeling.

|Karakter  | Ønsket fordeling |   Forventet antal |  Chi i anden bidrag |
|:------------------------ |:--------------|:------------|:-----------|
|02   |10%| `r exp[1]` |`r round(chibi,4)[1]`|
|4    |25%| `r exp[2]` |`r round(chibi,4)[2]`|
|7        |30%| `r exp[3]` |`r round(chibi,4)[3]`|
|10        |25%| `r exp[4]` |`r round(chibi,4)[4]`|
|12       |10%| `r exp[5]` |`r round(chibi,4)[5]`|

Bemærk forventede værdier er mindre end 5 men større end 3, der kan være problemer med præcisionen. Hvis man ønsker at sammenlægge kategorier giver det ikke mening at lægge 02 og 12 sammen, men gerne 02 og 4 eller 10 og 12. Summen af chi i anden bidrag giver teststørrelsen, dvs:

`r round(chibi,4)[1]`+`r round(chibi,4)[2]`+`r round(chibi,4)[3]`+`r round(chibi,4)[4]`=`r chi`

Hvilket fører til p-værdien `r chipv` illustreret ved den gule hale herunder, da p-værdien er mindre end 5% signifikansniveauet forkaster vi nulhypotesen, og konkluderer at statistikkarakterer på Finansøkonom ikke følger den ønskede fordeling. Vi kan ud fra chi i anden bidragene se hvilke karakterer der giver de største afvigelser. Store bidrag betyder store afvigelser mellem det observede og ønskede. Det største bidrag `r round(max(chibi),4)` stammer fra 02 karakteren, her er den observerede karakter `r round(obs,4)[1]`, mens den forventede værdi er `r round(exp,4)[1]`. Der er altså flere studerende, end forventet der får 02. Bemærk for at vi kan udtale os om populationen finansøkonomer, fordres at stikprøven er repræsentativ for finansøkonomer. Stikprøven er ikke udtaget simpelt tilfældigt, da der er tale om 2 bestemte klasser, det kan derfor diskuteres om stikprøven er afspejler populationen korrekt.

```{r gofstatkar,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(0,25,length.out=200)
y <- dchisq(x,chidf)
z <- seq(0,chicrit,length.out=200)
z2 <- seq(chicrit,15,length.out=200)
z3 <- seq(chi,15,length.out=200)
plot(x,y,type="l",main = "Chi i anden fordelingen\n4 frihedsgrader",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7)
polygon(c(0,z,chicrit),c(0,dchisq(z,chidf),0),col="green",border="NA")
polygon(c(chicrit,z2,25),c(0,dchisq(z2,chidf),0),col="red",border="NA")
polygon(c(chi,z3,25),c(0,dchisq(z3,chidf),0),col="yellow",border="NA")
#text(x=-3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår chi-scoren er\ni dette interval",cex = .7)
# text(x=3.5,y=0.1,"\nAfvis \nnulhypotesen\nnår z-scoren er\ni dette interval",cex = .7)
text(x=4,y=.05,"Grønt areal\n95%",cex = .7)
text(x=chi,y=.15,label=paste("chi-teststørrelsen",round(chi,2)),cex = .7)
text(x=chicrit*.9,y=0.11,label=paste("kritisk værdi",round(chicrit,2)),cex = .7)
segments( chicrit,  0,   chicrit, 0.1,lty=3,lwd=1,col ="black")
segments( chi, 0, chi, .15*.95,lty=3,lwd=1,col ="black")
#arrows( -3.2, 0.05,-2.7, 0.01,length=0.05,angle = 15)
arrows( chi*1.2, 0.05,chi*1.1, 0.01,length=0.05,angle = 15)
text(x=chi*1.3,y=0.06,label=paste("p-værdi",chipv),cex = .7)
axis(side = 1, at=c(round(chicrit,2),round(chi,2)),cex.axis=0.7,las=2)
grid()
```

Freestat output bliver:

![](img/gof.png)


</details>


## Chi i anden test
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/231079771' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>
## Chi i anden test 2
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/231074575' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>
Vi kan analysere kvalitative variable med 2 mulige udfald vha. test af 2 andele. Chi i anden testet er en udvidelse af test af 2 andele. Med chi i anden testen kan man sammenligne kvalitative variable med 2 eller flere mulige udfald. <img src="img/vandskade.jpg" align="right" width="45%" height="45%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/>Vi kan benytte chi i anden testet til at undersøge om der er en sammenhæng mellem 2 inddelingskriterier som fx. køn og bestået/ikke bestået, køn og karakter, aldersgruppe og karakter.

Antag et forsikringsselskab har indsamlet data for kunders skadesanmeldelser fordelt på øst og vest for Storebælt. Forsikringsselskabet ønsker at undersøge om der er forskel i andelen af kunder der anmelder skader i Øst- og Vestdanmark. Følgende data er angivet

```{r chiskade1, echo=FALSE, include=FALSE,warning=FALSE}
library(exams)
M <- as.table(rbind(c(300, 300), c( 250, 150)))
dimnames(M) <- list(landsdel = c("Østdanmark", "Vestdanmark"),
                    skader = c("Ingen skader anmeldt","1 eller flere skader"))
Xsq <- chisq.test(M,correct=F) # Prints test summary

obs <- as.matrix(Xsq$observed)
exp <- as.matrix(Xsq$expected)
chistat <- sum(Xsq$residuals^2)
chibi <- as.matrix(Xsq$residuals^2)
chidf <- (length(M[,1])-1)*(length(M[1,])-1)
chi <- sum(chibi)
chicrit <- qchisq(0.95,chidf)
chipv <- Xsq$p.value


```


| ***Observeret***   | Ingen skader anmeldt |   1 eller flere skader  | Total |
|:---- |:-----------|:-------------- |:--------------|
|Østdanmark     |300       |300               |600|
|Vestdanmark     |250        |150               |400|
|Total           |     550   |          450     | 1000|


Vi kan teste om der er forskel på om der er forskel på andelen af anmeldte skader i Øst- og Vestdanmark vha. chi i anden testet. Vi har følgende hypoteser.


$$H_0: Der\ er\ uafhæ\ \ ngighed\ mellem\ ræ\ kke-\ og\ sø\ jlekriterierne$$$$H_1: Der\ er\ afhæ\ \ ngighed\ mellem\ ræ\ kke-\ og\ sø\ jlekriterierne$$

Eller mere præcist i dette tilfælde:

$$H_0: Der\ er\ uafhæ\ \ ngighed\ mellem\ landsdel\ og\ skadesanmeldelse$$$$H_1: Der\ er\ afhæ\ \ ngighed\ mellem\ landsdel\ og\ skadesanmeldelse$$

Hvis nulhypotesen forkastes påvirker landsdelen kunder kommer fra altså andelen af anmeldte skader.

### Uafhængighed

Definitionen af uafhængighed mellem 2 hændelser A og B er at sandsynligheden for fælleshændelsen er lig med produktet af sandsynlighederne for enkelthændelserne som formel skriver vi:
$$P(A\cap B)=P(A)\cdot P(B)$$

Vores hændelse A kan fx. være kunden stammer fra Østdanmark, og hændelse B at kunden har ikke anmeldt skader. Vi får da følgende ligning:
$$P(Ø\ \ stdanmark\cap 0\ skader)=P(Ø\ \ stdanmark)\cdot P(0\ skader)$$
Vi kan omskrive dette til:
$$P(Ø\ \ stdanmark\cap0\ skader)=P(Ø\ \ stdanmark)\cdot P(0\ skader)\Leftrightarrow \frac{300}{1000}=\frac{600}{1000}\cdot \frac{550}{1000} \Leftrightarrow $$$$1000\cdot\frac{300}{1000}=1000\cdot \frac{600\cdot550}{1000\cdot1000} \Leftrightarrow 300= \frac{600\cdot550}{1000}$$
Her er venstresiden i ligningen jo den observerede celleværdi. Hvis der er uafhængighed under nulhypotesen, vil vi forvente at den observerede værdi, er lig med venstresiden, som vi kalder den forventede værdi. Hvis der er perfekt uafhængighed mellem landsdel og skadesanmeldelse, ville vi altså i hver celle forvente værdien:
$$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}$$

Vi får derfor følgende matrice.


| ***Forventet***   | Ingen skader anmeldt | 1 eller flere skader  | Total |
|:---- |:-----------|:-------------- |:--------------|
|Østdanmark     |$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}=\frac{600\cdot 550}{1000}=`r (600*550)/1000`$        |$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}=\frac{600\cdot 450}{1000}=`r (600*450)/1000`$               |600|
|Vestdanmark     |$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}=\frac{400\cdot 550}{1000}=`r (400*550)/1000`$        |$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}=\frac{400\cdot 450}{1000}=`r (400*450)/1000`$               |400|
|Total           |     550   |          450     | 1000|

Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet:

$$\frac{(O-E)^2}{E}$$

| ***Chi celle bidrag***   | Ingen skader anmeldt |   1 eller flere skader  | Total |
|:---- |:-----------|:-------------- |:--------------|
|Østdanmark     |$\frac{(`r obs[1,1]`-`r (600*550)/1000`)^2}{`r (600*550)/1000`}=`r chibi[1,1]`$        |$\frac{(`r obs[1,2]`-`r (600*450)/1000`)^2}{`r (600*450)/1000`}=`r chibi[1,2]`$            ||
|Vestdanmark     |$\frac{(`r obs[2,1]`-`r (400*550)/1000`)^2}{`r (400*550)/1000`}=`r chibi[2,1]`$                    |$\frac{(`r obs[2,2]`-`r (400*450)/1000`)^2}{`r (400*450)/1000`}=`r chibi[2,2]`$                     ||
|Total           |        |               | `r round2(sum(chibi),2)`|

Teststørrelsen bliver `r round2(sum(chibi),2)`, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader for chi i anden fordelingen er antallet af rækkeinddelingskriterier Østdanmark og Vestdanmark minus 1, gange antallet af søjleinddelingskriterier 0 skader og flere end 0 skader minus 1, dvs. $$(r-1)\cdot(s-1)=(2-1)\cdot(2-1)=1\cdot1=1$$
Vi får p-værdien `r round2(chipv,6)`, hvilket er klart mindre end signifikansniveauet på 5%, arealet er så lille vi ikke kan se det på figuren nedenfor. Vi forkaster altså nulhypotesen og konstaterer der er afhængighed mellem landsdel og anmeldte skader. Landsdelen som kunden stammer fra, påvirker altså antallet af anmeldte skader. Vi kan nu se om der er chi i anden bidrag, der er meget store og dermed bidrager stæ til konklusionen om afhængighed. Der er ikke en voldsom forskel i størrelserne på chi i anden bidragene, men når vi ser på observeret mod forventet, ser vi at 150 anmelder skader, det var forventet at 180 personer fra Vestdanmark anmelder skader. Denne tendens er modsat for Østdanmark. Vestdanmark anmelder altså færre skader end Østdanmark.

Ligesom for goodness of fit testet, skal de forventede værdier have en vis størrelse for at vore konklusioner er præcise. Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler.


```{r chi45,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(0.1,24,length.out=200)
y <- dchisq(x,chidf)
z <- seq(0.1,chicrit,length.out=200)
z2 <- seq(chicrit,22,length.out=200)
z3 <- seq(chi,22,length.out=200)
plot(x,y,type="l",main = "Chi i anden fordelingen\n1 frihedsgrad",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7,ylim=c(0,0.2),xlim=c(0,22))
polygon(c(0,z,chicrit),c(0,dchisq(z,chidf),0),col="green",border="NA")
polygon(c(chicrit,z2,25),c(0,dchisq(z2,chidf),0),col="red",border="NA")
polygon(c(chi,z3,25),c(0,dchisq(z3,chidf),0),col="yellow",border="NA")
text(x=7,y=0.05,"\nAfvis \nnulhypotesen når\nchiteststørrelsen er\ni det røde interval",cex = .7)
text(x=chicrit*.5,y=dchisq(chicrit*.7,chidf)*.5,"Grønt areal\n95%",cex = .7)
text(x=chi,y=.15,label=paste("chi-teststørrelsen",round2(chi,2)),cex = .7)
text(x=chicrit,y=0.11,label=paste("kritisk værdi",round2(chicrit,2)),cex = .7)
segments( chicrit,  0, chicrit, 0.1,lty=3,lwd=1,col ="black")
segments( chi, 0, chi, .15*.95,lty=3,lwd=1,col ="black")
arrows( 5.5, 0.03,5, 0.02,length=0.05,angle = 15)
text(x=chi*1.3,y=0.025,label=paste("p-værdi\n",round2(chipv,6)),cex = .7)
arrows( chi*1.2, 0.02,chi*1.17, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(0,round2(chicrit,2),round2(chi,2)),cex.axis=0.7,las=2)
grid()
```

Freestat output bliver
![](img/chiskade.png)



### Anmeldte skader fordelt på regioner og antal skader

```{r chiskade2,echo=FALSE, include=FALSE,warning=FALSE}
M <- as.table(rbind(c(150,125,50), c( 150, 100,25),c(75,30,10),c(75,40,10),c(100,45,15)))
dimnames(M) <- list(landsdel = c("Hovedstaden", "Sjælland","Syddanmark","Midtjylland","Nordjylland"),
                    skader = c("0 skader","1 skade","2 eller flere skader"))
(Xsq <- chisq.test(M,correct=F))  # Prints test summary
Xsq$observed   # observed counts (same as M)
Xsq$expected   # expected counts under the null
obs <- as.matrix(Xsq$observed)
exp <- as.matrix(Xsq$expected)
chistat <- sum(Xsq$residuals^2)
chibi <- as.matrix(Xsq$residuals^2)
chidf <- (length(M[,1])-1)*(length(M[1,])-1)
chi <- sum(chibi)
chicrit <- qchisq(0.95,chidf)
chicrit*.5
chipv <- Xsq$p.value


```

Vi antager nu der foreligger mere specifikke data for undersøgelsen omkring geografisk placering og skadesanmeldelse.Vi har finere inddeling på region og antal skader.

| ***Observeret***   | 0 skader  |   1 skade  | 2 eller flere skader | Total |
|:---- |:-----------|:-------------- |:--------------|:--------------|
|Hovedstaden     |150       |125          | 50     |325|
|Sjælland     |150       |100     | 25          |275|
|Syddanmark     |75        |30   | 10            |115|
|Midtjylland     |75        |40     | 10          |125|
|Nordjylland     |100        |45    | 15           |160|
|Total           |     550   |  340          |  110 | 1000|


Vi kan teste om der er forskel på om der er forskel på andelen af anmeldte skader i Øst- og Vestdanmark vha. chi i anden testet. Vi har følgende hypoteser.

$$H_0: Der\ er\ uafhæ\ \ ngighed\ mellem\ region\ og\ antal skader$$$$H_1: Der\ er\ afhæ\ \ ngighed\ mellem\ region\ og\ antal skader$$

Hvis nulhypotesen forkastes påvirker regionen kunder kommer fra altså antallet af anmeldte skader.


Vi beregner de forventede værdier efter den sædvanlige formel:

$$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}$$

Hvilket giver følgende matrix

| ***Forventet***   | 0 skader  |   1 skade  | 2 eller flere skader | Total |
|:---- |:-----------|:-------------- |:--------------|:--------------|
|Hovedstaden     |`r exp[1,1]`       |`r exp[1,2]`          | `r exp[1,3]`     |`r sum(exp[1,1:3])`|
|Sjælland     |`r exp[2,1]`       |`r exp[2,2]`     | `r exp[2,3]`          |`r sum(exp[2,1:3])`|
|Syddanmark     |`r exp[3,1]`        |`r exp[3,2]`   | `r exp[3,3]`            |`r sum(exp[3,1:3])`|
|Midtjylland     |`r exp[4,1]`        |`r exp[4,2]`     | `r exp[4,3]`          |`r sum(exp[4,1:3])`|
|Nordjylland     |`r exp[5,1]`        |`r exp[5,2]`    | `r exp[5,3]`           |`r sum(exp[5,1:3])`|
|Total           |     `r sum(exp[1:5,1])`   |  `r sum(exp[1:5,2])`          |  `r sum(exp[1:5,3])` | `r sum(exp)`|



Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet:

$$\frac{(O-E)^2}{E}$$


| ***Chi celle bidrag***   | 0 skader  |   1 skade  | 2 eller flere skader | Total |
|:---- |:-----------|:-------------- |:--------------|:--------------|
|Hovedstaden     |`r chibi[1,1]`       |`r chibi[1,2]`          | `r chibi[1,3]`     |`r sum(chibi[1,1:3])`|
|Sjælland     |`r chibi[2,1]`       |`r chibi[2,2]`     | `r chibi[2,3]`          |`r sum(chibi[2,1:3])`|
|Syddanmark     |`r chibi[3,1]`        |`r chibi[3,2]`   | `r chibi[3,3]`            |`r sum(chibi[3,1:3])`|
|Midtjylland     |`r chibi[4,1]`        |`r chibi[4,2]`     | `r chibi[4,3]`          |`r sum(chibi[4,1:3])`|
|Nordjylland     |`r chibi[5,1]`        |`r chibi[5,2]`    | `r chibi[5,3]`           |`r sum(chibi[5,1:3])`|
|Total           |     `r sum(chibi[1:5,1])`   |  `r sum(chibi[1:5,2])`          |  `r sum(chibi[1:5,3])` | `r sum(chibi)`|



Teststørrelsen bliver `r round2(sum(chibi),2)`, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver
$$(r-1)\cdot(s-1)=(5-1)\cdot(3-1)=4\cdot 2=8$$
Vi får p-værdien `r round2(chipv,6)`, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem region og antal anmeldte skader. Regionen som kunden stammer fra, påvirker altså antallet af anmeldte skader. Vi kan  se, der er chi i anden bidrag, der er store for region København, disse bidrager kraftigt til konklusionen om afhængighed. Københavnerne anmelder flere skader end forventet, dermed er der færre københavnere end forventet, der ikke anmelder skader.

Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler.


```{r chi46,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
x <- seq(0,30,length.out=200)
y <- dchisq(x,chidf)
z <- seq(0.1,chicrit,length.out=200)
z2 <- seq(chicrit,30,length.out=200)
z3 <- seq(chi,30,length.out=200)
plot(x,y,type="l",main = "Chi i anden fordelingen\n8 frihedsgrader",xaxt="n",cex.main=1,cex.axis=0.7,cex.lab=0.7,ylim=c(0,0.2),xlim=c(0,28))
polygon(c(0,z,chicrit),c(0,dchisq(z,chidf),0),col="green",border="NA")
polygon(c(chicrit,z2,25),c(0,dchisq(z2,chidf),0),col="red",border="NA")
polygon(c(chi,z3,25),c(0,dchisq(z3,chidf),0),col="yellow",border="NA")
text(x=chicrit*1.3,y=0.05,"\nAfvis \nnulhypotesen når\nchiteststørrelsen er\nstørre end 15.51",cex = .7)
text(x=chicrit*.5,y=dchisq(chicrit*.7,chidf)*.5,"Grønt areal\n95%",cex = .7)
text(x=chi,y=.15,label=paste("chi-teststørrelsen",round2(chi,2)),cex = .7)
text(x=chicrit,y=0.11,label=paste("kritisk værdi",round2(chicrit,2)),cex = .7)
segments( chicrit,  0, chicrit, 0.1,lty=3,lwd=1,col ="black")
segments( chi, 0, chi, .15*.95,lty=3,lwd=1,col ="black")
arrows( chicrit*1.15, 0.03,chicrit*1.1, 0.02,length=0.05,angle = 15)
text(x=chi*1.15,y=0.025,label=paste("p-værdi\n",round2(chipv,4)),cex = .7)
arrows( chi*1.1, 0.02,chi*1.05, 0.01,length=0.05,angle = 15)
axis(side = 1, at=c(0,round2(chicrit,2),round2(chi,2)),cex.axis=0.7,las=2)
grid()
```

Freestat output bliver
![](img/chiskade2.png)



<br>
<details>
  <summary>Spørgsmål Titanic</summary>


I 1912 forliste Titanic, vi har i filen oplysninger om passagererne.<img src="img/titanic.jpg" align="right" width="30%" height="30%"style="border:0.0px solid #eeeeee; padding:5px; margin:6px;"/> Har man har større chance for at overleve, hvis man er velhavende? Vi har ikke oplysninger om passagerernes formuer, men vi kan bruge oplysningerne om billetterne som en proxy for velstand. Variablen pclass angiver hvilken billet den pågældende passager havde, 1. klasse er dyrest. Variablen survived fortæller om en passager overlevede 1 eller døde 0. Data er i filen [Titanic](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlYWJOOG5yamNoOTQ).



```{r chititan,echo=FALSE, include=FALSE,warning=FALSE}
library(readxl)
titanic <- read_excel("/cloud/project/FILER/titanic.xls",sheet=1)
M <- as.matrix(cbind(titanic$pclass,titanic$survived))
head(M)

as.factor(titanic$pclass)
summary(as.factor(titanic$pclass))

table(titanic$pclass)

M <- table(titanic[,1:2])




dimnames(M) <- list(Klasse = c("1", "2","3"),
                    Overlevede = c("Døde","Overlevede"))
(Xsq <- chisq.test(M,correct=F))  # Prints test summary


Xsq$observed   # observed counts (same as M)
Xsq$expected   # expected counts under the null
obs <- as.matrix(Xsq$observed)
exp <- as.matrix(Xsq$expected)
chistat <- sum(Xsq$residuals^2)
chibi <- as.matrix(Xsq$residuals^2)
chidf <- (length(M[,1])-1)*(length(M[1,])-1)
chi <- sum(chibi)
chicrit <- qchisq(0.95,chidf)

chipv <- Xsq$p.value

```

</details>
<br>
<details>
  <summary>Svar Titanic</summary>


Vi sorterer passagerer efter billet og om de har overlevet.

| ***Observeret***   |  Døde  |Overlevede  |Total |
|:---- |:-----------|:-------------- |:--------------|
|1. Klasse       |`r M[1,1]`       |`r M[1,2]`            |`r sum(M[1,1:2])`|
|2. Klasse       |`r M[2,1]`       |`r M[2,2]`               |`r sum(M[2,1:2])`|
|3. Klasse       |`r M[3,1]`        |`r M[3,2]`             |`r sum(M[3,1:2])`|
|Total           |     `r sum(M[1:3,1])`   |  `r sum(exp[1:3,2])`          |  `r sum(M)`|


Vi kan teste om der er billettype betyder noget for overlevelse. Vi får følgende hypoteser:

$$H_0: Der\ er\ uafhæ\ \ ngighed\ mellem\ passagerklasse\ og\ overlevelse$$$$H_1: Der\ er\ afhæ\ \ ngighed\ mellem\ passagerklasse\ og\ overlevelse$$

Hvis nulhypotesen forkastes betyder passagerklasse noget for noget for overlevelsen


Vi beregner de forventede værdier:

$$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}$$

Hvilket giver følgende matrix

| ***Forventet***   |Døde  |Overlevede  |Total |
|:---- |:-----------|:-------------- |:--------------|
|1. Klasse       |`r round2(exp[1,1],2)`       |`r round2(exp[1,2],2)`            |`r sum(exp[1,1:2])`|
|2. Klasse       |`r round2(exp[2,1],2)`       |`r round2(exp[2,2],2)`               |`r sum(exp[2,1:2])`|
|3. Klasse       |`r round2(exp[3,1],2)`        |`r round2(exp[3,2],2)`             |`r sum(exp[3,1:2])`|
|Total           |     `r sum(exp[1:3,1])`   |  `r sum(exp[1:3,2])`          |  `r sum(exp)`|



Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet:

$$\frac{(O-E)^2}{E}$$


|***Chi celle bidrag***   |Døde  |Overlevede  |Total |
|:---- |:-----------|:-------------- |:--------------|
|1. Klasse       |`r round2(chibi[1,1],4)`       |`r round2(chibi[1,2],4)`               |`r round2(sum(chibi[1,1:2]),4)`|
|2. Klasse       |`r round2(chibi[2,1],4)`       |`r round2(chibi[2,2],4)`               |`r round2(sum(chibi[2,1:2]),4)`|
|3. Klasse       |`r round2(chibi[3,1],4)`        |`r round2(chibi[3,2],4)`              |`r round2(sum(chibi[3,1:2]),4)`|
|Total           |     `r round2(sum(chibi[1:3,1]),4)`   |  `r round2(sum(chibi[1:3,2]),4)`          |  `r round2(sum(chibi),4)`|



Teststørrelsen bliver `r round2(sum(chibi),2)`, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver
$$(r-1)\cdot(s-1)=(3-1)\cdot(2-1)=2\cdot 1=2$$
Vi får p-værdien `r round2(chipv,6)`, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem passagerklasse og overlevelse.

Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler.

Vi kan se at 200 1. klasses passagerer overlevede mod forventet 123.38 under nulhypotesen, hvilket giver et meget stort chi i anden bidrag. Omvendt overlevede kun 181 3. klasses passagerer mod 270.82 forventet under nulhypotesen. Der var altså væstentlig større chance for overlevelse hvis man er velhavende.
</details>
<br>
<details>
  <summary>Spørgsmål bankansatte</summary>

Vi ser på data for bankansatte i filen [Bankdata filen](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM). Er der sammenhæng mellem jobfunktion og køn?




```{r chibank,echo=FALSE, include=FALSE,warning=FALSE}

data <- read_excel("/cloud/project/FILER/BANKDATA.xls",sheet=1)

M <- table(data$job,data$gender)

Xsq <- chisq.test(M,correct=F) # Prints test summary

obs <- as.matrix(Xsq$observed)
exp <- round2(as.matrix(Xsq$expected),4)
chistat <- sum(Xsq$residuals^2)
chibi <- round2(as.matrix(Xsq$residuals^2),4)
chidf <- (length(M[,1])-1)*(length(M[1,])-1)
chi <- sum(chibi)
chicrit <- qchisq(0.95,chidf)

chipv <- Xsq$p.value

```


</details>
<br>
<details>
  <summary>Svar bankansatte</summary>


Vi sorterer personalet efter jobfunktion og køn.

|***Observeret***   |Kvinde  |Mand  |Total |
|:---- |:-----------|:-------------- |:--------------|
|Administration       |`r M[1,1]`       |`r M[1,2]`            |`r sum(M[1,1:2])`|
|Sikkerhedspersonale      |`r M[2,1]`       |`r M[2,2]`               |`r sum(M[2,1:2])`|
|Ledelse       |`r M[3,1]`        |`r M[3,2]`             |`r sum(M[3,1:2])`|
|Total           |     `r sum(M[1:3,1])`   |  `r sum(exp[1:3,2])`          |  `r sum(M)`|


Vi kan teste om der er billettype betyder noget for overlevelse. Vi får følgende hypoteser:

$$H_0: Der\ er\ uafhæ\ \ ngighed\ mellem\ jobfunktion\ og\ kø\ n$$$$H_1: Der\ er\ afhæ\ \ ngighed\ mellem\ jobfunktion\ og\ kø\ n$$

Hvis nulhypotesen forkastes har køn betydning for jobfunktion.


Vi beregner de forventede værdier:

$$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}$$

Hvilket giver følgende matrix

|***Forventet***   |Kvinde  |Mand  |Total |
|:---- |:-----------|:-------------- |:--------------|
|Administration       |`r round2(exp[1,1],2)`       |`r round2(exp[1,2],2)`            |`r sum(exp[1,1:2])`|
|Sikkerhedspersonale       |`r round2(exp[2,1],2)`       |`r round2(exp[2,2],2)`               |`r sum(exp[2,1:2])`|
|Ledelse       |`r round2(exp[3,1],2)`        |`r round2(exp[3,2],2)`             |`r sum(exp[3,1:2])`|
|Total           |     `r sum(exp[1:3,1])`   |  `r sum(exp[1:3,2])`          |  `r sum(exp)`|



Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet:

$$\frac{(O-E)^2}{E}$$


|***Chi celle bidrag***   |Kvinde  |Mand  | Total |
|:---- |:-----------|:-------------- |:--------------|
|Administration       |`r round2(chibi[1,1],4)`       |`r round2(chibi[1,2],4)`               |`r round2(sum(chibi[1,1:2]),4)`|
|Sikkerhedspersonale       |`r round2(chibi[2,1],4)`       |`r round2(chibi[2,2],4)`               |`r round2(sum(chibi[2,1:2]),4)`|
|Ledelse       |`r round2(chibi[3,1],4)`        |`r round2(chibi[3,2],4)`              |`r round2(sum(chibi[3,1:2]),4)`|
|Total           |     `r round2(sum(chibi[1:3,1]),4)`   |  `r round2(sum(chibi[1:3,2]),4)`          |  `r round2(sum(chibi),4)`|



Teststørrelsen bliver `r round2(sum(chibi),2)`, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver
$$(r-1)\cdot(s-1)=(3-1)\cdot(2-1)=2\cdot 1=2$$
Vi får en meeget lille p-værdi afrundet til `r round2(chipv,6)`, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem jobfunktion og køn.

Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler.

Udfra tabellerne ses at mænd er underrepræsenteret i administrationen og overrepræsenteret i sikkerhedspersonale og ledelse.

</details>
<br>
<details>
  <summary>Spørgsmål bankansatte</summary>

Vi ser fortsat på data for bankansatte i filen [Bankdata filen](https://drive.google.com/uc?export=download&id=0B1E7VnhxsDMlRENKWWxlNlBXbmM). Er der sammenhæng mellem jobfunktion og minoritet? Minoritet er ikke-hvide.




```{r chibank2,echo=FALSE, include=FALSE,warning=FALSE}

data <- read_excel("/cloud/project/FILER/BANKDATA.xls",sheet=1)


M <- table(data$job,data$minority)
Xsq <- chisq.test(M,correct=F) # Prints test summary

obs <- as.matrix(Xsq$observed)
exp <- round2(as.matrix(Xsq$expected),4)
chistat <- sum(Xsq$residuals^2)
chibi <- round2(as.matrix(Xsq$residuals^2),4)
chidf <- (length(M[,1])-1)*(length(M[1,])-1)
chi <- sum(chibi)
chicrit <- qchisq(0.95,chidf)

chipv <- Xsq$p.value

```
</details>
<br>
<details>
  <summary>Svar bankansatte</summary>
Vi sorterer personalet efter jobfunktion og køn.

|***Observeret***   |Ikke-minoritet  |minoritet  | Total |
|:---- |:-----------|:-------------- |:--------------|
|Administration       |`r M[1,1]`       |`r M[1,2]`            |`r sum(M[1,1:2])`|
|Sikkerhedspersonale      |`r M[2,1]`       |`r M[2,2]`               |`r sum(M[2,1:2])`|
|Ledelse       |`r M[3,1]`        |`r M[3,2]`             |`r sum(M[3,1:2])`|
|Total           |     `r round2(sum(M[1:3,1]))`   |  `r round2(sum(exp[1:3,2]))`          |  `r sum(M)`|


Vi kan teste om minoritet betyder noget for jobfunktion. Vi får følgende hypoteser:

$$H_0: Der\ er\ uafhæ\ \ ngighed\ mellem\ jobfunktion\ og\ minoritet$$$$H_1: Der\ er\ afhæ\ \ ngighed\ mellem\ jobfunktion\ og\ minoritet$$

Hvis nulhypotesen forkastes betyder det at tilhører man en minoritet har dette betydning for jobfunktionen.


Vi beregner de forventede værdier:

$$\frac{ræ\ \ kkesum\cdot sø\ jlesum}{totalsum}$$

Hvilket giver følgende matrix

|***Forventet***   |Ikke-minoritet  |Minoritet  |Total |
|:---- |:-----------|:-------------- |:--------------|
|Administration       |`r round2(exp[1,1],2)`       |`r round2(exp[1,2],2)`            |`r sum(exp[1,1:2])`|
|Sikkerhedspersonale       |`r round2(exp[2,1],2)`       |`r round2(exp[2,2],2)`               |`r sum(exp[2,1:2])`|
|Ledelse       |`r round2(exp[3,1],2)`        |`r round2(exp[3,2],2)`             |`r sum(exp[3,1:2])`|
|Total           |     `r round2(sum(exp[1:3,1]))`   |  `r round2(sum(exp[1:3,2]))`          |  `r sum(exp)`|



Vi kan nu beregne chi i anden cellebidragene med samme formel som for goodness of fit testet:

$$\frac{(O-E)^2}{E}$$


|***Chi celle bidrag***   |Ikke-minoritet  |minoritet  |Total |
|:---- |:-----------|:-------------- |:--------------|
|Administration       |`r round2(chibi[1,1],4)`       |`r round2(chibi[1,2],4)`               |`r round2(sum(chibi[1,1:2]),4)`|
|Sikkerhedspersonale       |`r round2(chibi[2,1],4)`       |`r round2(chibi[2,2],4)`               |`r round2(sum(chibi[2,1:2]),4)`|
|Ledelse       |`r round2(chibi[3,1],4)`        |`r round2(chibi[3,2],4)`              |`r round2(sum(chibi[3,1:2]),4)`|
|Total           |     `r round2(sum(chibi[1:3,1]),4)`   |  `r round2(sum(chibi[1:3,2]),4)`          |  `r round2(sum(chibi),4)`|



Teststørrelsen bliver `r round2(sum(chibi),2)`, denne bruger vi til at beregne p-værdien for testet af uafhængighed. Antallet af frihedsgrader bliver
$$(r-1)\cdot(s-1)=(3-1)\cdot(2-1)=2\cdot 1=2$$
Vi får en lille p-værdi på `r round2(chipv,6)`, hvilket er klart mindre end signifikansniveauet på 5%. Vi forkaster nulhypotesen og konstaterer, der er afhængighed mellem jobfunktion og om man tilhører en minoritet.

Forudsætningen om forventede værdier større end 5 er opfyldt for alle celler.

Udfra tabellerne ses at minoriteter er overrepræsenteret blandt administration og sikkerhedspersonale og  underrepræsenteret i ledelsen.

</details>


## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=95" target="_blank">Selvtest Chi i anden investeringsfonde med videoløsninger</a></h2>
## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=55" target="_blank">Selvtest Chi i anden realkredit med videoløsninger</a></h2>


```{r, include=FALSE}
Pris <- c(6,7,6,5,7,6,5,6,3,1,2,5,2,3,1,2)
Software <- c(5,3,4,7,7,4,7,5,5,3,6,7,4,5,6,3)
Æstetik <- c(3,2,4,1,5,2,2,4,6,7,6,7,5,6,5,7)
Brand <- c(4,2,5,3,5,3,1,4,7,5,7,6,6,5,5,7)
Venner <- c(7,2,5,6,2,4,1,7,3,2,6,7,6,2,4,5)
Familie <- c(6,3,4,7,1,5,4,5,4,4,5,7,2,3,5,6)

data <- data.frame(Pris, Software, Æstetik, Brand, Venner, Familie)


```

# ANOVA


<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->







<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/231386150' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

ANOVA er en metode til at sammenligne middelværdierne for mere end to kvantitative variable. Skal man sammenligne to middelværdier med varianshomogenitet, benytter man pooled t-test, er der mere end 2 middelværdier benyttes ANOVA F-test . Forudsætningerne for at benytte testen er at populationerne er normalfordelte og har samme varians.

ANOVA er en forkortelse af analysis of variances, man tester om middelværdierne er ens vha. varianserne.
Vi undersøger om k populationer har samme middelværdi, hypoteserne bliver:

$$H_0:\mu_1=\mu_2=...=\mu_k$$$$H_1:Ikke\ alle\ middelvæ\ rdier\ er\ ens.$$

Den totale variation SST kan opdeles i SSW og SSA hvor, SSW er variationen indenfor de k grupper, SSA er variationen mellem grupperne.

Hvis variationen indenfor grupperne SSW er lille i forhold til variationen mellem grupperne SSA, er middelværdierne ikke ens.

Herunder er et eksempel, hvor populationerne er dagsafkast for aktier, variationen indenfor grupperne SSW er lille i forhold til variationen mellem grupperne SSA, derfor er middelværdierne signifikant forskellige.



```{r anova1,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}


X1<-seq(-6,10,length=250)
Y1<-dnorm(X1,mean=-1,sd=0.5)
Y2<-dnorm(X1, mean=4,sd=0.5)
Y3<-dnorm(X1, mean=6,sd=0.5)
plot(X1,Y1, xlim=c(-5,10), type="l", lty=1, col="blue", lwd=4, xlab="Dagsafkast i procent", ylab="Sandsynligeheds tæthed",main="3 aktier dagsafkast standardafvigelsen er 0.5")
points(X1, Y2, type="l", lty=2, col="red", lwd=4)
points(X1, Y3, type="l", lty=3, col="green", lwd=4)
legend("topright", legend=c("Middel=-1","Middel=4","Middel=6"), col=c("blue", "red", "green"),lty=c(1,2,3), lwd=4)
options(scipen=999)
```

Herunder er en figur med dagsafkast for aktier, hvor variationen indenfor grupperne SSW er stor i forhold til variationen mellem grupperne SSA, derfor er middelværdierne ikke signifikant forskellige.

```{r anova2,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
X1<-seq(-6,10, length=250)
Y1<-dnorm(X1,mean=0,sd=2)
Y2<-dnorm(X1, mean=0.5,sd=2)
Y3<-dnorm(X1, mean=1,sd=2)
plot(X1,Y1, xlim=c(-5,10), type="l", lty=1, col="blue", lwd=4, xlab="Dagsafkast i procent", ylab="Sandsynligeheds tæthed",main="3 aktier dagsafkast standardafvigelsen er 2")
points(X1, Y2, type="l", lty=2, col="red", lwd=4)
points(X1, Y3, type="l", lty=3, col="green", lwd=4)
legend("topright", legend=c("Middel=0","Middel=0.5","Middel=1"), col=c("blue", "red", "green"),lty=c(1,2,3), lwd=4)
```

Herunder er et eksempel hvor forudsætningen om varianshomogenitet ikke er opfyldt, de 3 aktier har forskelligt variation.

```{r anova3,echo=FALSE,fig.width=9, fig.height=5, dev='svg'}
X1<-seq(-6,10, length=250)
Y1<-dnorm(X1,mean=0,sd=0.5)
Y2<-dnorm(X1, mean=0.5,sd=1)
Y3<-dnorm(X1, mean=1,sd=2)
plot(X1,Y1, xlim=c(-5,10), type="l", lty=1, col="blue", lwd=4, xlab="Dagsafkast i procent", ylab="Sandsynligeheds tæthed",main="3 aktier dagsafkast standardafvigelserne er 0.5 1 og 2")
points(X1, Y2, type="l", lty=2, col="red", lwd=4)
points(X1, Y3, type="l", lty=3, col="green", lwd=4)
legend("topright", legend=c("Middel=0","Middel=0.5","Middel=1"), col=c("blue", "red", "green"),lty=c(1,2,3), lwd=4)
```




```{r sidedesign  ,echo=FALSE, include=FALSE}
filnavn2 <- "Hjemmesidedesigns besøgstider i millisekunder" #Sæt filnavn her
arknavn <- "Hjemmesidedesigns besøgstider" #Max 31 karakterer

design1 <- c(82843,59394,81801,30489,13313,104223,102679,49202,114935,28259,51840,53022,69169,48950,54136,84444,15549,950,28508,62335,49793,112352,120032,131917,52765,29472,67888,72243,49088,23097,32963,82060,1872,86392,32508,54667,99172,58035,99169,14181,23643,24603,20709,108656,5819,46688,4681,46493,9198,20896,92070,26126,122101,80075,33937,62344,58861,39264,60197,67278,83674,39415,61348,65581,44362,54873,59795,66300,45057,23081,40615,25196,41284,83605,13350,14946,8339,62645,2913,41941,45155,32255,63727,35700,30684,31996,65102)
design2 <- c(71827,37319,58311,36533,6818,80400,63015,46884,34959,26474,58288,26884,49839,21429,62147,99139,94912,73811,86357,51995,30681,48114,49222,107531,86660,12138,74575,55986,64647,68512,114809,49653,101971,50830,33338,58244,72956,125002,110199,63455,81010,115506,66669,37104,78443,49145,93021,123614,98359,88815,90593,117125,64600,29965,44772,32049,2497,67889,82164,22965,54715,54106,98329,47993,92144,84562,20356,52538,67054,97753,71671,41890,31720,76461,73304,47125,2318,70861,76591,84593,75405,57897,51787,41253,73431,63389,18919,55268,81982,87541,55648,84354)
design3 <- c(83582,77192,46849,78697,16113,64715,3538,34949,49486,39785,88179,9459,89480,53856,86557,55052,71208,123707,50193,45519,100996,30882,58819,81720,77615,62253,129496,27960,86143,60150,57427,33528,35995,32471,104309,7884,81678,11850,48415,40502,73605,37777,75874,56501,33139,27051,68832,90323,49026,69200,57450,42561,66711,66235,39755,47409,22144,78020,69744,92665,17254,59873,33482,89393,86341,105640,46459,78211,48738,15418,76289,62738,57546,86848,76238,66945,71600,36136,96525,22965,73227,57209,76677,75946,68013,67915,93695,84944,140866,95108)
design4 <- c(87525,85458,69967,78628,50987,75734,56856,111047,132646,54189,94762,49209,38163,40042,97440,65811,117103,90774,106641,113264,65240,145625,73585,18345,77660,18045,84831,141808,62624,62583,46071,26759,89133,69834,22797,34974,86747,73046,91871,67384,95531,95374,77528,42291,24870,70152,73253,46145,94064,56200,110121,59713,141903,39915,11170,79569,69959,62308,43855,87563,77917,42056,66819,76900,69615,79550,50910,69513,54020,71256,93424,91259,76676,97087,68750,39110,66374,69093,93727,58509,77682,10121,17727,84362,60025,41049,103331,76090,81667,29803)


tider <- c(design1,design2,design3,design4)
design <- c(rep("design1",length(design1)),rep("design2",length(design2)),rep("design3",length(design3)),rep("design4",length(design4)))

Designs <- data.frame(design,tider)


WriteXLS("Designs", ExcelFileName = paste0(filnavn2,".xls"), SheetNames = arknavn,col.names = TRUE,row.names = F,AdjWidth = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
# done <- drop_upload(paste0(filnavn2,".xls"))
# dblink <- drop_share(paste0(filnavn2,".xls"),short_url = FALSE)$url

ano <- anova(lm(tider~design))
pv <- round(ano$`Pr(>F)`[1],4)
Ftest <- round(ano$`F value`,4)
SSA <- round(ano$`Sum Sq`[1],4)
SSW <- round(ano$`Sum Sq`[2],4)

```


Et forsikringsselskab har udviklet 4 forskellige layouts til information om skadesdækning. Brugerne udsættes vilkårligt for et af de 4 layouts, selskabet registrerer tiderne for besøgene på hjemmesiderne for at afgøre hvilket design, der er optimalt mht. brugervenlighed og overskuelighed.


<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/231384291' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>
Hent datasættet <a href="Hjemmesidedesigns besøgstider i millisekunder.xls" download>Hjemmesidedesigns besøgstider i millisekunder</a>, der viser de `r length(tider)` observede besøgstider på de 4 hjemmesider.

Forsikringsselskabet ønsker at undersøge om der er forskel på besøgstiderne, vi opstiller hypoteserne:

$$H_0:\mu_{Design 1}=\mu_{Design 2}=\mu_{Design 3}=\mu_{Design 4}$$$$H_1:Ikke\ alle\ middelvæ\ rdier\ er\ ens\ for\ de\ 4\ designs.$$

Freestat output
![](img/anova1.png)

Vi får en F-teststørrelse på `r Ftest[1]`, der resulterer i en p-værdi på `r pv`, hvilket er under signifikansniveauet på 0.05. Vi kan forkaster altså nulhypotesen om ens middelværdier.

Freestat output
![](img/anovaFtest.png)

Vi skal tjekke forudsætningen om varianshomogenitet

$$H_0:\sigma_{Design 1}=\sigma_{Design 2}=\sigma_{Design 3}=\sigma_{Design 4}$$$$H_1:Ikke\ alle\ varianser\ er\ ens\ for\ de\ 4\ designs.$$


Vi får en teststørrelse på `r bartlett.test(tider,design)[1]`. Chi i anden testet giver os en p-værdi på `r bartlett.test(tider,design)[3]`, hvilket er større end signifikanssandsynligheden på 0.05, vi kan ikke afvise nulhypotesen. Varianserne er ens, så forudsætningen er opfyldt.

Freestat output af Bartlett test for varianshomogenitet
![](img/Bartlett.png)

Normalitet

Herunder er 4 normalfraktildiagrammer, for de 4 designs, vi kan godt antage, stikprøverne stammer fra normalfordelte populationer.

```{r qqplots15_25, echo=FALSE ,fig.width=9, fig.height=9, dev='svg'}

library(gridExtra)

qqplot.data <- function (vec) # argument: vector of numbers
{
  # following four lines from base R's qqline()
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x <- qnorm(c(0.25, 0.75))
  slope <- diff(y)/diff(x)
  int <- y[1L] - slope * x[1L]
  d <- data.frame(resids = vec)
  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope, intercept = int)

}

qq1 <- qqplot.data(subset(Designs,design=="design1")[,2])+ labs(title = "Design 1 data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq2 <- qqplot.data(subset(Designs,design=="design2")[,2])+ labs(title = "Design 2 data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq3 <- qqplot.data(subset(Designs,design=="design3")[,2])+ labs(title = "Design 3 data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq4 <- qqplot.data(subset(Designs,design=="design4")[,2])+ labs(title = "Design 4 data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")


grid.arrange(qq1,qq2,qq3,qq4,nrow=2, ncol=2)
```

Tukey Kramer

Vi kan undersøge hvilke designs der har de største afvigelser ved at se på forskellene mellem stikprøvegennemsnittene, der er størst forskel mellem besøgstiderne for design 1 og design 4.

![](img/Tukeykramer.png)


Vi kan grafisk sammenligne middelværdierne i boxplots, her ser vi ligeledes forskellen er størst mellem design 1 og design 4. Middelværdierne er markeret med orange prikker.


```{r boxplots,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg"}
ggplot(data = Designs, aes(x=design, y=tider)) + geom_boxplot(aes(fill = design)) + ggtitle("Boxplots for de 4 designs")+
stat_summary(fun.y="mean", colour="orange", geom="point", shape=16, size=3)
```

```{r OMX-data ,echo=FALSE, warning=FALSE, include=FALSE}
filnavn <- "3 Banker Ugeafkast i procent"
library(quantmod)
companies <- c("DANSKE.CO","JYSK.CO","SYDB.CO")
test <- getSymbols(companies,from = "2014-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE)
DKkurs <- as.data.frame(cbind(weeklyReturn(DANSKE.CO[,6])  , weeklyReturn(JYSK.CO[,6]) ,weeklyReturn(SYDB.CO[,6])))
names(DKkurs) <- c("Danske Bank","Jyske Bank","Sydbank")
DKkurs[is.na(DKkurs)] <- 0 #Replace NA with 0
afkast <- DKkurs*100

uger <- length(afkast[,1])
afkastdf <- data.frame(bank <- c(rep("Danske Bank",uger),rep("Jyske Bank",uger),rep("Sydbank",uger)),ugeafkast <- c(afkast[,1],afkast[,2],afkast[,3]),datodf <- rep(row.names(afkast),3))
names(afkastdf) <- c("Bank","Ugeafkast","Dato")
WriteXLS("afkastdf", ExcelFileName = "3 Danske Banker Ugeafkast i procent.xls", col.names = TRUE,row.names = F,AdjWidth = TRUE, BoldHeaderRow = TRUE, FreezeRow = 1, FreezeCol = 1)
means <- c(mean(afkast[,1]),mean(afkast[,2]),mean(afkast[,3]))

DDBJYSKE <- abs(means[1]-means[2])
DDBSYD <- abs(means[1]-means[3])
JYSKESYD <- abs(means[2]-means[3])
ano <- anova(lm(ugeafkast~bank))
pv <- round(ano$`Pr(>F)`[1],4)
Ftest <- round(ano$`F value`,4)
SSA <- round(ano$`Sum Sq`[1],4)
SSW <- round(ano$`Sum Sq`[2],4)
```

<details>
  <summary>Spørgsmål 3 banker afkast</summary>




Hent datasættet <a href="3 Danske Banker Ugeafkast i procent.xls" download>3 Danske Banker Ugeafkast i procent</a>
, i dette datasæt er de seneste `r uger` ugers afkast i procent for hhv. Danske Bank, Jyske Bank og Sydbank. Er der signifikant forskel på afkastene på de 3 bankaktier?

</details>
<br>
<details>
  <summary>Svar 3 banker afkast</summary>
Vi opstiller hypoteserne for test af om middelværdierne er identiske:
$$H_0:\mu_{Danske Bank}=\mu_{Jyske Bank}=\mu_{Sydbank}$$$$H_1:Ikke\ alle\ middelvæ\ rdier\ er\ ens\ for\ de\ 3\ banker$$

Vi får variationen i grupperne SSW til `r SSW` og variationen mellem grupperne SSA til `r SSA`. Dette giver en F-teststørrelse på `r Ftest[1]` der resulterer i p-værdi på `r pv`. Vi kan altså ikke forkaste altså nulhypotesen om ens middelværdier.

Vi kan da se at de absolutte forskelle mellem stikprøvegennemsnittene er relativt små:

|Forskelle mellem Banker  | Absolutte forskelle |
|:------------------------ |:--------------|
|Danske Bank - Jyske Bank     |`r round2(DDBJYSKE,2)`|
|Danske Bank - Sydbank    |`r round2(DDBSYD,2)`|
|Jyske Bank - Sydbank         |`r round2(JYSKESYD,2)`|


Vi skal tjekke forudsætningen om varianshomogenitet

$$H_0:\sigma_{Danske Bank}=\sigma_{Jyske Bank}=\sigma_{Sydbank}$$$$H_1:Ikke\ alle\ varianser\ er\ ens\ for\ de\ 3\ banker.$$


Vi får en teststørrelse på `r bartlett.test(Ugeafkast~Bank,data=afkastdf)[1]`. Chi i anden testet giver os en p-værdi på `r bartlett.test(Ugeafkast~Bank,data=afkastdf)[3]`, hvilket er mindre end signifikanssandsynligheden på 0.05, vi afviser nulhypotesen. Varianserne er ikke ens, så forudsætningen er ikke opfyldt. Vi har således problemer med kvaliteten af analysen.

Normalitet

```{r qqplotbank, echo=FALSE ,fig.width=9, fig.height=3, dev='svg', warning=FALSE}
library(gridExtra)

qqplot.data <- function (vec) # argument: vector of numbers
{
  # following four lines from base R's qqline()
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x <- qnorm(c(0.25, 0.75))
  slope <- diff(y)/diff(x)
  int <- y[1L] - slope * x[1L]
  d <- data.frame(resids = vec)
  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope, intercept = int)
}

qq1 <- qqplot.data(subset(afkastdf,Bank=="Danske Bank")[,2])+ labs(title = "Danske Bank\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq2 <- qqplot.data(subset(afkastdf,Bank=="Jyske Bank")[,2])+ labs(title = "Jyske Bank\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq3 <- qqplot.data(subset(afkastdf,Bank=="Sydbank")[,2])+ labs(title = "Sydbank\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")

grid.arrange(qq1,qq2,qq3,nrow=1, ncol=3)
```

Vi kan grafisk sammenligne middelværdierne for ugeafkastet for de 3 banker i boxplots , her ser vi der ikke er stor forskel på middelværdierne. Middelværdierne er markeret med orange prikker.

```{r boxplotsbank,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg", warning=FALSE}
ggplot(data = afkastdf, aes(x=Bank, y=ugeafkast)) + geom_boxplot(aes(fill = Bank)) + ggtitle("Boxplots for ugeafkast for de 3 banker")+
stat_summary(fun.y="mean", colour="orange", geom="point", shape=16, size=3)
```
</details>
<br>
<details>
  <summary>Spørgsmål IMDB</summary>
```{r imdb  ,echo=FALSE, include=FALSE, warning=FALSE}
imdb <- import("IMDB stikprøve på 759 film.xls",sheet=1)
attach(imdb)
n <- nrow(imdb)
ano <- anova(lm(imdb$Rating~imdb$Genre))
pv <- round(ano$`Pr(>F)`[1],4)
Ftest <- round(ano$`F value`,4)
SSA <- round(ano$`Sum Sq`[1],4)
SSW <- round(ano$`Sum Sq`[2],4)
mact <- mean(as.numeric(subset(imdb,Genre=="action")$Rating))
mdoc <- mean(subset(imdb,Genre=="dokumentar")$Rating)
mdra <- mean(subset(imdb,Genre=="drama")$Rating)
mkom <- mean(subset(imdb,Genre=="komedie")$Rating)
mrom <- mean(subset(imdb,Genre=="romance")$Rating)
msho <- mean(subset(imdb,Genre=="short")$Rating)
```

<a href="IMDB stikprøve på 759 film.xls" download>Hent IMDB data</a>, der viser data for `r n` film simpelt tilfældigt udtrukket af en database med `r nrow(imdb)` film. Vi ønsker at se om, der er forskel på vurderingen af de forskellige genrer action, komedie, drama, documentar, romance og short, undersøg dette vha. ANOVA test

</details>
<br>
<details>
  <summary>Svar IMDB</summary>




Vi opstiller hypoteserne:

$$H_0:\mu_{action}=\mu_{komedie}=\mu_{drama}=\mu_{documentar}=\mu_{romance}=\mu_{short}$$$$H_1:Ikke\ alle\ middelvæ\ rdier\ er\ ens\ for\ de\ 5\ genrer.$$


Vi får en F-teststørrelse på `r Ftest[1]`, der resulterer i en meget lille p-værdi på `r pv`, hvilket er klart under signifikansniveauet på 0.05. Vi kan forkaster altså nulhypotesen om ens middelværdier.


Vi skal tjekke forudsætningen om varianshomogenitet

$$H_0:\sigma_{action}=\sigma_{komedie}=\sigma_{drama}=\sigma_{documentar}=\sigma_{romance}=\sigma_{short}$$$$H_1:Ikke\ alle\ standardafvigelser\ er\ ens\ for\ de\ 5\ genrer.$$

Vi får en teststørrelse på `r bartlett.test(imdb$Rating,imdb$Genre)[1]`. Chi i anden testet giver os en p-værdi på `r bartlett.test(imdb$Rating,imdb$Genre)[3]`.



Normalitet

Herunder er 5 normalfraktildiagrammer, for de 5 genrer, dokumentar og short genrerne ser ikke normalfordelte ud. Hvilket kan give problemer med kvaliteten i vor analyse.

```{r imdbqqplot, echo=FALSE ,fig.width=9, fig.height=9, dev='svg'}
library(gridExtra)

qqplot.data <- function (vec) # argument: vector of numbers
{
  # following four lines from base R's qqline()
  y <- quantile(vec[!is.na(vec)], c(0.25, 0.75))
  x <- qnorm(c(0.25, 0.75))
  slope <- diff(y)/diff(x)
  int <- y[1L] - slope * x[1L]
  d <- data.frame(resids = vec)
  ggplot(d, aes(sample = resids)) + stat_qq() + geom_abline(slope = slope, intercept = int)
}

qq1 <- qqplot.data(as.numeric(subset(imdb,Genre=="action")$Rating))+ labs(title = "Action genre data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq2 <- qqplot.data(as.numeric(subset(imdb,Genre=="komedie")$Rating))+ labs(title = "Komedie genre data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq3 <- qqplot.data(as.numeric(subset(imdb,Genre=="drama")$Rating))+ labs(title = "Drama genre data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq4 <- qqplot.data(as.numeric(subset(imdb,Genre=="dokumentar")$Rating))+ labs(title = "Dokumentar genre data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")
qq5 <- qqplot.data(as.numeric(subset(imdb,Genre=="short")$Rating))+ labs(title = "Short genre data\nnormalfraktildiagram",x="teoretiske fraktiler",y="Stikprøve fraktiler")



grid.arrange(qq1,qq2,qq3,qq4,qq5,nrow=2, ncol=3)
```

```{r boxplotsimdb,echo=FALSE,fig.width=9, fig.height=5 ,dev="svg"}
ggplot(data = imdb, aes(x=Genre, y=as.numeric(Rating))) + geom_boxplot(aes(fill = Genre)) + ggtitle("Boxplots ratings for de 5 genrer")+
stat_summary(fun.y="mean", colour="orange", geom="point", shape=16, size=3)

```

Vi kan ud fra boxplots se at dokumentarfilm rates højt i modsætning til actionfilm. Vi kan i tabellen herunder se hvor de største forskelle er mellem genrerne.

|Forskelle gennemsnit genrer  |Absolutte forskelle |
|:------------------------ |:--------------|
|Action - dokumentar     |`r abs(mact-mdoc)`|
|Action - drama     |`r abs(mact-mdra)`|
|Action - komedie     |`r abs(mact-mkom)`|
|Action - romance     |`r abs(mact-mrom)`|
|Action - short     |`r abs(mact-msho)`|
|Dokumentar - drama    |`r abs(mdoc-mdra)`|
|Dokumentar - komedie    |`r abs(mdoc-mkom)`|
|Dokumentar - romance    |`r abs(mdoc-mrom)`|
|Dokumentar - short    |`r abs(mdoc-msho)`|
|Drama - komedie     |`r abs(mdra-mkom)`|
|Drama - romance     |`r abs(mdra-mrom)`|
|Drama - short     |`r abs(mdra-msho)`|
|Komedie - romance    |`r abs(mkom-mrom)`|
|Komedie - short    |`r abs(mkom-msho)`|
|Romance - short    |`r abs(mrom-msho)`|
</details>

## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=64" target="_blank">Selvtest Anova analyse Realkredit med videoløsninger</a></h2>
## Selvtest
<h2><a href="https://www.edutest.dk/mod/quiz/view.php?id=82" target="_blank">Selvtest Anova analyse Aktier med videoløsninger</a></h2>

# Cran R



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->






Vi bruger software programmet R da det er gratis og kan bruges til alt indenfor statistik, det er svært i begyndelsen, så sørg for at komme til timerne :O)

Der er et hav af videoer på youtube og hjælpesider fx.



https://youtu.be/cX532N_XLIs?list=PLqzoL9-eJTNBDdKgJgJzaQcY6OXmsXAHU

https://youtu.be/UYclmg1_KLk?list=PLqzoL9-eJTNBDdKgJgJzaQcY6OXmsXAHU

https://youtu.be/2TcPAZOyV0U?list=PLqzoL9-eJTNBDdKgJgJzaQcY6OXmsXAHU

https://youtu.be/qPk0YEKhqB8?list=PLqzoL9-eJTNBDdKgJgJzaQcY6OXmsXAHU

https://youtu.be/3RWb5U3X-T8?list=PLqzoL9-eJTNBDdKgJgJzaQcY6OXmsXAHU

https://www.datacamp.com/courses/free-introduction-to-r

https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf

http://dss.princeton.edu/training/RStudio101.pdf

https://youtu.be/uwlwNRbaKMI


## R video-tutorials

Herunder er 3 begynder videotutorials forsøg at gøre det samme som i videoerne. Du kan downloade scripts fra hver tutorial direkte under hver videovindue.

<br>
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/291538428' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>




<a href="fil1.R" download="fil1.R">Hent r script klik her.</a>

<br>
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/291538548' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>
<a href="fil2.R" download="fil1.R">Hent r script klik her.</a>

<br>
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/291542840' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

<a href="fil1.R" download="fil3.R">Hent r script klik her.</a>




# Faktoranalyse



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->






<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292365661' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

Faktoranalyse FA er ligesom, klyngeanalyse vi ser på senere, en strukturanalyse, der belyser hvilke sammenhænge der er i et datasæt. FA er en statistikmodel der navnlig bruges til at forenkle tolkningen af et datamateriale, der indeholder en stor mængde variable. FA bygger på et kæmpe antal udregninger med udgangspunkt i korrelationskoefficienter og er i praksis nærmest umulig at gennemføre uden brug af computersoftware. Før computerens opfindelse kunne en faktoranalyse nemt lægge beslag på en halv snes statistikere på fuld tid gennem flere måneder. Resultatet ville være identifikation få faktorer, skjult i et datamateriale.

Faktoranalysen kan fx. hjælpe med at vise sammenhænge mellem svar i spørgeskemaer, hvilket kan være en hjælp markedsføringsmæssigt, til at forstå hvilke svar samvarierer. En sådan gruppering af spørgsmål kan hjælpe med bedre at forstå kundernes ønsker og behov. Faktoranalyse FA er et  godt værktøj til at forstå, hvad dine spørgeskemadata betyder, især når du har mange variable. Faktoranalysen forsøger at finde skjulte variable, som forklarer opførslen af dine observerede variable. FA har historiske rødder i psykometri, dvs målingen af mentale egenskaber.

I modsætning hertil søger man med Klyngeanalysen at finde sammenhænge mellem respondenterne/observationerne og altså ikke variablene, hvilket er et godt hjælpeværktøj i forbindelse med markedssegmentering.

Der findes 2 typer af FA Exploratory Factor Analysis (EFA) og Confirmatory Factor Analysis (CFA). EFA betyder, at du ikke rigtig ved, hvilke skjulte variable (eller faktorer) der findes, og hvor mange de er, så du forsøger at finde dem. CFA betyder, at du allerede har nogle gæt eller modeller på  skjulte variable (eller faktorer), og vi vil kontrollere, om dette er korrekt. Vi benytter i det følgende EFA

## Hvilke faktorer er vigtige når man køber en ny computer:

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292365603' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

Lad os sige, man har indsamlet et spørgeskema for at undersøge, hvad der er vigtigt, når en forbruger bestemmer, hvilken computer der skal købes. Spørgeskemaet er udformet, som hvor vigtig er Pris for computerkøbet, vægt fra 1 til 7 hvor 7 er højest/vigtigst.


Dette datasæt er lille i forhold til, hvad der er realistisk, da vi blot forsøger at illustrere analysen. Normalt vil man have flere end 6 variable. For at sikre solide analyseresultater, vil man ligeledes have flere respondenter/observationer.

I noterne er input til R og output fra R, markeret i grå rammer. Output dvs. resultaterne R leverer er markeret med ## i hver linje. Input dvs. de kommandoer vi skal skrive ind i R er ikke markeret.

Rammen herunder er input til R, da linjerne ikke er markeret. Læs datasættet ind i R, dette kan du gøre ved at copy paste nedenstående kode, i den grå ramme, direkte ind i R enten i console eller et script.

Bemærk data.frame er en to-dimensionel data struktur, nedenstående betyder vore 6 variable nu er lagret i en dataframe.

```{r eval=FALSE}
Pris <- c(6,7,6,5,7,6,5,6,3,1,2,5,2,3,1,2)
Software <- c(5,3,4,7,7,4,7,5,5,3,6,7,4,5,6,3)
Æstetik <- c(3,2,4,1,5,2,2,4,6,7,6,7,5,6,5,7)
Brand <- c(4,2,5,3,5,3,1,4,7,5,7,6,6,5,5,7)
Venner <- c(7,2,5,6,2,4,1,7,3,2,6,7,6,2,4,5)
Familie <- c(6,3,4,7,1,5,4,5,4,4,5,7,2,3,5,6)

data <- data.frame(Pris, Software, Æstetik, Brand, Venner, Familie)
```

## Forudsætninger for faktoranalysen.

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292365022' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

Nu skal vi undersøge om det er fornuftigt at foretage en faktoranalyse, dette kan vi undersøge ved enten Bartletts korrelationstest eller Kaiser-Meyer-Olkin KMO.

For at teste dette skal man installere og loade pakken psych, vi skal kun installere første gang. Bemærk install.packages("psych") er kommenteret ud nedenfor, så første gang skal du kommentere install.packages("psych") ud.

```{r eval=FALSE}
#install.packages("psych")
library("psych")
```

Du kan alternativt benytte pacman pakken, hvilket ofte er at foretrække. Hvis du indlæser nedenstående installeres og loades pakken psych:

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(psych)
```

Nu hvor psych pakken er indlæst kan vi køre Bartletts test i R:

```{r warning=FALSE, message=FALSE}
cortest.bartlett(data)
```

Nulhypotesen i Bartletts test er at variablene ikke er korrelerede dvs. alle korrelationskoefficienter $\rho=0$,

$$H_0:Alle\ \rho=0$$
$$H_1:Ikke\ alle\ \rho=0  $$

Forkaster vi nulhypotesen, er der basis for at gennemføre faktoranalysen. Den lille p-værdi på 0.00167791, betyder vi gennemfører faktoranalysen.

Vi kan ligeledes køre Kaiser-Meyer-Olkin KMO testet fra pshych pakken:

```{r}
KMO(data)
```


For KMO skal Overall MSA =  0.49, fortæller om egnethed af data til faktoranalyse. Skal være større end kritisk grænse på ca. 0.5, dette er ikke helt tilfældet her, men vi gennemfører alligevel faktoranalysen.

Vi kan se af korrelationsmatricen, at nogle variable er korrellerede og andre tilsyneladende ikke.

```{r}
cor(data)
```

Så det ser ud til, at Pris har stærke negative sammenhænge med Æstetik og Brand.
Venner har en stærk positiv sammenhæng med Familie.

Det betyder, at vi kan forvente, at vi vil have to fælles faktorer, og en vil være relateret til pris, æstetik og brand, og den anden vil være relateret til ven og familie. Vi kan lave et corrplot, der grafisk illustrerer disse sammenhænge, store blå prikker er positiv korrelation, store røde negativ korrelation. Så vi skal installere corplott pakken, her bruger vi pacman til installationen.

```{r corrplot, dev='svg'}
pacman::p_load(corrplot)
corrplot(cor(data), order = "hclust", tl.col='black', tl.cex=.5)
```


## Selve Faktoranalysen

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292365273' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

Vi er nu klar til at teste om der er grundlag for at sammenlægge variable til faktorer. Dette tester vi i selve faktor analysen, ved hjælp af funktionen factanal.

Hvis vi samler alle spørgsmål til en samlet faktor, har vi følgende faktor analyse:

```{r}
fa1 <- factanal(data, factor=1)
fa1
```

**Uniqueness** angiver hvor meget af variationen i en variabel, der ikke er associeret med faktoren. Jo lavere Uniqueness, des større sammenhæng til faktorerne.

**Loadings** angiver hvordan hver variabel er vægtet for faktorerne, men også hvor stærk korrelationen er til hver faktor. Faktor 1 påvirkes således mest af Æstetik, Brand og Pris. Denne faktor kan ses af corrplottet hvor disse tre variable ses at påvirke hinanden, Pris er negativt korreleret med Æstetik og Brand.

**Proportion Var** er et vigtigt nøgletal, der angiver andelen af variationen i data, der er forklaret af den pågældende faktor. Her forklares alså kun 36.5% af variationen i datasættet. Proportion Var findes som SS loadings divideret med antallet af variable dvs. her 6.

Lad os se på hvad der sker, hvis vi deler variablene op i 2 faktorer:

```{r}
fa2 <- factanal(data, factor=2)
fa2
```

**Cumulative Var** 0.61 er summen af proportion var 0.368 og 0.242, og betyder at faktor 1 og faktor 2 forklarer 61% af variationen i datamaterialet.

Faktor 2 forklares altså primært af Venner og Familie, dette stemmer godt overens med billedet vi så i corrplot.

Nu opdeler vi variablene i 3 faktorer.

```{r}
fa3 <- factanal(data, factor=3)
fa3
```

Nu forklares 70.5% af variationen i datamaterialet altså ud fra de 3 faktorer.

## Hvor mange faktorer bør benyttes?

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292365468' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>


Der er ingen fast regel for hvor mange faktorer der bør benyttes. Der er flere forskelle metoder til bestemmelse af antallet af faktorer, vi viser herunder 2 metoder.

### Eigenvalues metoden

Eigenvalues udtrykker hvor meget af datamaterialets samlede varians, der dækkes af den pågældende faktor. Eigenvalues er standardiserede således at summen giver antallet af variable, herunder ses at summen er 6, da der er 6 variable i datasættet. Vi ser hvor stor en del af variationen hver faktor forklarer, når der er 6 faktorer. Faktor 5 og faktor 6 bibringer meget lidt yderligere forklaring af variationen.

```{r}
ev <- eigen(cor(data))
ev$values
sum(ev$values)
ev$values/sum(ev$values)
```

Når vi benytter Eigenvalues metoden, bestemmes antallet af faktorer ud fra  antallet af Eigenvalues større end 1, det er denne metode fx. SPSS benytter. Vi ser at kun 2 Eigenvalues er 2.45701130 og 1.68900056 er større end 1, vi får således kun 2 faktorer. Eigenvalues metoden er ofte lidt konservativ, således at vi får færre faktorer end med de øvrige metoder.

### Screeplot metoden

Vi kan se på nedenstående screeplot, der hvor kurven flader ud, bibringer yderligere faktorer ikke synderlig megen yderligere forklaring til modellen. Man vil med screeplot kriteriet, vælge antallet af faktorer hvor kurven knækkker i tilfældet med 3 faktorer. Man vil ikke altid entydigt kunne afgøre hvor screeplot kurven knækker, her må man så afgøre dette bedst muligt.

```{r, dev='svg'}
screeplot(princomp(data),type="line",npcs = 6, main="Screeplot Computereksempel")
```


<br>
<details>
  <summary>Spørgsmål personality Stanford</summary>
Hent nu filen personality, hvor 240 Stanford studerende har svaret på i hvor høj grad de mener at besidde 32 forskellige personlighedstræk. 1 til 8 hvor 1 er mindst og 8 er mest. Foretag hvis en test viser dette er fordelagtigt en faktoranalyse.

Download personality fra filen <a href="personality.xlsx" download>her</a> og importer den i R via File - Import Dataset.


</details>
<br>
<details>
  <summary>Svar personality Stanford</summary>

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292364790' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>


```{r echo=FALSE, warning=FALSE}
pacman::p_load(readxl)
personality <- read_excel("personality.xlsx")
```

```{r}
pacman::p_load(psych)
cortest.bartlett(personality)
KMO(personality)
```

Vi gennemfører klart analysen viser begge tests.

```{r, dev='svg'}
#cor(personality) korrelationsmatricen er udeladt af pladshensyn.
corrplot(cor(personality), order = "hclust", tl.col='black', tl.cex=.5)
```

```{r, dev='svg'}
screeplot(princomp(personality),type="line", main="Screeplot personality")
```


```{r}
evp <- eigen(cor(personality))
evp$values
```

Vi benytter her 7 faktorer:

```{r}
fapers7 <- factanal(personality,7)
fapers7
```


Vi benytter her 8 faktorer:

```{r}
fapers8 <- factanal(personality,8)
fapers8
```

</details>
<br>
<details>
  <summary>Spørgsmål Mediedata</summary>

Download filen om mediedata <a href="mediedata.xlsx" download>her</a>. Importer denne i R, husk under importen at vælge det korrekte sheet, der indeholder data.

Datasættet omhandler danskernes medievaner, 324 danskere er blevet spurgt om deres medievaner. Datasættet indeholder følgende 11 variable.


**TV-kigning**
samlet	Antal minutter pr. dag.

**Radiolytning**
Samlet	Antal minutter pr. dag.

**Avislæsning**
Samlet	Antal minutter pr. dag.

**TV-kigning**
Nyheder	Antal minutter pr. dag. "Nyheder" omfatter "Nyheder, politik og aktuelt"

**Radiolytning**
Nyheder	Antal minutter pr. dag. "Nyheder" omfatter "Nyheder, politik og aktuelt"

**Avislæsning**
Nyheder	Antal minutter pr. dag. "Nyheder" omfatter "Nyheder, politik og aktuelt"

**Internetforbrug**
0 Ingen internetadgang hjemme eller på arbejde
1 Bruger aldrig
2 Mindre end en gang om måneden
3 En gang om måneden
4 Flere gange om måneden
5 En gang om ugen
6 Flere gange om ugen
7 Hver dag


**Alder**
Alder i år


**Højest fuldførte uddannelse	**
1 Folkeskole 6.-8. klasse
2 Folkeskole 9.-10. klasse
3 Gymnasielle uddannelser, studentereksamen, HF, HHX, HTX
4 Kort erhvervsudd. under 1-2 års varighed, F.eks AMU Arbejdsmarkedsudd., Basisår Erhvervsfaglige udd.
5 Faglig udd. (håndværk, handel, landbrug mv.), F.eks. Faglærte, Social- og sundhedsassistent-udd. og tilsvarende
6 Kort videreg. udd af op til 2-3 år, F.eks. Erhv.akademi, datamatiker, tandplejer, byggetekniker, installatør, HD
7 Mellemlang videreg.udd. 3-4 år. Prof.bachelorer, F.eks. Diploming, sygeplejerske, skolelærer, pædagog, journalist, HA
8 Universitetsbachelor. 1. del af kandidatuddannelse
9 Lang videregående uddannelse. Kandidatuddannelser af 5.-6. års varighed, F.eks. Cand.mag., cand.jur., cand.polyt. etc.
10 Forskeruddannelse. Ph.d., doktor

**Kvindedummy**
Dummy variabel kodet med kvinde=1, mand=0

**Hjemmeboendebørndummy**
Dummy variabel kodet med Ja=1, Nej=0

Gennemfør en faktor analyse på datasættet.

</details>
<br>
<details>
  <summary>Spørgsmål Genderroles</summary>

Download filen genderroles <a href="genderroles.xlsx" download>her</a> og importer den i R via File - Import Dataset.
Pas på variablene skal konverteres til dummy variable, hvor det giver mening. Man bør nok udelade  variablen Region, ellers skal den ændres til et passende antal dummy variable.

Gennemfør en faktor analyse på datasættet.

</details>
<br>
<details>
  <summary>Spørgsmål Valgfri datasæt</summary>
  Find et valgfrit datasæt fx. på nettet, gennemfør en faktoranalyse på dette datasæt.
</details>
<br>


# Klyngeanalyse



<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->



<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292611639' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```





Vi har et datasæt bestående af 32 bilmodeller med 11 variable:

1.	mpg	Miles/(US) gallon
2.	cyl	Number of cylinders
3.	disp	Displacement (cu.in.)
4.	hp	Gross horsepower
5.	drat	Rear axle ratio
6.	wt	Weight (1000 lbs)
7.	qsec	1/4 mile time
8.	vs	Engine (0 = V-shaped, 1 = straight)
9.	am	Transmission (0 = automatic, 1 = manual)
10.	gear	Number of forward gears
11.	carb	Number of carburetors

Vi vil gerne gruppere de forskellige bilmodeller i forskellige grupper eller klynger udfra deres specifikationer. For at undersøge, om vi på baggrund af tekniske karakteristika, kan gruppere bilmodellerne, benytter vi klyngeanalyse. Bemærk i faktoranalysen grupperer vi variablene, i klyngeanalysen grupperer vi respondenterne eller observationerne, her altså bilerne.

Der findes overordnet 2 typer af klyngeudvælgelse:

***Ikke-hierarkisk, k-means metoden*** benyttes, hvis vi har store datasæt hvor der kræves mange observationer, man vælger på forhånd hvor mange klynger man vil have.

***Hierarkisk klyngedannelse, agglomerative metode*** hvor man starter med at hver respondent har sin egen klynge og man derefter sammenhober disse trin for trin kaldes den sammenhobede eller agglomerative metode. Vi benytter til bildatasættet den agglomerative metode, da vi ikke har en stort datasæt, er denne klart at foretrække.


```{r}
pacman::p_load("datasets")#Vi henter pakken datasets der indeholder en del datasæt
head(mtcars) #Vi kan se starten af datasættet med Head kommandoen
```

Vi kan se at når vi sammenligner forskellige variable ser det ud til at der er forskellige grupper. Nedenfor ser vi fx de 32 biler plottet i et diagram efter hestekræfter og miles per gallon. Bilerne er farvekodet med antal cylindre.

```{r}
#Her angiver vi modelnavne for hver bil
#med label rownames vi bruger geom_text i stedet for point her.
pacman::p_load("ggplot2")
ggplot(mtcars, aes(hp, mpg, color = cyl)) +
  geom_point() #Plot med kun punkter
ggplot(mtcars, aes(hp, mpg, color = cyl,label=rownames(mtcars)))+
  geom_text(size=3,check_overlap = TRUE)
```

Vi kan benytte t til at transponere data matricen, så kan vi tegne et corrplot, det er meget mørkt da alle bilerne er positivt korrelerede, men man kan ane nogle sammenhænge. t(mtcars) betyder vi transponerer (vender) matricen, så ser vi i stedet på grupper af respondenter, som vi netop analyserer i klyngeanalysen. Hvis ikke vi vender matricen ser vi på korrelationsmatricen mellem de 11 variable i stedet, ligesom vi tidligere har gjort med faktoranalysen.

```{r, dev='svg'}
#korrelationsmatricen for transponeret mtcars data, hclust betyder vi ordner efter variable der passer sammen
pacman::p_load(corrplot)
corrplot(cor(t(mtcars)), order = "hclust", tl.col='black', tl.cex=.5)
```

```{r}
#Her er korrelationsmatricen ikke transponeret, hvilket svarer til en matrice baseret på variable som ved faktoranalysen vi tidligere så på.
corrplot(cor(mtcars), order = "hclust", tl.col='black', tl.cex=.5)
```

## Hierakisk klyngeanalyse hclust kommandoen

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292611307' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

Vi får nu R til at danne klynger vha. af hclust (hierarcical cluster) kommandoen, denne benytter default en metode der hedder complete til at finde ens klynger, der findes mange andre metoder. For at benytte hclust skal R først beregne afstandene mellem bilerne dette gøres med dist kommandoen. Algoritmen beregner afstandene mellem de forskellige bilmodeller vha. af den euklidiske metrik. Biler med kort afstand kommer i klynger sammen, biler med lang afstand kommer i forskellige klynger.

Nedenfor ses et udsnit af afstandende mellem hver af de 32 biler, det er en meget stor 32 $\times$ 32 matrice, derfor har vi benyttet head for kun at vise noget af matricen. Fx er afstanden mellem to forskellige biler som en Mazda RX4 og en Lincoln Continental 318.05 hvilket er en stor afstand i forhold til fx. Mazda RX4 og Mazda RX4 Wag på kun 0.62. Bemærk hvordan supersportsvognen Maserati Bora har store afstande til de fleste af de øvrige biler, Maseratien var en komfortabel, rummeligere og kraftigere og tungere sportsvogn end fx. Ferrari Dino.


```{r, dev='svg'}
head(as.matrix(dist(mtcars)))
```

Vi gemmer hclust data i clusters variablen, vi så kan benytte til at tegne en oversigt over klyngerne.
Vi kan nu plotte en grafisk oversigt over bilerne. I nederste linje er den fineste inddeling, hvor samtlige biler er i deres egen klynge. Den blå linje med 3 skæringer i dendogrammet indikerer der er 3 klynger, den røde 4 klynger.

```{r, dev='svg'}
clusters <- hclust(dist(mtcars))
plot(clusters,cex=0.5,main = "Dendogram af mtcars",xlab = "Klyngetræ",sub="Bilmodeller")
abline(h = 190, col="red") #Tegn rød vandret linje h betyder horisontal
abline(h = 230, col="blue")
```

Hvis vi ønsker at undersøge en indeling med et bestemt antal klynger, kan vi bruge cutree i R, til at undersøge klyngerne i en skæring med fx. 4 klynger nærmere. Her ser vi som nævnt, Maserati Bora skiller sig ud ved at have sin egen klynge. Nummeret ved hver af de 32 biler angiver hvilken klynge bilen tilhører.

```{r, dev='svg'}
clusterCut <- cutree(clusters, 4) #Opdeling i 4 klynger.
clusterCut
```

Vi kan benytte subset kommandoen til at se på hvilke variable der er i hver klynge, herunder ser vi på klynge 3.

```{r, dev='svg'}
subset(clusterCut,clusterCut==3)
```


Vi kan ligeledes sammenligne klyngeinddelingen med de enkelte variable og se om disse passer sammen. Fx. passer hp meget fint med inddelingen i klynger.

```{r}
table(clusterCut, mtcars$cyl)
table(clusterCut, mtcars$mpg)
table(clusterCut, mtcars$hp)
table(clusterCut, mtcars$carb)
table(clusterCut, mtcars$wt)
```

Hvis dendogrammet virker lidt uoverskueligt, kan man vælge ape pakken for at lave mere fancy plots, her er rigtig mange muligheder.

```{r, warning=FALSE, dev='svg'}
#install.packages("ape")
library("ape")
colors = c("red", "blue", "green", "pink")
clus4 = cutree(clusters, 4)
plot(as.phylo(clusters), type = "fan", tip.color = colors[clus4],
     label.offset = 0, cex = 0.5)
```

Herunder er et plot, hvor farvekoden er baseret på klyngerne.
```{r, dev='svg'}
ggplot(mtcars, aes(hp, mpg)) +
  geom_point(alpha = 0.4, size = 3.5) + geom_point(col = clusterCut)
```

## Ikke hierakisk klyngeanalyse kmeans kommandoen

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292611226' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

Vi kunne også have brugt kmeans metoden, her skal vi så angive hvor mange klynger, vi ønsker i analysen. Her benytter vi K-means og får 4 klynger med 7, 6, 9, 10 biler. I output fra R kan vi under Cluster means se gennemsnit, for de 4 klynger for alle 11 variable.

```{r, dev='svg'}
mtcarsCluster4 <- kmeans(mtcars, 4)
mtcarsCluster4
```

Nedenfor ser vi på en tabel inddeling med 4 klynger med de 32 biler, sorteret efter antallet af cylindre.

```{r}
table(mtcarsCluster4$cluster, mtcars$cyl)
```


Nedenfor ser vi på en tabel inddeling med 3 klynger med de 32 biler, sorteret efter antallet af cylindre. Kører vi kmeans analysen igen, falder bilerne ikke nødvendigvis i samme klynger som tidligere, det skyldes algoritmen kan give forskellig optimale inddelinger.

```{r, dev='svg'}
mtcarsCluster3 <- kmeans(mtcars, 3)
table(mtcarsCluster3$cluster, mtcars$cyl)
```


Vi kan lave et klyngeplot der viser forskellene på de 32 biler, herunder ses plottet med 3 klynger. Bemærk vi skal hente pakken **factoextra**, der indeholder plotfunktionen fviz_cluster(). Vi har benyttet funktionen **scale()**, det er en rigtig god ide at benytte hvis, der er stor forskel på måleenhederne i en data.frame. Funktionen **scale()** bringer variablene i samme skale. Der er fx. stor forskel på enhederne i carb og disp, prøv at sammenligne nedenstående plot med et tilsvarende plot uden scale.

```{r, dev='svg'}
km3.res <- kmeans(scale(mtcars), 3, nstart = 25)
pacman::p_load(factoextra)
fviz_cluster(km3.res, data = mtcars, main = "Klyngeplot biler opdelt i 3 klynger",repel = TRUE)
```


Vi kan lave et klyngeplot der viser forskellene på de 32 biler, herunder ses plottet med 4 klynger.

```{r, dev='svg'}
km4.res <- kmeans(scale(mtcars), 4, nstart = 25)
fviz_cluster(km4.res, data = mtcars, main = "Klyngeplot biler opdelt i 4 klynger",repel = TRUE)
```
Vi kan lave et klyngeplot der viser forskellene på de 32 biler, herunder ses plottet med 5 klynger.

```{r, dev='svg'}
km5.res <- kmeans(scale(mtcars), 5, nstart = 25)
fviz_cluster(km5.res, data = mtcars, main = "Klyngeplot biler opdelt i 5 klynger",repel = TRUE)
```


## Validering med ANOVA

Skal man undersøge om grupperne/klyngerne er forskellige med hensyn til de forskellige variable, kan man benytte Anova, hvor klyngerne er den uafhængige variabel. Man skal da gerne nå frem til at klyngegennemsnittede er signifikant forskellige mht. flere af variablene der indgår i analysen.

<!-- Undersøg om der er forskel på hestekræfter hp i de 5 klynger dannet af kmeans analysen hvis du vil gennemføre Anova analysen i Freestat skal du eksportere datasættet.   -->
<!-- Du kan benytte kmeans og export (rio pakken) kommandoerne   -->
<!-- Man kan danne en kvalitativ variabel med fx. 3 klynger med kmeans kommandoen   -->
<!-- Og klistre den på kmeansdatasættet med cbind kommandoen, desværre driller rio pakken på mange windows maskiner. -->



<!-- ```{r} -->
<!-- # install.packages("rio") -->
<!-- library(rio) -->
<!-- mtcarsklynge <- as.data.frame(cbind(kmeans(mtcars,3)$cluster,mtcars$hp)) -->
<!-- export(mtcarsklynge,"mtcarsklynge.xlsx") -->
<!-- ``` -->

<!-- <!-- Der er små forskelle i p-værdierne mellem Freestat og R Anova testet da algoritmerne beregner efter lidt forskellige metoder. -->

<!-- # ```{r} -->
<!-- # anova(lm(mtcarsklynge$V2 ~ mtcarsklynge$V1,data=mtcarsklynge)) -->
<!-- <!-- ``` -->

<details>
  <summary>Spørgsmål US arrestationer samt urbaniseringsgrad</summary>

Lav en klyngeanalyse for datasæt med 50 observationer for amerikanske stater på 4 variable, data stammer fra World Almanac and Book of facts 1975. (Crime rates).

1.	Mord, antal arrestationer (pr 100,000)
2.	Overfald, antal arrestationer (pr 100,000)
3.	Urbaniseringsgrad	andel af bybefolkning.
4.	Voldtægt, antal arrestationer (pr 100,000)

```{r}
pacman::p_load(datasets)
arrest <- USArrests
head(arrest)
```

Undersøg om der kan dannes klynger og hvorledes disse kan karakteriseres. Illustrer grafisk og kommenter på karakteristika for klyngerne.

</details>
<br>
<details>
  <summary>Svar US arrestationer samt urbaniseringsgrad kort version</summary>
  <style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/292611431' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
</details>
<br>
<details>
  <summary>Spørgsmål GDP</summary>

Download filen om GDP og GDP per capita <a href="GDP.xlsx" download>her</a>. Importer denne i R. Sørg for at få navnene for de enkelte lande som label, dette kan du fx. gøre ved nedenstående kommandoer:

Hvad betyder:
GDP[1:50,]
og
GDP[,1]

```{r, eval=FALSE, warning=F, message=F, results=F}
GDP <- GDP[1:50,]
row.names(GDP) <- as.matrix(GDP[,1])

plot(clusters,cex=0.5,main = "GDP",xlab = "Klyngetræ",sub="GDP")
```


Undersøg om der kan dannes klynger og hvorledes disse kan karakteriseres, der er rigtig mange observationer dvs. lande, se i stedet på deldatasæt der giver mening. Illustrer grafisk og kommenter på karakteristika for klyngerne.
</details>
<br>
<details>
  <summary>Spørgsmål Forbes 100 US</summary>

Download filen om de 100 rigeste i USA  <a href="Forbes100.xlsx" download>her</a>. Filen er tilrettet, dvs. binære kvalitative variable er kodet om til dummy variable.

Undersøg om der kan dannes klynger og hvorledes disse kan karakteriseres. Illustrer grafisk og kommenter på karakteristika for klyngerne.

Bemærk det er godt at sætte navnene på de velhavende som rækkenavne i din data.frame, for at det er nemmere at få et overblik i klyngetræ diagrammet, dette kan du fx. gøre som nedenfor:

```{r, eval=FALSE, warning=F, message=F, results=F}
row.names(Forbes100) <- as.matrix(Forbes100[,1])
clusters <- hclust(dist(Forbes100))
plot(clusters,cex=0.5,main = "US 100 Rigeste",xlab = "Klyngetræ",sub="US top 100")
```
</details>
<br>
<details>
  <summary>Spørgsmål Valgfri datasæt</summary>
  Find et valgfrit datasæt fx. på nettet, gennemfør en klyngeanalyse på dette datasæt.
</details>
<br>




# Tidsrækker og ARIMA


<!-- BEGIN PROTECT-->
<meta name="robots" content="noindex, nofollow">
<META HTTP-EQUIV="CACHE-CONTROL" CONTENT="NO-CACHE">
<style>
.Sentry_blanket {
background-color:#FFFFFF;
position:absolute;
z-index: 9001; /*ooveeerrrr nine thoussaaaannnd*/
top:0px;
left:0px;
width:105%;
height:10000px;
padding:20px;
}
</style>
<script language="JavaScript" type="text/JavaScript">
/* BEGIN Editable Settings: ///////////////////////////////////////////////////////////*/
PpLID = "38855,36811,36812, 39445"; /* Makes this page viewable by only members of one or more PayPal plans, enter one Ppl ID or more than one separated by commas */
pageLevel = 0; /* Access Level required to view this page   */
SingleOut = 0; /* Makes this page viewable by only one member, enter their account number  */
/* END Editable Settings: ////////////////////////////////////////////////////////////*/
Sentry_ID = 22367;
</script>
<script type="text/javascript" src="https://www.sentrylogin.com/sentry/scripts/Sentry_pAJAX.js"></script>
<noscript>
<meta http-equiv="refresh" content="0; url=https://www.sentrylogin.com/sentry/noscript.asp">
</noscript>
<div id="Sentry_noJS" class="Sentry_blanket">Sentry Page Protection</div>
<div id="Sentry_redirecting" class="Sentry_blanket" style="display:none;">Please Wait...</div>
<script language="JavaScript" type="text/JavaScript">
if(window.onload){
  window.onload = SentryProtect;
}
else if(document.body.onload){
  document.body.onload = SentryProtect;
}
else{
  SentryProtect(); /* call it here  */
}
</script>
<!-- END PROTECT -->






```{r setup1, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r , include=FALSE, warning=FALSE}
# ts.sim3 <-round(arima.sim(list(order = c(0,0,0)), n = 50)*2+20,2)
# ts.plot(ts.sim3,ylab="Aktiekurs",xlab="Tid")
# auto.arima(ts.sim3)
# require(openxlsx)
# library(forecast)
# t3 <- as.matrix(ts.sim3)
# colnames(t3) <- "Dagskurs"
# hs <- createStyle(textDecoration = "BOLD", fontColour = "#FFFFFF", fontSize=12,
#                   fontName="Arial Narrow", fgFill = "#4F80BD")
# write.xlsx(t3, file = "ARIMA1.xlsx", colNames = TRUE,sheetName="Aktiekurs",colNames = TRUE,headerStyle = hs)
library(readxl)
ARIMA1 <- read_excel("ARIMA1.xlsx")
ARIMA2 <- read_excel("ARIMA2.xlsx")
ARIMA22 <- read_excel("ARIMA22.xlsx")
ARIMA23 <- read_excel("ARIMA23.xlsx")
ARIMA3 <- read_excel("ARIMA3.xlsx")
ARIMA4 <- read_excel("ARIMA4.xlsx")
```

Gennemgangen af tidsrækkeanalyse bygger meget på praktisk anvendelighed (dvs. vi vil gerne kunne forudsige kursudviklingen), vi vil springe let hen over teorien der kan være tung og er meget omfattende. Nedenstående links giver dog en indføring i den teoretiske del, som vi her ikke berører.

http://ucanalytics.com/blogs/arima-models-manufacturing-case-study-example-part-3/

http://ucanalytics.com/blogs/step-by-step-graphic-guide-to-forecasting-through-arima-modeling-in-r-manufacturing-case-study-example/

Her er en gennemgang af forskellige typer af tidsrækker man kan opleve.

https://people.duke.edu/~rnau/411arim.htm#arima010

Video om ARIMA
https://youtu.be/Aw77aMLj9uM



En tidsrække er observationer, der er observeret over tid, fx. lukkekursen på Novo i 2018, kan vi beskrive som en tidsrække. Hvor vi både registrerer dato og lukkekursen. ARIMA er et avanceret analyseværktøj til at beskrive tidsrækker. Vi vil i de følgende kaptiler, med eksempler beskrive hvordan de enkelte elementer i ARIMA rent praktisk fungerer.

***AR*** står for AutoRegressive
***I*** står for Integrated
***MA*** står for Moving Average

Lad i de følgende afsnit se på nogle simple eksempler for trinvis, at kunne beskrive hvorledes modellen fungerer.

## ARIMA(0,0,0)

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/293712878' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>


Nedenfor har vi aktiekurser for 50 dage for en fiktiv aktie, vi vil nu undersøge om disse kan bruges til at forudsige noget om fremtidige aktiekurser. For at gøre dette, skal man enten importere Excelfilen, eller copy paste data fra rammen nedenfor.

Hent ARIMA1.xlsx Excel filen <a href="ARIMA1.xlsx" download>her</a>. Importer ARIMA1.xlsx til R via menuen File - Import Dataset - Excel. Nu skal datasættet rettes til en tidsserie med ts() kommandoen.

```{r warning=FALSE}
ARIMA1 <- ts(ARIMA1)
```





<!-- ```{r, echo=FALSE, comment="",warning=FALSE} -->

<!-- # write.table(as.data.frame(ARIMA1), file = "ARIMA1") kommando til gemme ts -->
<!-- library("readxl") -->
<!-- ARIMA1 <- read_xlsx("ARIMA1.xlsx") -->
<!-- ARIMA1 <- ts(ARIMA1) -->
<!-- dput(ARIMA1) -->

<!-- ``` -->


Vi kan nu plotte vore data i R.

```{r, warning=FALSE}
plot.ts(ARIMA1, xlab='Tid', ylab = 'Kursdata')
```

Det er svært at se nogen tydelig udvikling i kursen.

Vi benytter auto.arima til at undersøge om der er en systematik i tidsserien, for at bruge denne funktion skal vi hente og loade pakken forecast med fx. pacman:

```{r, warning=FALSE, echo=FALSE}
pacman::p_load(forecast)
```

Funktionen auto.arima i R er en fantastisk funktion, der automatisk finder den ARIMA model, der passer bedst på observationerne.

```{r, warning=FALSE}
auto.arima(ARIMA1)
```


Output ARIMA(0,0,0) with non-zero mean, fortæller os at data er ligesom hvid støj. Den bedste forudsigelse af aktieprisen, vi kan komme med er gennemsnittet af alle kurserne. Vi kan altså ikke forudsige prisen vha. vore fine værktøjer.

Akaike Information Criterion (AIC) , og Bayesian Information Criterion (BIC) benyttes til at vælge ARIMA modellen med mindst AIC og BIC værdier. auto.arima finder den bedste model automatisk.



Her er ligningen for aktiekursen, den bedste forudsigelse af den fremtidige kurs er den gennemsnitlige kurs der tidligere er observeret.

$$\hat{Y_t}=19.90$$

Variablen $\hat{Y}_t$, kaldet Y hat t angiver vort estimat (gæt) på aktiekursen på tidspunkt $t=1,2,3,...$. Der er således så lidt systematik i Data at her er tale om en ARIMA(0,0,0) model. Vi ser også at der står "ARIMA(0,0,0) with non-zero mean" i output fra R.


```{r,, include=FALSE, warning=FALSE}
# ts.sim4 <-round(arima.sim(list(order = c(1,0,0), ar = 0.5), n = 50)*10+100,3)
# t4 <- as.matrix(ts.sim4)
# colnames(t4) <- "Dagskurs"
# hs <- createStyle(textDecoration = "BOLD", fontColour = "#FFFFFF", fontSize=12,
#                   fontName="Arial Narrow", fgFill = "#4F80BD")
# write.xlsx(t4, file = "ARIMA2.xlsx", colNames = TRUE,sheetName="Aktiekurs",colNames = TRUE,headerStyle = hs)

```

## ARIMA(1,0,0) eller AR(1) autoregression

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/293712597' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

En ARIMA(1,0,0) model kan skrives som:

$$\hat{Y_t}=c + \phi Y_{t-1}$$

Vi kan forklare $\hat{Y_t}$ er værdien for tidsrækken på tidspunkt $t$, ud fra en konstant $c$ plus en faktor $\phi$, der ganges på værdien for tidsrækken på tidspunkt $t-1$. For at bestemme c skal vi kende tidsrækkens sande middelværdi $\mu$ og $\phi$, disse værdier kan R beregne for os. Vi kan så beregne konstanten $c=(1-\phi)\cdot \mu$. Det betyder så at vi kan estimere fremtidige værdier tidsrækken.

Vi har nu et eksempel hvor den sande middelværdi for tidsrækken er $\mu=100$ og $\phi=0.5$ for en ARIMA(1,0,0) model. Så kan vi beregne $c=(1-\phi)\cdot \mu=(1-0.5)\cdot 100=50$ er middelværdien estimeret ved den gennemsnitlige kurs. Ligningen for modellen kan så skrives som:

$$\hat{Y_t}=c + \phi Y_{t-1} \Leftrightarrow \hat{Y_t}=50 + 0.5 Y_{t-1}$$

$\phi$ fortæller, hvis kursen dagen før var 80 gennemsnitskursen er 100, vil kursen imorgen $t=1$ ifølge modellen være forudsagt som:
$$50+0.5\cdot 80=90$$
Dagen efter $t=2$ vil kursen så være forudsagt til:
$$50+0.5\cdot 90=95$$
Om 3 dage dvs. $t=3$ vil kursen så være forudsagt til:
$$50+0.5\cdot 95=97.5$$
Om 4 dage dvs. $t=4$ vil kursen så være forudsagt til:
$$50+0.5\cdot 97.5=98.75$$

Osv..

Vi siger at forudsagte værdier konvergerer mod (dvs. nærmer sig) $\mu=100$.

AR i ARIMA, står for autoregression, selv-regression mod middelværdien, i eksemplet så vi hvordan værdien nærmer sig 100, hvis vi forudsiger flere dages kurser kan vi se dette.

$\phi$ må kun antage værdier mellem og ikke lig med -1 og 1, hvilket betyder den er stationær, altså nærmer sig den sande middelværdi $\mu$.

Hvad vil der ske hvis $\mu=100$ og $\phi=-0.5$ for en ARIMA(1,0,0) model (husk $c=(1-\phi)\cdot\mu$ når man skal bestemme modellen)?



Hent ARIMA2.xlsx Excel filen <a href="ARIMA2.xlsx" download>her</a>. Importer ARIMA2.xlsx til R via menuen File - Import Dataset - Excel. Nu skal datasættet rettes til en tidsserie med ts() kommandoen.

```{r warning=FALSE}
ARIMA2 <- ts(ARIMA2)
```




```{r,warning=FALSE}
aaa2 <- auto.arima(ARIMA2)
aaa2
```
Her afslører auto.arima 1. ordens autoregression dvs.

Modellen kan skrives som.

$$\hat{Y_t}=c + \phi Y_{t-1}\Leftrightarrow \hat{Y_t}=(1-`r round2(aaa2$coef[1],4)`)\cdot `r round2(aaa2$coef[2],4)` + `r round2(aaa2$coef[1],4)`Y_{t-1}\Leftrightarrow \hat{Y_t}=`r round2((1- aaa2$coef[1])* aaa2$coef[2],4)` + `r round2(aaa2$coef[1],4)`Y_{t-1}$$

Vi ser nu igen på vores eksempel med ARIMA2, vi kan nu i R forudsige aktiekursen 12 perioder frem med predict:

```{r, warning=FALSE}
predict(auto.arima(ARIMA2), n.ahead = 12)$pred
```


<details>
  <summary>Spørgsmål ARIMA(1,0,0)</summary>
Hent ARIMA22.xlsx Excel filen <a href="ARIMA22.xlsx" download>her</a>. Importer ARIMA22.xlsx til R via menuen File - Import Dataset - Excel. Bestem for den fremtidige aktiekurs 15 perioder frem, udregn direkte fx. vha. Excel og tjek dit resultat i R.
</details>
<br>
<details>
<summary>Svar ARIMA(1,0,0)</summary>
```{r}
ARIMA22 <- ts(ARIMA22)
aaa22 <- auto.arima(ARIMA22)
aaa22
```



```{r, warning=FALSE}
predict(auto.arima(ARIMA22), n.ahead = 15)$pred
```


</details>
<br>
<details>
  <summary>Spørgsmål ARIMA(1,0,0)</summary>
Hent ARIMA23.xlsx Excel filen <a href="ARIMA23.xlsx" download>her</a>. Importer ARIMA23.xlsx til R via menuen File - Import Dataset - Excel. Bestem for den fremtidige aktiekurs 15 perioder frem, udregn direkte fx. vha. Excel og tjek dit resultat i R.
</details>
<br>


## ARIMA(0,1,0) eller I(1) Random Walk with a drift

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/293713019' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>



Hvis en serie er ikke-stationær, er den simpleste model en random walk:

$$\hat{Y_t}-Y_{t-1}=\mu\Leftrightarrow \hat{Y_t}=Y_{t-1}+\mu$$
Dette betyder at Y stiger konstant med $\mu$ i hver periode. Drift betyder at tidsrækken stiger konstant.

Forestiller man sig en ARIMA(0,1,0) med drift 10 og en kurs på tidspunkt t-1 på 120, vil vi forudsige en kurs på 130 ved tid t og 140 ved tid t+1 osv. Vi kan opskrive modellen som:
$$\hat{Y_t}-Y_{t-1}=10\Leftrightarrow \hat{Y_t}=Y_{t-1}+10$$



```{r, include=FALSE, warning=FALSE}
# ts.sim1 <-round(arima.sim(list(order = c(0,1,0)), n = 50, mean=1)*10+100,3)
# ts.plot(ts.sim1)
# auto.arima(ts.sim1)
# t1 <- as.matrix(ts.sim1)
# colnames(t1) <- "Dagskurs"
# hs <- createStyle(textDecoration = "BOLD", fontColour = "#FFFFFF", fontSize=12,
#                   fontName="Arial Narrow", fgFill = "#4F80BD")
# write.xlsx(t1, file = "ARIMA3.xlsx", colNames = TRUE,sheetName="Aktiekurs",colNames = TRUE,headerStyle = hs)

```

```{r, echo=FALSE, comment="",warning=FALSE}
library("readxl")
ARIMA3 <- read_xlsx("ARIMA3.xlsx")
ARIMA3 <- ts(ARIMA3)
# dput(ARIMA3)
```

Hent ARIMA3.xlsx Excel filen <a href="ARIMA3.xlsx" download>her</a>. Importer ARIMA3.xlsx til R via menuen File - Import Dataset - Excel. Nu skal datasættet rettes til en tidsserie med ts() kommandoen.


```{r}
ts.plot(ARIMA3)
auto.arima(ARIMA3)
```

Modellen ovenfor kan skrives som:
$$\hat{Y_t}-Y_{t-1}=\mu\Leftrightarrow \hat{Y_t}-Y_{t-1}=7.9\Leftrightarrow \hat{Y_t}=Y_{t-1}+7.9$$
Vi indsætter drift i stedet for $\mu$, tolningen er at modellen forudsiger at aktiekursen stiger med 7.9 fra periode til periode.


Hvis vi har en ren random walk model uden drift dvs. med $\mu=0$ ARIMA(0,1,0) for en aktiekurs , forventer vi at kursen til tid t vil være den samme som til tid t-1. Denne kan skrives som:

$$\hat{Y_t}-Y_{t-1}=0$$



## ARIMA(0,0,1) eller MA(1) Moving average


<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/293712987' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>




Vi kan i stedet for at bruge tidligere aktiekurser til at forudsige aktiekursen i stedet benytte tidligere målefejl residualer til at forudsige kursen.

Modellen kan skrives som:

$$\hat{Y_t}=\mu+\theta_1 e_{t-1}$$
Hvis vi forestiller os $\mu=50$ $\theta_1=0.5$ kursen til tid t-1 var 120 forudsigelsen til tid t-1 var 100, så målefejlen residualen til tid t-1 er $e_{t-1}$ er faktisk kurs minus forudsagt kurs altså 120-100=20. Nu kan vi forudsige kursen til tid t som:
$$\hat{Y_t}=\mu+\theta_1 e_{t-1}\Leftrightarrow \hat{Y_t}=50+0.5\cdot20=60$$

```{r, include=FALSE, warning=FALSE}
# library(openxlsx)
# ts.sim5 <- round(arima.sim(list(order = c(0,0,1),ma = 0.9), n = 50)*10+100,3)
# t5 <- as.matrix(ts.sim5)
# colnames(t5) <- "Dagskurs"
# hs <- createStyle(textDecoration = "BOLD", fontColour = "#FFFFFF", fontSize=12,
#                   fontName="Arial Narrow", fgFill = "#4F80BD")
# write.xlsx(t5, file = "ARIMA4.xlsx", colNames = TRUE,sheetName="Aktiekurs",colNames = TRUE,headerStyle = hs)

```


Hent ARIMA4.xlsx Excel filen <a href="ARIMA4.xlsx" download>her</a>. Importer ARIMA4.xlsx til R via menuen File - Import Dataset - Excel. Nu skal datasættet rettes til en tidsserie med ts() kommandoen.


```{r, warning=FALSE}
ts.plot(ARIMA4)
auto.arima(ARIMA4)
```

Vi kan nu forudsige aktiekursen 12 perioder frem med predict:

```{r, warning=FALSE}
predict(auto.arima(ARIMA4), n.ahead = 12)$pred
```

Hvorfor svarer den forudsagte værdi til mean i en ren ARIMA(0,0,1) eller MA(1) model? (Vink hvad er definitionen på en residual)

## Plots med forskellige modeller

```{r, echo=FALSE}
ap1 <- round(arima.sim(list(order = c(0,1,1),ma = -0.5), n = 50)*10+100,3)
ts.plot(ap1,ylab="Aktiekurs")
auto.arima(ap1)

```

Kursen svinger omkring middelværdien.

```{r, echo=FALSE}
ap2 <- round(arima.sim(list(order = c(1,1,1),ma = 0.2,ar=0.5), n = 50)*10+100,3)
ts.plot(ap2,ylab="Aktiekurs")
auto.arima(ap2)

```



```{r, echo=FALSE}
ap3 <- round(arima.sim(list(order = c(1,0,1),ma = 0.8,ar=-0.3), n = 200)*10+100,3)
ts.plot(ap3,ylab="Aktiekurs")
auto.arima(ap3)
```


Vi kan også grafisk vise hvordan kursen vil udvikle sig med 80% og 95% konfidensbælter.


```{r, warning=FALSE}
forecast(auto.arima(ap3))
plot(forecast(auto.arima(ap3)))
```



## ARIMA af højere orden

Arima modeller kan afhænge af flere tidligere perioder, fx kan ligningen for ARIMA(2,0,0) eller AR(2), opskrives som:

$$\hat{Y_t}=c + \phi Y_{t-1}+ \phi_2 Y_{t-2}$$
Modellen afhænger altså af 2 tidligere perioder (lags) og ikke en. Man betegner dette som en model med lag 2.

Arima modeller kan indeholde flere forskellige elementer med lag som fx. ARIMA(0,2,1).

## ARIMA og sæsonalitet

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/293712749' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>



Hvis fx. en aktie handles lavere om fredagen kan ARIMA modellerne korrigere for dette ved sæsonkorrektion. I sæsonkorrigerede modeller vises dette som en ekstra vektor med 3 tal for hhv. sæsonkorrigeret AR eller SAR, sæsonkorrigeret I eller SI og sæsonkorrigeret MA eller SMA. En model som ARIMA(1,0,0)(1,0,0) har altså udover AR også en sæsonkomponent.



## ARIMA eksempler

### Traktorer

Hent følgende data for traktor salg, med følgende kommandoer i R.

```{r, warning=FALSE}
data = read.csv('http://ucanalytics.com/blogs/wp-content/uploads/2015/06/Tractor-Sales.csv')
data = ts(data[,2],start = c(2003,1),frequency = 12)

```

Vi ser salget er voksende over tid, der er ligeledes en sæsonkomponent.

```{r, warning=FALSE}
plot(data, xlab='Years', ylab = 'Tractor Sales')
```

Differens tranformer data for at generere stationære data mht. middel (fjern trend)

```{r, warning=FALSE}
plot(diff(data),ylab='Differenced Tractor Sales')
```

log transformer data for at sikre stationaritet mht. varians.

```{r, warning=FALSE}
plot(log10(data),ylab='Log (Tractor Sales)')
```

Eventuel Differens og log transformation af data for at sikre stationaritet både mht. middel og varians.

```{r, warning=FALSE}
plot(diff(log10(data)),ylab='Differenced Log (Tractor Sales)')
```

Find bedste model med auto.arima, når der er stationaritet.

Akaike Information Criterion (AIC) , og Bayesian Information Criterion (BIC), vælg ARIMA modellen med mindst AIC and BIC værdier. auto.arima finder den bedste model automatisk.

```{r, warning=FALSE}
require(forecast)
ARIMAfit = auto.arima(log10(data), approximation=FALSE,trace=FALSE)
ARIMAfit

```
Nu kan vi forudsige kommende traktor salg med modellen

```{r}
par(mfrow = c(1,1))
pred = predict(ARIMAfit, n.ahead = 36)
salg <- 10^pred$pred
salg
plot(data,type='l',xlim=c(2003,2018),ylim=c(1,1600),xlab = 'Year',ylab = 'Tractor Salg')
lines(10^(pred$pred),col='blue')
lines(10^(pred$pred+2*pred$se),col='orange')
lines(10^(pred$pred-2*pred$se),col='orange')
```




### Detail debet card forbrug på Island (millioner ISK).

```{r, warning=FALSE, include=FALSE}
require("fpp")
```

```{r, warning=FALSE }
#Hent fpp pakken og load den
plot(debitcards)
```


```{r , warning=FALSE}
dldebitcards <- diff(log10(debitcards))
plot(dldebitcards,ylab="Differenced Log (debitcards)")
```


```{r, warning=FALSE}
require(forecast)
ARIMAfit = auto.arima(log10(debitcards), approximation=FALSE,trace=FALSE)
ARIMAfit

```
Nu kan vi forudsige kommende debetkort omsætning med modellen

```{r, warning=FALSE}
par(mfrow = c(1,1))
pred = predict(ARIMAfit, n.ahead = 36)
plot(debitcards,type='l',xlim=c(2000,2016),ylim=c(1,40000),xlab = 'Year',ylab = 'Debetcard usage')
lines(10^(pred$pred),col='blue')
lines(10^(pred$pred+2*pred$se),col='orange')
lines(10^(pred$pred-2*pred$se),col='orange')

```





Forudsagt brug af debetkort bliver:
```{r, warning=FALSE}
10^(pred$pred)
```





```{r, warning=FALSE, include=FALSE}
# plot(ausair)
# plot(ausbeer)
```



## Forecast Aktiekurser

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/293712809' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>



Man kan hente online aktiekurser med quantmod pakken installer denne med fx. pacman, vi skal også bruge pakken forecast som vi ligeledes henter. Vi henter nedenfor Google justeret lukkekurs til dato det er 6 søjle i GOOG matricen nedenfor. Vi kan se forecaste aktiekursen vha.

```{r, warning=FALSE}
pacman::p_load(quantmod, forecast)
getSymbols("GOOG",from = "2017-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE)
plot(GOOG[,6],main = "Google adj. close")
```


```{r, warning=FALSE}
agoog <- auto.arima(GOOG[,6])
agoog
fagoog <- forecast(agoog)
fagoog
plot(fagoog,main = "Google adj. close")
```

```{r, warning=FALSE}
getSymbols("GS",from = "2017-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE)
plot(GS[,6],main = "Goldman Sachs adj. close")
ags <- auto.arima(GS[,6])
ags
fags <- forecast(ags)
fags
plot(fags,main = "Goldman Sachs adj. close")
```

```{r, warning=FALSE}
getSymbols("DANSKE.CO",from = "2017-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE)
plot(DANSKE.CO[,6],main = "Danske Bank adj. close")
addb <- auto.arima(DANSKE.CO[,6])
addb
faddb <- forecast(addb)
faddb
plot(faddb,main = "Danske Bank adj. close")
```

```{r, warning=FALSE}
getSymbols("BRK-A",from = "2000-01-01", to = Sys.Date(),getSymbols.warning4.0=FALSE)
plot(`BRK-A`[,6],main = "Berkshire adj. close")
aberkshire <- auto.arima(`BRK-A`[,6])
aberkshire
faberkshire <- forecast(aberkshire)
faberkshire
plot(faberkshire,main = "Berkshire adj. close")
```



## Aktieafkast


<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/293712927' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>



I Quantmod pakken ligger også mulighed for at beregne fx. dagligt, ugentligt afkast, dette gør vi vha. funktionen "periodReturn".

```{r , warning=FALSE}
getSymbols("AAPL",src='yahoo')
apple <- periodReturn(`AAPL`,period='yearly',subset='2003::')  # Årligt Afkast 2003 til i dag
plot(apple, main = "Apple årligt afkast siden 2007")
auto.arima(apple)
```


```{r , warning=FALSE}
getSymbols("BRK-A",src='yahoo')
berkshire <- periodReturn(`BRK-A`,period='yearly',subset='2003::')
plot(berkshire, main = "Berkshire årligt afkast siden 2007")
auto.arima(berkshire)
```

### ARIMA opsamling video
<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://player.vimeo.com/video/234990675' frameborder='0' webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe></div>
<br>

